{"title":"懒羊羊","description":"星际拾荒者","language":"zh-Hans","link":"https://www.xxlaila.cn","pubDate":"Mon, 13 Apr 2020 02:35:48 GMT","lastBuildDate":"Thu, 16 Apr 2020 08:03:41 GMT","generator":"hexo-generator-json-feed","webMaster":"xxlaila","items":[{"title":"etcd备份与恢复","link":"https://www.xxlaila.cn/2020/04/13/etcd备份与恢复/","description":"ETCD 存储 k8s 所有数据信息ETCD 是k8s集群极为重要的一块服务，存储了集群所有的数据信息。同理，如果发生灾难或者 etcd 的数据丢失，都会影响集群数据的恢复，k8s中只用kube-apiserver和etcd进行数据交互。etcdctl版本: 3.3.18，kubernetes: v1.17.3。均采用二进制安装","pubDate":"Mon, 13 Apr 2020 02:35:48 GMT","guid":"https://www.xxlaila.cn/2020/04/13/etcd备份与恢复/","category":"kubernetes"},{"title":"Prometheus监控应用","link":"https://www.xxlaila.cn/2020/04/12/Prometheus监控应用/","description":"Prometheus 应用安装Prometheus的单机安装比较简单，这里采用的是单机进行安装。Prometheus的相关插件下载地址123456# 下载Prometheuswget https://github.com/prometheus/prometheus/releases/download/v2.17.1/prometheus-2.17.1.linux-amd64.tar.gztar zxc prometheus-2.17.1.linux-amd64.tar.gz &amp;&amp; mv prometheus-2.17.1.linux-amd64 /opt/prometheus# 创建prometheus 数据存放目录mkdir -p /opt/prometheus/data创建prometheus启动文件12345678910111213141516171819202122cat &gt;/usr/lib/systemd/system/prometheus.service&lt;&lt;EOF[Unit]Description=PrometheusDocumentation=https://prometheus.io/docsWants=network-online.targetAfter=network-online.target[Service]User=rootGroup=rootType=simpleExecStart=/opt/prometheus/prometheus --config.file=/opt/prometheus/prometheus.yml --storage.tsdb.path=/opt/prometheus/dataRestart=on-failure[Install]WantedBy=multi-user.targetEOF# 启动prometheussystemctl restart prometheus.service &amp;&amp;systemctl status prometheus.service# 默认端口9090部署node_exporter主要用来监控服务器的基础信息，如: cpu、内存、磁盘、网卡。123# 下载node_exporterwget https://github.com/prometheus/node_exporter/releases/download/v1.0.0-rc.0/node_exporter-1.0.0-rc.0.linux-amd64.tar.gztar node_exporter-1.0.0-rc.0.linux-amd64.tar.gz &amp;&amp; mv node_exporter-1.0.0-rc.0.linux-amd64/node_exporter /usr/bin/ &amp;&amp; rm -rf node_exporter-1.0.0-rc.0.linux-amd64*设置node_exporter开机启动123456789101112131415161718192021cat &gt;/usr/lib/systemd/system/node_exporter.service&lt;&lt;EOF[Unit]Description=node_exporterDocumentation=https://prometheus.io/docsAfter=network.target[Service]User=rootGroup=rootType=simpleExecStart=/usr/bin/node_exporterRestart=on-failure[Install]WantedBy=multi-user.targetEOF# 启动 node_exportersystemctl start node_exporter.service &amp;&amp; systemctl status node_exporter.service# 默认端口9100安装mysql_exporter主要监控mysql数据库的信息123# 下载mysql_exporterwget https://github.com/prometheus/mysqld_exporter/releases/download/v0.12.1/mysqld_exporter-0.12.1.linux-amd64.tar.gz&amp;&amp; tar zxf mysqld_exporter-0.12.1.linux-amd64.tar.gz &amp;&amp; mv mysqld_exporter-0.12.1.linux-amd64/mysqld_exporter &amp;&amp; rm -rf mysqld_exporter-0.12.1.linux-amd64*创建msql的连接权限mysqld_exporter需要连接Mysql，首先为它创建用户并赋予所需要的权限：12345678910GRANT REPLICATION CLIENT, PROCESS ON . TO 'exporter'@'localhost' identified by '123456';GRANT SELECT ON performance_schema.* TO 'exporter'@'localhost';flush privileges;# 创建.my.cnf文件在当前的用户目录(可变更)创建.my.cnf文件cat &gt; .my.cnf&lt;&lt;EOF[client]user=exporterpassword=123456设置mysql_exporter开启启动123456789101112131415161718192021222324252627282930313233cat &gt;/usr/lib/systemd/system/mysql_exporter.service&lt;&lt;EOF[Unit]Description=mysqld_exporterDocumentation=https://prometheus.io/docsAfter=network.target[Service]User=rootGroup=rootType=simpleExecStart=/usr/bin/mysqld_exporter \\ --collect.info_schema.processlist \\ --collect.info_schema.innodb_tablespaces \\ --collect.info_schema.innodb_metrics \\ --collect.perf_schema.tableiowaits \\ --collect.perf_schema.indexiowaits \\ --collect.perf_schema.tablelocks \\ --collect.engine_innodb_status \\ --collect.perf_schema.file_events \\ --collect.binlog_size \\ --collect.info_schema.clientstats \\ --collect.perf_schema.eventswaits \\ --config.my-cnf=/root/.my.cnfRestart=on-failure[Install]WantedBy=multi-user.targetEOF# 启动 mysql_exportersystemctl start mysql_exporter.service &amp;&amp; systemctl status mysql_exporter.service# 默认端口9104使用granafa给 MySQLD_Exporter添加监控图表:主从主群监控(模板7371)：相关mysql 状态监控7362：缓冲池状态7365Prometheus基于文件的动态加载基于文件的服务发现是最通用的方式。这种方式不需要依赖于任何的平台或者第三方服务。对于Prometheus而言也不可能支持所有的平台或者环境。通过基于文件的服务发现方式下，Prometheus会定时从文件中读取最新的Target信息，可以通过任意的方式将监控Target的信息写入即可。Prometheus 可以通过JSON或者YAML格式的文件，定义所有的监控目标。下面我是通过yaml的文件格式来进行配置监控。在添加实例的时候添加了一些额外的标签信息。如: env、service、group等，实例中采集到的样本信息将包含这些标签信息，从而可以通过该标签按照环境对数据进行统计。修改prometheus.yml123456789101112131415161718192021222324252627282930cat prometheus.yml global: scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute. evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute. scrape_timeout: 10s # scrape_timeout is set to the global default (10s).alerting: alertmanagers: - static_configs: - targets: # - alertmanager:9093rule_files: # - \"first_rules.yml\" # - \"second_rules.yml\"scrape_configs: - job_name: 'kxl_docker' file_sd_configs: - files: - /opt/prometheus/sd_config/docker.yml refresh_interval: 5s - job_name: 'kxl_vm' file_sd_configs: - files: - /opt/prometheus/sd_config/vm.yml refresh_interval: 5s - job_name: 'kxl_mysql' file_sd_configs: - files: - /opt/prometheus/sd_config/mysql.yml refresh_interval: 5sscrape_configs 这里我定义了三组，分别是监控docker、vm、mysql的，每一个组对应一个yml文件。对应的服务到对应的文件进行增加即可。还可以增加(zk、es、ng、redis)等服务。创建被扫描的文件1mkdir -p /opt/prometheus/sd_config &amp;&amp; cd /opt/prometheus/sd_configdocker.yml123456- labels: service: docker env: test group: docker targets: - 172.21.1.30:8080vm.yml12345678- labels: env: test group: linux_node service: vm targets: - 172.21.1.30:9100 - 172.21.1.52:9100 - 172.21.1.52:9100mysql.yml12345678910111213- labels: service: mysql env: test group: mysql targets: - 172.21.1.30:9104 - labels: service: mysql env: dev group: mysql targets: - 172.21.1.52:9104在Prometheus UI的Targets下就可以看到当前定义的yml文件中动态获取到实例信息以及监控任务的采集状态，同时在Labels列下会包含用户添加的自定义标签:在Prometheus UI的service-discovery下可以看到我们定义的job类型alertmanager 部署12345wget https://github.com/prometheus/alertmanager/releases/download/v0.20.0/alertmanager-0.20.0.linux-amd64.tar.gztar zxf alertmanager-0.20.0.linux-amd64.tar.gz &amp;&amp; mv alertmanager-0.20.0.linux-amd64 /opt/alertmanager &amp;&amp; rm -rf alertmanager-0.20.0.linux-amd64*# Alermanager会将数据保存到本地中，默认的存储路径为data/。因此，在启动Alertmanager之前需要创建相应的目录mkdir -p /opt/alertmanager/data设置alertmanager开机启动1234567891011121314151617181920cat &gt;/usr/lib/systemd/system/alertmanager.service&lt;&lt;EOF[Unit]Description=alertmanagerDocumentation=https://prometheus.io/docsWants=network-online.targetAfter=network-online.target[Service]User=rootGroup=rootType=simpleExecStart=/opt/alertmanager/alertmanager --config.file=/opt/alertmanager/alertmanager.yml --storage.tsdb.path=/opt/alertmanager/dataRestart=on-failure[Install]WantedBy=multi-user.targetEOF# 启动systemctl start alertmanager &amp;&amp; systemctl status alertmanager修改prometheus配置用于加载alertmanager和alertmanager rules123456789101112131415161718192021222324252627282930313233343536cat prometheus.ymlglobal: scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute. evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute. scrape_timeout: 10salerting: alertmanagers: - static_configs: - targets: - 172.21.1.30:9093rule_files: - 'rules/*.rules'scrape_configs: - job_name: 'kxl_promethes' file_sd_configs: - files: - /opt/prometheus/sd_config/data.yml refresh_interval: 5s - job_name: 'kxl_docker' file_sd_configs: - files: - /opt/prometheus/sd_config/docker.yml refresh_interval: 5s - job_name: 'kxl_vm' file_sd_configs: - files: - /opt/prometheus/sd_config/vm.yml refresh_interval: 5s - job_name: 'kxl_mysql' file_sd_configs: - files: - /opt/prometheus/sd_config/mysql.yml refresh_interval: 5s# 重启prometheussystemctl restart prometheus新建rules规则12345678910111213141516171819202122232425262728293031323334mkdir -p /opt/prometheus/rulescat &gt;node.rules&lt;&lt;EOFgroups:- name: kxl_Instances rules: - alert: InstanceDown expr: up == 0 for: 5m labels: severity: page # Prometheus templates apply here in the annotation and label fields of the alert. annotations: description: '&#123;&#123; $labels.instance &#125;&#125; of job &#123;&#123; $labels.job &#125;&#125; has been down for more than 5 minutes.' summary: 'Instance &#123;&#123; $labels.instance &#125;&#125; down' - alert: 内存使用率过高 expr: 100-(node_memory_Buffers_bytes+node_memory_Cached_bytes+node_memory_MemFree_bytes)/node_memory_MemTotal_bytes*100 &gt; 30 for: 1m labels: severity: warning annotations: summary: \"Instance &#123;&#123; $labels.instance &#125;&#125; 内存使用率过高\" description: \"&#123;&#123; $labels.instance &#125;&#125; of job &#123;&#123;$labels.job&#125;&#125;内存使用率超过80%,当前使用率[&#123;&#123; $value &#125;&#125;].\" - alert: cpu使用率过高 expr: 100-avg(irate(node_cpu_seconds_total&#123;mode=\"idle\"&#125;[5m])) by(instance)*100 &gt; 0 for: 1m labels: severity: warning annotations: summary: \"Instance &#123;&#123; $labels.instance &#125;&#125; cpu使用率过高\" description: \"&#123;&#123; $labels.instance &#125;&#125; of job &#123;&#123;$labels.job&#125;&#125;cpu使用率超过80%,当前使用率[&#123;&#123; $value &#125;&#125;].\"EOF配置告警策略12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152cat alertmanager.yml global: resolve_timeout: 5m smtp_smarthost: 'smtp.exmail.qq.com:465' smtp_from: 'zxc@xxlaila.cn.com' smtp_auth_username: 'zxc@xxlaila.cn.com' smtp_auth_password: '123456' smtp_require_tls: true hipchat_api_url: 'https://hipchat.foobar.org/' wechat_api_url: 'https://qyapi.weixin.qq.com/cgi-bin/' wechat_api_secret: 'KJfj93rijk903240i--234jsnjkhf23sjkfjsfs' # 企业微信Secret wechat_api_corp_id: 'wwa98457kdsnfk8' # 企业微信CorpIdtemplates: - 'template/*.tmpl' 告警信息模版route: group_by: ['alertname'] group_wait: 10s group_interval: 10s repeat_interval: 1h #receiver: 'web.hook' receiver: default routes: - receiver: 'wechat' continue: truereceivers:#- name: 'web.hook' - name: 'default' email_configs: - to: 'cq_xxlaila@163.com' html: '&#123;&#123; template \"test.html\" . &#125;&#125;' headers: &#123; Subject: \"[WARN] email\"&#125; send_resolved: true webhook_configs: - url: 'http://127.0.0.1:5001/' - name: 'wechat' wechat_configs: - send_resolved: true to_user: '@all' # 接受人，都是all to_party: '4' # 接收组的id agent_id: '1000002' # 企业微信自定义应用的id corp_id: 'wwa98457kdsnfk8' # 企业微信CorpId message: '&#123;&#123; template \"test_wechat.html\" . &#125;&#125;' # 发送消息的模版inhibit_rules: - source_match: severity: 'critical' target_match: severity: 'warning' equal: ['alertname', 'dev', 'instance']Alertmanager主要负责对Prometheus产生的告警进行统一处理，因此在Alertmanager配置中一般会包含以下几个主要部分：全局配置（global）：用于定义一些全局的公共参数，如全局的SMTP配置，Slack配置等内容；模板（templates）：用于定义告警通知时的模板，如HTML模板，邮件模板等；告警路由（route）：根据标签匹配，确定当前告警应该如何处理；接收人（receivers）：接收人是一个抽象的概念，它可以是一个邮箱也可以是微信，Slack或者Webhook等，接收人一般配合告警路由使用；抑制规则（inhibit_rules）：合理设置抑制规则可以减少垃圾告警的产生.tmpl模板的配置123456789101112131415161718192021222324252627282930313233343536373839404142# 创建.tmpl模版存放目录mkdir /opt/alertmanager/template &amp;&amp; cd /opt/alertmanager/template# 企业微信cat &gt;test_wechat.tmpl &lt;&lt;EOF&#123;&#123; define \"test_wechat.html\" &#125;&#125; &#123;&#123; range $i, $alert := .Alerts.Firing &#125;&#125; [报警项]:&#123;&#123; index $alert.Labels \"alertname\" &#125;&#125; [环境]: &#123;&#123; index $alert.Labels \"env\" &#125;&#125; [实例]:&#123;&#123; index $alert.Labels \"instance\" &#125;&#125; [报警阀值]:&#123;&#123; index $alert.Annotations \"value\" &#125;&#125; [开始时间]:&#123;&#123; $alert.StartsAt &#125;&#125; &#123;&#123; end &#125;&#125;&#123;&#123; end &#125;&#125;EOF# 邮件告警cat &gt;test.tmpl &lt;&lt;EOF&#123;&#123; define \"test.html\" &#125;&#125;&lt;table border=\"1\"&gt; &lt;tr&gt; &lt;td&gt;报警项&lt;/td&gt; &lt;td&gt;环境&lt;/td&gt; &lt;td&gt;实例&lt;/td&gt; &lt;td&gt;报警阀值&lt;/td&gt; &lt;td&gt;开始时间&lt;/td&gt; &lt;/tr&gt; &#123;&#123; range $i, $alert := .Alerts &#125;&#125; &lt;tr&gt; &lt;td&gt;&#123;&#123; index $alert.Labels \"alertname\" &#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123; index $alert.Labels \"env\"&#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123; index $alert.Labels \"instance\" &#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123; index $alert.Annotations \"value\" &#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123; $alert.StartsAt &#125;&#125;&lt;/td&gt; &lt;/tr&gt; &#123;&#123; end &#125;&#125;&lt;/table&gt;&#123;&#123; end &#125;&#125;EOF# 重启alertmanagersystemctl restart alertmanager","pubDate":"Sun, 12 Apr 2020 04:47:44 GMT","guid":"https://www.xxlaila.cn/2020/04/12/Prometheus监控应用/","category":"监控"},{"title":"关于openstack 安装centos-release-openstack-ocata失败解决","link":"https://www.xxlaila.cn/2020/04/09/关于openstack-安装centos-release-openstack-ocata失败解决/","description":"关于openstack 安装centos-release-openstack-ocata失败解决openstack ocata版本在后期增加节点的时候，安装centos-release-openstack-ocata失败。ocata版本安装参考centos-release-openstack-ocata 错误提示安装centos-release-openstack-ocata前系统版本centos 7.4，在yum安装的时候提示:","pubDate":"Thu, 09 Apr 2020 05:16:19 GMT","guid":"https://www.xxlaila.cn/2020/04/09/关于openstack-安装centos-release-openstack-ocata失败解决/","category":"openstack"},{"title":"利用 zabbix 监控全国天气状况","link":"https://www.xxlaila.cn/2020/04/08/利用-zabbix-监控全国天气状况/","description":"利用 zabbix 监控全国天气状况&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;本次主要是采用zabbix 的 http 代理方式进行数据的采集。可以通过网站的api接口来测试获取天气的状况。这里使用的是高德地图的天气。zabbix版本使用4.0 以上支持http 代理。3.0 版本不支持。","pubDate":"Wed, 08 Apr 2020 06:20:47 GMT","guid":"https://www.xxlaila.cn/2020/04/08/利用-zabbix-监控全国天气状况/","category":"zabbix"},{"title":"openvpn推送路由","link":"https://www.xxlaila.cn/2020/03/26/openvpn推送路由/","description":"需求&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;openvpn 做好以后，发现到腾讯云网络不通，拓扑图参考如下：","pubDate":"Thu, 26 Mar 2020 01:05:15 GMT","guid":"https://www.xxlaila.cn/2020/03/26/openvpn推送路由/","category":"vpn"},{"title":"openvpn配置ldap","link":"https://www.xxlaila.cn/2020/03/11/openvpn配置ldap/","description":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;企业内一般都有ldap，基本上所有的系统都支持ldap登录，openvpn也不例外，","pubDate":"Wed, 11 Mar 2020 10:31:55 GMT","guid":"https://www.xxlaila.cn/2020/03/11/openvpn配置ldap/","category":"vpn"},{"title":"openvpn部署","link":"https://www.xxlaila.cn/2020/03/10/openvpn部署/","description":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由于公司内部系统比较多，而且这部分系统都是只能在公司内网访问，","pubDate":"Tue, 10 Mar 2020 11:48:13 GMT","guid":"https://www.xxlaila.cn/2020/03/10/openvpn部署/","category":"vpn"},{"title":"Kubernetes里的Service究竟是如何工作","link":"https://www.xxlaila.cn/2020/03/01/Kubernetes里的Service究竟是如何工作/","description":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Service是Kubernetes接入层的一种抽象资源，它为我们提供了一种固定的、统一的访问接口地址和负载均衡能力，","pubDate":"Sun, 01 Mar 2020 03:31:06 GMT","guid":"https://www.xxlaila.cn/2020/03/01/Kubernetes里的Service究竟是如何工作/","category":"kubernetes"},{"title":"Elasticsearch集群规划","link":"https://www.xxlaila.cn/2020/02/20/Elasticsearch集群规划/","description":"集群规划&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在Elasticsearch集群规划中，如何规划集群，合理的规划集群可以防止Elasticsearch出现脑裂，","pubDate":"Thu, 20 Feb 2020 07:38:04 GMT","guid":"https://www.xxlaila.cn/2020/02/20/Elasticsearch集群规划/","category":"elasticsearch"},{"title":"traefik支持socketio会话","link":"https://www.xxlaila.cn/2020/02/17/traefik支持socketio会话/","description":"场景&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;公司业务出现使用一个使用websocket的会话需求，和常见的web聊天工具一样，如网页QQ。","pubDate":"Mon, 17 Feb 2020 10:48:57 GMT","guid":"https://www.xxlaila.cn/2020/02/17/traefik支持socketio会话/","category":"traefik"},{"title":"白话Kubernetes基础概念","link":"https://www.xxlaila.cn/2020/02/17/白话Kubernetes基础概念/","description":"Kubernetes 简介微服务框架的流行，使得服务越来越精细化，服务也变的越来越多，对于发布和管理而言产生了巨大的挑战，而 Docker 的诞生，给与微服务的资源治理和控制提供了很好的基础。","pubDate":"Mon, 17 Feb 2020 07:58:00 GMT","guid":"https://www.xxlaila.cn/2020/02/17/白话Kubernetes基础概念/","category":""},{"title":"如何实现应用在Kubernetes上的优雅落地","link":"https://www.xxlaila.cn/2020/02/17/如何实现应用在Kubernetes上的优雅落地/","description":"Kubernetes 热度&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;国内外对 Kubernetes 这波潮流的追捧，包括各大云厂商：蚂蚁金服、京东、美团、滴滴等各大公司都把 Kubernetes 作为自己的基础设施的重心。","pubDate":"Mon, 17 Feb 2020 07:31:30 GMT","guid":"https://www.xxlaila.cn/2020/02/17/如何实现应用在Kubernetes上的优雅落地/","category":"kubernetes"},{"title":"traefik2.0-动态配置","link":"https://www.xxlaila.cn/2020/01/13/traefik2-0-动态配置/","description":"实战&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;之前在traefik部署的时候做了traefik 2.0 的动态安装和动态配置加载","pubDate":"Mon, 13 Jan 2020 09:39:36 GMT","guid":"https://www.xxlaila.cn/2020/01/13/traefik2-0-动态配置/","category":"Ingress"},{"title":"traefik 2.0 灰度发布","link":"https://www.xxlaila.cn/2020/01/09/traefik灰度发布/","description":"灰度发布&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Traefik2.0 的一个更强大的功能就是灰度发布，灰度发布我们有时候也会称为金丝雀发布（Canary），主要就是让一部分测试的服务也参与到线上去，经过测试观察看是否符号上线要求。","pubDate":"Thu, 09 Jan 2020 08:52:01 GMT","guid":"https://www.xxlaila.cn/2020/01/09/traefik灰度发布/","category":"Ingress"},{"title":"traefik 2.0部署","link":"https://www.xxlaila.cn/2020/01/08/traefik2-0部署/","description":"认识&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Traefik2.0 中的配置可以使用两种不同的方式动态配置：完全动态的路由配置静态配置：启动配置","pubDate":"Wed, 08 Jan 2020 09:52:01 GMT","guid":"https://www.xxlaila.cn/2020/01/08/traefik2-0部署/","category":"Ingress"},{"title":"Elasticsearch索引管理","link":"https://www.xxlaila.cn/2019/12/30/Elasticsearch索引管理/","description":"痛点&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;公司上线了elk日志分析系统，但是在线下开发测试环境数据量比较大，而且线下都是一些测试和开发使用的数据。也没有必要存放起来。","pubDate":"Mon, 30 Dec 2019 06:41:07 GMT","guid":"https://www.xxlaila.cn/2019/12/30/Elasticsearch索引管理/","category":"elasticsearch"},{"title":"centos 安装字体三步曲","link":"https://www.xxlaila.cn/2019/12/23/centos-安装字体三步曲/","description":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;上传字体到服务器。安装准备","pubDate":"Mon, 23 Dec 2019 09:38:36 GMT","guid":"https://www.xxlaila.cn/2019/12/23/centos-安装字体三步曲/","category":"centos"},{"title":"nfs服务器异常","link":"https://www.xxlaila.cn/2019/12/23/nfs服务器异常/","description":"故障表现&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;近期发现只要是挂载nfs的服务器，不定期的出现服务器卡死，发现是在ansible自动化发布的时候出现一直卡死，然后登录服务器端发现发现命令不能用，如: ls、df等命令无法正常使用。","pubDate":"Mon, 23 Dec 2019 01:29:41 GMT","guid":"https://www.xxlaila.cn/2019/12/23/nfs服务器异常/","category":"centos"},{"title":"traefik https使用","link":"https://www.xxlaila.cn/2019/12/19/traefik-https使用/","description":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;之前已经使用traefik服务作为入口，测试并访问了tomcat应用，之前是通过http来访问的，而我们在yaml文件里面也添加8443端口用于https访问，在实际环境中我们也是需要https来进行访问应用，通过traefik实现https，traefik http应用","pubDate":"Thu, 19 Dec 2019 06:06:08 GMT","guid":"https://www.xxlaila.cn/2019/12/19/traefik-https使用/","category":"Ingress"},{"title":"kube-eventer事件发射器","link":"https://www.xxlaila.cn/2019/12/16/kube-eventer事件发射器/","description":"介绍&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;kube-eventer 是一个事件发射器，它将 Kubernetes 事件发送到接收器(例如，DingTalk、SLS、Kafka 等)。","pubDate":"Mon, 16 Dec 2019 03:05:43 GMT","guid":"https://www.xxlaila.cn/2019/12/16/kube-eventer事件发射器/","category":"kubernetes"},{"title":"master加入node节点","link":"https://www.xxlaila.cn/2019/12/13/master加入node节点/","description":"介绍&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;之前一直没有做k8s集群的时候一直没有master加入为node节点。在使用的时候遇到了很多坑，","pubDate":"Fri, 13 Dec 2019 08:26:22 GMT","guid":"https://www.xxlaila.cn/2019/12/13/master加入node节点/","category":"kubernetes"},{"title":"istio部署错误解决","link":"https://www.xxlaila.cn/2019/12/13/istio部署错误解决/","description":"前言&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在前面的一篇文章中我做了简单的部署，但是在疏忽bookinfo的时候出现了错误。","pubDate":"Fri, 13 Dec 2019 01:31:46 GMT","guid":"https://www.xxlaila.cn/2019/12/13/istio部署错误解决/","category":"kubernetes"},{"title":"alertmanager告警配置","link":"https://www.xxlaila.cn/2019/12/06/alertmanager告警配置/","description":"介绍&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 前篇文章做了kubernetes 的 监控，基于prometheus与grafana部署，监控是做好了，但是还缺乏告警机制，没有告警机制监控就白做了，prometheus的告警就是alertmanager来做。","pubDate":"Fri, 06 Dec 2019 08:46:31 GMT","guid":"https://www.xxlaila.cn/2019/12/06/alertmanager告警配置/","category":"监控"},{"title":"k8s v1.14 prometheus与grafana部署","link":"https://www.xxlaila.cn/2019/12/04/k8s-v1-14-prometheus与grafana部署/","description":"介绍&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;kube-prometheus是读取Metrcs、etcd、api的其中数据。","pubDate":"Wed, 04 Dec 2019 09:55:44 GMT","guid":"https://www.xxlaila.cn/2019/12/04/k8s-v1-14-prometheus与grafana部署/","category":"监控"},{"title":"centos 7 升级内核","link":"https://www.xxlaila.cn/2019/12/03/centos-7-升级内核/","description":"centos 7 升级内核版本查看当前内核版本12345# uname -r3.10.0-693.el7.x86_64# uname -aLinux k8s-master-01-3.kxl 3.10.0-693.el7.x86_64 #1 SMP Tue Aug 22 21:09:27 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux","pubDate":"Tue, 03 Dec 2019 09:01:03 GMT","guid":"https://www.xxlaila.cn/2019/12/03/centos-7-升级内核/","category":"centos"}]}