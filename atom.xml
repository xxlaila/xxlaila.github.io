<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>懒羊羊</title>
  
  <subtitle>xxlila</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://xxlaila.github.io/"/>
  <updated>2019-10-10T09:08:03.948Z</updated>
  <id>https://xxlaila.github.io/</id>
  
  <author>
    <name>xxlaila</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>harbor 使用</title>
    <link href="https://xxlaila.github.io/2019/10/10/harbor-%E4%BD%BF%E7%94%A8/"/>
    <id>https://xxlaila.github.io/2019/10/10/harbor-使用/</id>
    <published>2019-10-10T08:49:41.000Z</published>
    <updated>2019-10-10T09:08:03.948Z</updated>
    
    <content type="html"><![CDATA[<h3 id="harbor使用"><a href="#harbor使用" class="headerlink" title="harbor使用"></a>harbor使用</h3><h4 id="days-2019-10-10"><a href="#days-2019-10-10" class="headerlink" title="days(2019-10-10)"></a>days(2019-10-10)</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;前面文章介绍了harbor的部署，今天第一次学习入门使用。</p><a id="more"></a><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;服务器安装docker以后，我们怎么吧镜像push到我们的私有仓库，和怎么吧镜像pull到本地，首先在服务器上装备docker环境</p><h5 id="连接harbor"><a href="#连接harbor" class="headerlink" title="连接harbor"></a>连接harbor</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># docker login reg.xxlaila.cn</span></span><br><span class="line">Username: admin</span><br><span class="line">Password: </span><br><span class="line">Error response from daemon: Get https://172.21.16.90/v1/users/: dial tcp reg.xxlaila.cn:443: connect: connection refused</span><br></pre></td></tr></table></figure><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这里第一次连接报错，Docker自从1.3.X之后docker registry交互默认使用的是HTTPS，但是我们搭建私有镜像默认使用的是HTTP服务，所以与私有镜像交时出现以上错误。</p><h5 id="解决问题"><a href="#解决问题" class="headerlink" title="解决问题"></a>解决问题</h5><ul><li><p>修改或添加配置</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat /etc/docker/daemon.json </span></span><br><span class="line">&#123;</span><br><span class="line"><span class="string">"insecure-registries"</span> : [<span class="string">"reg.xxlaila.cn"</span>]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>重新启动docker，并重新登录</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># systemctl restart docker</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#  docker login reg.xxlaila.cn</span></span><br><span class="line">Username: admin</span><br><span class="line">Password: </span><br><span class="line">Login Succeeded</span><br></pre></td></tr></table></figure></li></ul><h5 id="Harbor上创建新项目供上传使用"><a href="#Harbor上创建新项目供上传使用" class="headerlink" title="Harbor上创建新项目供上传使用"></a>Harbor上创建新项目供上传使用</h5><p><img src="http://img.xxlaila.cn/1570697850857.jpg" alt="img"></p><h5 id="Docker服务器给镜像打标签"><a href="#Docker服务器给镜像打标签" class="headerlink" title="Docker服务器给镜像打标签"></a>Docker服务器给镜像打标签</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># docker images</span></span><br><span class="line">REPOSITORY                     TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">docker.io/xxlaila/kxl-eureka   v2                  eb8cf7e3f24f        7 months ago        474 MB</span><br><span class="line"></span><br><span class="line"><span class="comment"># docker tag docker.io/xxlaila/kxl-eureka:v2 reg.xxlaila.cn/kxl/kxl-eureka:v2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># docker images</span></span><br><span class="line">REPOSITORY                      TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">docker.io/xxlaila/kxl-eureka    v2                  eb8cf7e3f24f        7 months ago        474 MB</span><br><span class="line">reg.xxlaila.cn/kxl/kxl-eureka   v2                  eb8cf7e3f24f        7 months ago        474 MB</span><br></pre></td></tr></table></figure><h5 id="上传镜像"><a href="#上传镜像" class="headerlink" title="上传镜像"></a>上传镜像</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># docker push reg.xxlaila.cn/kxl/kxl-eureka:v2</span></span><br><span class="line">The push refers to a repository [reg.xxlaila.cn/kxl/kxl-eureka]</span><br><span class="line">f6026bf67b63: Pushed </span><br><span class="line">1489a4b0f1dd: Pushed </span><br><span class="line">2af6e035aa36: Pushed </span><br><span class="line">472cfce4528e: Pushed </span><br><span class="line">071d8bd76517: Pushed </span><br><span class="line">v2: digest: sha256:20d3bc74fdcb2fc4cdfc9066f742c828898c728f7e3f2114498ebe2848b71653 size: 1368</span><br></pre></td></tr></table></figure><p><img src="http://img.xxlaila.cn/1570698233987.jpg" alt="img"></p><h5 id="下载镜像"><a href="#下载镜像" class="headerlink" title="下载镜像"></a>下载镜像</h5><ul><li><p>删除本地镜像</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># docker rmi reg.xxlaila.cn/kxl/kxl-eureka:v2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># docker rmi docker.io/xxlaila/kxl-eureka:v2</span></span><br></pre></td></tr></table></figure></li><li><p>下载harbor上的镜像</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># docker pull reg.xxlaila.cn/kxl/kxl-eureka:v2</span></span><br><span class="line">Trying to pull repository reg.xxlaila.cn/kxl/kxl-eureka ... </span><br><span class="line">v2: Pulling from reg.xxlaila.cn/kxl/kxl-eureka</span><br><span class="line">a02a4930cb5d: Pull complete </span><br><span class="line">6ea3dcbee0db: Extracting [==================================================&gt;]  81.4 MB/81.4 MB</span><br><span class="line">6ea3dcbee0db: Pull complete </span><br><span class="line">c423a7a79cc1: Pull complete </span><br><span class="line">7418081934c1: Pull complete </span><br><span class="line">f89b73853622: Pull complete </span><br><span class="line">Digest: sha256:20d3bc74fdcb2fc4cdfc9066f742c828898c728f7e3f2114498ebe2848b71653</span><br><span class="line">Status: Downloaded newer image <span class="keyword">for</span> reg.xxlaila.cn/kxl/kxl-eureka:v2</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;harbor使用&quot;&gt;&lt;a href=&quot;#harbor使用&quot; class=&quot;headerlink&quot; title=&quot;harbor使用&quot;&gt;&lt;/a&gt;harbor使用&lt;/h3&gt;&lt;h4 id=&quot;days-2019-10-10&quot;&gt;&lt;a href=&quot;#days-2019-10-10&quot; class=&quot;headerlink&quot; title=&quot;days(2019-10-10)&quot;&gt;&lt;/a&gt;days(2019-10-10)&lt;/h4&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;前面文章介绍了harbor的部署，今天第一次学习入门使用。&lt;/p&gt;
    
    </summary>
    
      <category term="kubrnetes" scheme="https://xxlaila.github.io/categories/kubrnetes/"/>
    
    
      <category term="harbor" scheme="https://xxlaila.github.io/tags/harbor/"/>
    
  </entry>
  
  <entry>
    <title>HPA认识</title>
    <link href="https://xxlaila.github.io/2019/10/09/hpa/"/>
    <id>https://xxlaila.github.io/2019/10/09/hpa/</id>
    <published>2019-10-09T07:12:23.000Z</published>
    <updated>2019-10-10T03:16:18.017Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Pod-自动扩缩容"><a href="#Pod-自动扩缩容" class="headerlink" title="Pod 自动扩缩容"></a>Pod 自动扩缩容</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Kubernetes提供了这样一个资源对象: <code>Horizontal Pod Autoscaling</code> Pod水平自动伸缩），简称HPA。HAP通过监控分析RC或者Deployment控制的所有Pod的负载变化情况来确定是否需要调整Pod的副本数量，这是HPA最基本的原理。</p><a id="more"></a><p><img src="http://img.xxlaila.cn/1570605234009.jpg" alt="img"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;HPA在kubernetes集群中被设计成一个Kubernetes API资源和控制器，可以通过kubectl autoscale命令来创建一个HPA资源对象，HPA Controller默认15s轮询一次（可通过kube-controller-manager的标志–horizontal-pod-autoscaler-sync-period进行设置），查询指定的资源（RC或者Deployment）中Pod的资源使用率，并且与创建时设定的值和指标做对比，从而实现自动伸缩的功能。<br><a href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/" target="_blank" rel="noopener">详细介绍</a></p><h3 id="Pod水平自动伸缩练习"><a href="#Pod水平自动伸缩练习" class="headerlink" title="Pod水平自动伸缩练习"></a>Pod水平自动伸缩练习</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由于Horizontal Pod Autoscaler使用此API收集指标，因此需要在群集中部署metrics-server监视以通过资源指标API提供指标,</p><h4 id="运行php-apache服务器"><a href="#运行php-apache服务器" class="headerlink" title="运行php-apache服务器"></a>运行php-apache服务器</h4><p>首先，我们将开始运行该映像的部署，并将其服务公开</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl run php-apache --image=0layfolk0/hpa-example --requests=cpu=200m --limits=cpu=500m --expose --port=80</span><br><span class="line">kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed <span class="keyword">in</span> a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.</span><br><span class="line">service/php-apache created</span><br><span class="line">deployment.apps/php-apache created</span><br></pre></td></tr></table></figure><h4 id="创建水平Pod自动缩放器"><a href="#创建水平Pod自动缩放器" class="headerlink" title="创建水平Pod自动缩放器"></a>创建水平Pod自动缩放器</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当服务运行以后。我们将使用kubectl autoscale创建自动 缩放器。以下命令将创建一个水平Pod自动缩放器，该缩放器将维护由我们在这些说明的第一步中创建的php-apache部署控制的Pod的1至10个副本。粗略地说，HPA将（通过部署）增加或减少副本数，以将所有Pod的平均CPU利用率维持在50％（因为每个pod通过kubectl运行请求200毫核，这意味着平均CPU利用率为100毫-核心）。<a href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#algorithm-details" target="_blank" rel="noopener">算法更多信息</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl autoscale deployment php-apache --cpu-percent=50 --min=1 --max=10</span><br><span class="line">horizontalpodautoscaler.autoscaling/php-apache autoscaled</span><br></pre></td></tr></table></figure><p>我们可以通过运行以下命令检查自动定标器的当前状态:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get hpa</span><br><span class="line">NAME         REFERENCE               TARGETS   MINPODS   MAXPODS   REPLICAS   AGE</span><br><span class="line">php-apache   Deployment/php-apache   0%/50%    1         10        1          14s</span><br></pre></td></tr></table></figure><p><strong>注释</strong>: 由于我们没有向服务器发送任何请求，因此当前CPU消耗为0％（“ CURRENT”列显示了由相应部署控制的所有Pod的平均值）。</p><h4 id="增加压力测试"><a href="#增加压力测试" class="headerlink" title="增加压力测试"></a>增加压力测试</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;现在我们要对<code>php-apache</code>做压力测试来观看自动缩放如何对增加的负载做出反应，我们将启动一个容器，并将无限循环的查询发送到php-apache服务。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl run -i --tty load-generator --image=busybox /bin/sh</span><br><span class="line">kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed <span class="keyword">in</span> a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.</span><br><span class="line">If you don<span class="string">'t see a command prompt, try pressing enter.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">/ # while true; do wget -q -O- http://php-apache.default.svc.cluster.local; done</span></span><br><span class="line"><span class="string">OK!OK!OK!OK!OK!OK!OK!OK!OK!OK!OK!OK!OK!OK!OK!OK!OK!OK!OK!OK!OK!O</span></span><br></pre></td></tr></table></figure><p>在一分钟左右的时间内，我们应该通过执行以下命令来看到更高的CPU负载：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get hpa</span><br><span class="line">NAME         REFERENCE               TARGETS    MINPODS   MAXPODS   REPLICAS   AGE</span><br><span class="line">php-apache   Deployment/php-apache   250%/50%   1         10        1          9m12s</span><br><span class="line"></span><br><span class="line">$ kubectl get deployment php-apache</span><br><span class="line">NAME         READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">php-apache   3/5     5            3           88m</span><br></pre></td></tr></table></figure><p>这里由于网络问题和pull 镜像太慢了，我就直接结束了测试</p><h4 id="停止压力测试"><a href="#停止压力测试" class="headerlink" title="停止压力测试"></a>停止压力测试</h4><p>我们在<code>busybox</code>容器的终端里面执行<code>&lt;Ctrl&gt; + C</code>来结束压力测试，然后我们在观察结果</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$  kubectl get hpa</span><br><span class="line">NAME         REFERENCE               TARGETS   MINPODS   MAXPODS   REPLICAS   AGE</span><br><span class="line">php-apache   Deployment/php-apache   91%/50%   1         10        5          10m</span><br><span class="line"></span><br><span class="line">$ kubectl get deployment php-apache</span><br><span class="line">NAME         READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">php-apache   2/2     2            2           99m</span><br></pre></td></tr></table></figure><p><a href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/" target="_blank" rel="noopener">自动缩放多个指标和自定义指标</a></p><h3 id="nginx-测试"><a href="#nginx-测试" class="headerlink" title="nginx 测试"></a>nginx 测试</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;利用之前<a href="https://xxlaila.github.io/2019/10/09/Deployment%E4%BD%BF%E7%94%A8/">Deployment</a>里面的nginx做测试，我们只需要吧之前的yaml文件稍作修改即可</p><h4 id="修改nginx-deployment-yaml"><a href="#修改nginx-deployment-yaml" class="headerlink" title="修改nginx-deployment.yaml"></a>修改nginx-deployment.yaml</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">$ cat &gt; nginx-deployment.yaml &lt;&lt;EOF</span><br><span class="line">apiVersion: apps/v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-deploy</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: nginx-deploy</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  minReadySeconds: 5</span><br><span class="line">  revisionHistoryLimit: 10</span><br><span class="line">  strategy:</span><br><span class="line">    <span class="built_in">type</span>: RollingUpdate</span><br><span class="line">    rollingUpdate:</span><br><span class="line">      maxSurge: 1</span><br><span class="line">      maxUnavailable: 1</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx-deploy</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: nginx-deploy</span><br><span class="line">        image: nginx:1.13.3</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br><span class="line">        resources:</span><br><span class="line">          requests:</span><br><span class="line">            memory: <span class="string">"200Mi"</span></span><br><span class="line">            cpu: <span class="string">"200m"</span></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h4 id="新建立nginx-deploy-hpa-yaml"><a href="#新建立nginx-deploy-hpa-yaml" class="headerlink" title="新建立nginx-deploy-hpa.yaml"></a>新建立nginx-deploy-hpa.yaml</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">$ cat &gt; nginx-deploy-hpa.yaml &lt;&lt;EOF</span><br><span class="line">apiVersion: autoscaling/v1</span><br><span class="line">kind: HorizontalPodAutoscaler</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-deploy</span><br><span class="line">  namespace: default</span><br><span class="line">spec:</span><br><span class="line">  maxReplicas: 5</span><br><span class="line">  minReplicas: 1</span><br><span class="line">  scaleTargetRef:</span><br><span class="line">    apiVersion: extensions/v1beta1</span><br><span class="line">    kind: Deployment</span><br><span class="line">    name: nginx-deploy</span><br><span class="line">  targetCPUUtilizationPercentage: 10</span><br><span class="line">status:</span><br><span class="line">  currentCPUUtilizationPercentage: 8</span><br><span class="line">  currentReplicas: 1</span><br><span class="line">  desiredReplicas: 0</span><br></pre></td></tr></table></figure><ul><li><p>执行创建</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl apply -f nginx-deployment.yaml</span><br><span class="line">$ kubectl apply -f kubectl apply -f nginx-deploy-hpa.yaml</span><br></pre></td></tr></table></figure></li><li><p>查看验证</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get hpa</span><br><span class="line">NAME           REFERENCE                 TARGETS   MINPODS   MAXPODS   REPLICAS   AGE</span><br><span class="line">nginx-deploy   Deployment/nginx-deploy   0%/10%    1         5         2          45s</span><br><span class="line"></span><br><span class="line">$ kubectl get rs</span><br><span class="line">NAME                        DESIRED   CURRENT   READY   AGE</span><br><span class="line">load-generator-7fbcc7489f   1         1         1       8m28s</span><br><span class="line">nginx-deploy-d494b9564      2         2         2       13m</span><br></pre></td></tr></table></figure></li><li><p>执行压力测试</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">``` bash</span><br><span class="line">$ kubectl run -i --tty load-generator --image=busybox /bin/sh</span><br><span class="line">kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed <span class="keyword">in</span> a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.</span><br><span class="line">If you don<span class="string">'t see a command prompt, try pressing enter.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">/ # while true; do wget -q -O- http://172.30.224.5:80; done</span></span><br></pre></td></tr></table></figure></li><li><p>查看效果</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get hpa</span><br><span class="line">NAME           REFERENCE                 TARGETS   MINPODS   MAXPODS   REPLICAS   AGE</span><br><span class="line">nginx-deploy   Deployment/nginx-deploy   28%/10%   1         5         4          4m48s</span><br><span class="line"></span><br><span class="line">$ kubectl get rs</span><br><span class="line">NAME                        DESIRED   CURRENT   READY   AGE</span><br><span class="line">load-generator-7fbcc7489f   1         1         1       12m</span><br><span class="line">nginx-deploy-d494b9564      5         5         5       18m</span><br><span class="line"></span><br><span class="line">$ kubectl get hpa</span><br><span class="line">NAME           REFERENCE                 TARGETS   MINPODS   MAXPODS   REPLICAS   AGE</span><br><span class="line">nginx-deploy   Deployment/nginx-deploy   16%/10%   1         5         5          5m39s</span><br></pre></td></tr></table></figure></li><li><p>结束压测<br>等待一会查看结果</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get hpa</span><br><span class="line">NAME           REFERENCE                 TARGETS   MINPODS   MAXPODS   REPLICAS   AGE</span><br><span class="line">nginx-deploy   Deployment/nginx-deploy   0%/10%    1         5         1          12m</span><br><span class="line"></span><br><span class="line">$ kubectl get rs</span><br><span class="line">NAME                        DESIRED   CURRENT   READY   AGE</span><br><span class="line">load-generator-7fbcc7489f   1         1         1       19m</span><br><span class="line">nginx-deploy-d494b9564      1         1         1       25m</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Pod-自动扩缩容&quot;&gt;&lt;a href=&quot;#Pod-自动扩缩容&quot; class=&quot;headerlink&quot; title=&quot;Pod 自动扩缩容&quot;&gt;&lt;/a&gt;Pod 自动扩缩容&lt;/h3&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Kubernetes提供了这样一个资源对象: &lt;code&gt;Horizontal Pod Autoscaling&lt;/code&gt; Pod水平自动伸缩），简称HPA。HAP通过监控分析RC或者Deployment控制的所有Pod的负载变化情况来确定是否需要调整Pod的副本数量，这是HPA最基本的原理。&lt;/p&gt;
    
    </summary>
    
      <category term="kubernetes" scheme="https://xxlaila.github.io/categories/kubernetes/"/>
    
    
      <category term="hpa" scheme="https://xxlaila.github.io/tags/hpa/"/>
    
  </entry>
  
  <entry>
    <title>Deployment使用</title>
    <link href="https://xxlaila.github.io/2019/10/09/Deployment%E4%BD%BF%E7%94%A8/"/>
    <id>https://xxlaila.github.io/2019/10/09/Deployment使用/</id>
    <published>2019-10-09T01:59:08.000Z</published>
    <updated>2019-10-09T07:10:56.403Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Deployment和rc的对比"><a href="#Deployment和rc的对比" class="headerlink" title="Deployment和rc的对比"></a>Deployment和rc的对比</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;首先RC是Kubernetes的一个核心概念，当我们把应用部署到集群之后，需要保证应用能够持续稳定的运行，RC就是这个保证的关键，主要功能如:</p><ul><li>确保Pod数量: 它会确保Kubernetes中有指定数量的Pod在运行，如果少于指定数量的Pod，RC就会创建新的，反之这会删除多余的，保证Pod的副本数量不变。</li><li>确保Pod健康: 当Pod不健康，比如运行出错了，总之无法提供正常服务时，RC也会杀死不健康的Pod，重新创建新的。</li><li>弹性伸缩: 在业务高峰或者低峰的时候，可以用过RC来动态的调整Pod数量来提供资源的利用率，当然我们也提到过如果使用HPA这种资源对象的话可以做到自动伸缩。</li><li>滚动升级: 滚动升级是一种平滑的升级方式，通过逐步替换的策略，保证整体系统的稳定性</li></ul><a id="more"></a><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Deployment同样也是Kubernetes系统的一个核心概念，主要职责和RC一样的都是保证Pod的数量和健康，二者大部分功能都是完全一致的，我们可以看成是一个升级版的RC控制器，Deployment具备的新特性</p><ul><li>RC的全部功能: Deployment具备上面描述的RC的全部功能</li><li>事件和状态查看: 可以查看Deployment的升级详细进度和状态</li><li>回滚: 当升级Pod的时候如果出现问题，可以使用回滚操作回滚到之前的任一版本</li><li>版本记录: 每一次对Deployment的操作，都能够保存下来，这也是保证可以回滚到任一版本的基础</li><li>暂停和启动: 对于每一次升级都能够随时暂停和启动</li></ul><p><strong>对比</strong>: Deployment作为新一代的RC，在功能上更为丰富，同时官方也是推荐使用Deployment来管理Pod，比如一些官方组件kube-dns、kube-proxy也都是使用的Deployment来管理的，所以最好使用Deployment来管理Pod。</p><h3 id="Deployment-介绍"><a href="#Deployment-介绍" class="headerlink" title="Deployment 介绍"></a>Deployment 介绍</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Deployment拥有多个Replica Set，而一个Replica Set拥有一个或多个Pod。一个Deployment控制多个rs主要是为了支持回滚机制，每当Deployment操作时，Kubernetes会重新生成一个Replica Set并保留，以后有需要的话就可以回滚至之前的状态。</p><p><strong>实例</strong>: 创建一个Deployment，它创建了一个Replica Set来启动3个nginx pod，yaml文件如下:</p><ul><li><p>nginx-deployment.yaml</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">$ cat &gt; nginx-deployment.yaml &lt;&lt;EOF</span><br><span class="line">apiVersion: apps/v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-deploy</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: nginx-demo</span><br><span class="line">spec:</span><br><span class="line">  replicas: 3</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: nginx</span><br><span class="line">        image: nginx:1.7.9</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></li><li><p>执行创建</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl create -f nginx-deployment.yaml</span><br><span class="line">deployment.apps/nginx-deploy created</span><br></pre></td></tr></table></figure></li><li><p>执行一下命令查看刚刚创建的Deployment</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get deployments</span><br><span class="line">NAME           READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">nginx-deploy   0/3     3            0           12s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 再次执行上面命令</span></span><br><span class="line">$ kubectl get deployments</span><br><span class="line">NAME           READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">nginx-deploy   1/3     3            1           35s</span><br></pre></td></tr></table></figure></li><li><p>可以看到Deployment已经创建了1个Replica Set了，执行下面的命令查看rs和pod</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get rs</span><br><span class="line">NAME                     DESIRED   CURRENT   READY   AGE</span><br><span class="line">nginx-deploy-6dd86d77d   3         3         2       70s</span><br><span class="line"></span><br><span class="line"><span class="comment"># </span></span><br><span class="line">$ kubectl get pod --show-labels</span><br><span class="line">NAME                           READY   STATUS              RESTARTS   AGE   LABELS</span><br><span class="line">nginx-deploy-6dd86d77d-9n9vf   1/1     Running             0          99s   app=nginx,pod-template-hash=6dd86d77d</span><br><span class="line">nginx-deploy-6dd86d77d-bhrsk   0/1     ContainerCreating   0          99s   app=nginx,pod-template-hash=6dd86d77d</span><br><span class="line">nginx-deploy-6dd86d77d-jdnrh   1/1     Running             0          99s   app=nginx,pod-template-hash=6dd86d77d</span><br></pre></td></tr></table></figure></li></ul><p>上面的Deployment的yaml文件中的replicas:3将会保证我们始终有3个POD在运行。</p><h3 id="滚动升级"><a href="#滚动升级" class="headerlink" title="滚动升级"></a>滚动升级</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;修改之前使用的nginx-deployment.yaml文件中的nginx镜像修改为nginx:1.13.3，然后在spec下面添加滚动升级策略：</p><ul><li><p>nginx-deploments.yml</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps/v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-deploy</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: nginx-demo</span><br><span class="line">spec:</span><br><span class="line">  replicas: 3</span><br><span class="line">  minReadySeconds: 5</span><br><span class="line">  strategy:</span><br><span class="line">    <span class="built_in">type</span>: RollingUpdate</span><br><span class="line">    rollingUpdate:</span><br><span class="line">      maxSurge: 1</span><br><span class="line">      maxUnavailable: 1</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: nginx</span><br><span class="line">        image: nginx:1.13.3</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br></pre></td></tr></table></figure></li><li><p>minReadySeconds:</p><ul><li>滚动升级时5s后认为该pod就绪</li><li>如果没有设置该值，Kubernetes会假设该容器启动起来后就提供服务了</li><li>如果没有设置该值，在某些极端情况下可能会造成服务不正常运行</li></ul></li><li><p>rollingUpdate:</p><ul><li>于replicas为3,则整个升级,pod个数在2-4个之间</li></ul></li><li><p>maxSurge:</p><ul><li>升级过程中最多可以比原先设置多出的POD数量</li><li>例如：maxSurage=1，replicas=3,则表示Kubernetes会先启动1一个新的Pod后才删掉一个旧的POD，整个升级过程中最多会有3+1个POD。</li></ul></li><li><p>maxUnavaible:</p><ul><li>升级过程中最多有多少个POD处于无法提供服务的状态</li><li>当maxSurge不为0时，该值也不能为0</li><li>例如：maxUnavaible=1，则表示Kubernetes整个升级过程中最多会有1个POD处于无法服务的状态。</li></ul></li><li><p>执行创建</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl apply -f nginx-deployment.yaml</span><br><span class="line">deployment.apps/nginx-deploy configured</span><br></pre></td></tr></table></figure></li><li><p>查看状态</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用rollout命令</span></span><br><span class="line">$ kubectl rollout status deployment/nginx-deploy</span><br><span class="line">Waiting <span class="keyword">for</span> deployment <span class="string">"nginx-deploy"</span> rollout to finish: 2 out of 3 new replicas have been updated...</span><br><span class="line"></span><br><span class="line"><span class="comment"># 暂停升级</span></span><br><span class="line">$ kubectl rollout pause deployment deployment/nginx-deploy</span><br><span class="line"></span><br><span class="line"><span class="comment"># 继续升级</span></span><br><span class="line">$ kubectl rollout resume deployment deployment/nginx-deploy</span><br></pre></td></tr></table></figure></li></ul><p>升级结束后，继续查看rs的状态</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get rs</span><br><span class="line">NAME                      DESIRED   CURRENT   READY   AGE</span><br><span class="line">nginx-deploy-6dd86d77d    0         0         0       21m</span><br><span class="line">nginx-deploy-799d666985   3         3         3       10m</span><br></pre></td></tr></table></figure><p>根据AGE我们可以看到离我们最近的当前状态是：3，和我们的yaml文件是一致的，证明升级成功了。用describe命令可以查看升级的全部信息:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl describe deploy nginx-deploy</span><br><span class="line">Name:                   nginx-deploy</span><br><span class="line">Namespace:              default</span><br><span class="line">CreationTimestamp:      Wed, 09 Oct 2019 10:12:56 +0800</span><br><span class="line">Labels:                 k8s-app=nginx-demo</span><br><span class="line">Annotations:            deployment.kubernetes.io/revision: 2</span><br><span class="line">                        kubectl.kubernetes.io/last-applied-configuration:</span><br><span class="line">                          &#123;<span class="string">"apiVersion"</span>:<span class="string">"apps/v1beta1"</span>,<span class="string">"kind"</span>:<span class="string">"Deployment"</span>,<span class="string">"metadata"</span>:&#123;<span class="string">"annotations"</span>:&#123;&#125;,<span class="string">"labels"</span>:&#123;<span class="string">"k8s-app"</span>:<span class="string">"nginx-demo"</span>&#125;,<span class="string">"name"</span>:<span class="string">"nginx-deploy"</span>,<span class="string">"nam...</span></span><br><span class="line"><span class="string">Selector:               app=nginx</span></span><br><span class="line"><span class="string">Replicas:               3 desired | 3 updated | 3 total | 3 available | 0 unavailable</span></span><br><span class="line"><span class="string">StrategyType:           RollingUpdate</span></span><br><span class="line"><span class="string">MinReadySeconds:        5</span></span><br><span class="line"><span class="string">RollingUpdateStrategy:  1 max unavailable, 1 max surge</span></span><br><span class="line"><span class="string">Pod Template:</span></span><br><span class="line"><span class="string">  Labels:  app=nginx</span></span><br><span class="line"><span class="string">  Containers:</span></span><br><span class="line"><span class="string">   nginx:</span></span><br><span class="line"><span class="string">    Image:        nginx:1.13.3</span></span><br><span class="line"><span class="string">    Port:         80/TCP</span></span><br><span class="line"><span class="string">    Host Port:    0/TCP</span></span><br><span class="line"><span class="string">    Environment:  &lt;none&gt;</span></span><br><span class="line"><span class="string">    Mounts:       &lt;none&gt;</span></span><br><span class="line"><span class="string">  Volumes:        &lt;none&gt;</span></span><br><span class="line"><span class="string">Conditions:</span></span><br><span class="line"><span class="string">  Type           Status  Reason</span></span><br><span class="line"><span class="string">  ----           ------  ------</span></span><br><span class="line"><span class="string">  Available      True    MinimumReplicasAvailable</span></span><br><span class="line"><span class="string">  Progressing    True    NewReplicaSetAvailable</span></span><br><span class="line"><span class="string">OldReplicaSets:  &lt;none&gt;</span></span><br><span class="line"><span class="string">NewReplicaSet:   nginx-deploy-799d666985 (3/3 replicas created)</span></span><br><span class="line"><span class="string">Events:</span></span><br><span class="line"><span class="string">  Type    Reason             Age   From                   Message</span></span><br><span class="line"><span class="string">  ----    ------             ----  ----                   -------</span></span><br><span class="line"><span class="string">  Normal  ScalingReplicaSet  23m   deployment-controller  Scaled up replica set nginx-deploy-6dd86d77d to 3</span></span><br><span class="line"><span class="string">  Normal  ScalingReplicaSet  12m   deployment-controller  Scaled up replica set nginx-deploy-799d666985 to 1</span></span><br><span class="line"><span class="string">  Normal  ScalingReplicaSet  12m   deployment-controller  Scaled down replica set nginx-deploy-6dd86d77d to 2</span></span><br><span class="line"><span class="string">  Normal  ScalingReplicaSet  12m   deployment-controller  Scaled up replica set nginx-deploy-799d666985 to 2</span></span><br><span class="line"><span class="string">  Normal  ScalingReplicaSet  11m   deployment-controller  Scaled down replica set nginx-deploy-6dd86d77d to 1</span></span><br><span class="line"><span class="string">  Normal  ScalingReplicaSet  11m   deployment-controller  Scaled up replica set nginx-deploy-799d666985 to 3</span></span><br><span class="line"><span class="string">  Normal  ScalingReplicaSet  10m   deployment-controller  Scaled down replica set nginx-deploy-6dd86d77d to 0</span></span><br></pre></td></tr></table></figure><h3 id="回滚Deployment"><a href="#回滚Deployment" class="headerlink" title="回滚Deployment"></a>回滚Deployment</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;前面已经滚动平滑的升级Deployment，但是如果升级后的POD出了问题该怎么办？我们能够想到的最好最快的方式当然是回退到上一次能够提供正常工作的版本，Deployment就为我们提供了回滚机制。</p><ul><li>首先，查看Deployment的升级历史:<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl rollout <span class="built_in">history</span> deployment nginx-deploy</span><br><span class="line">deployment.extensions/nginx-deploy </span><br><span class="line">REVISION  CHANGE-CAUSE</span><br><span class="line">1         &lt;none&gt;</span><br><span class="line">2         &lt;none&gt;</span><br></pre></td></tr></table></figure></li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从上面的结果可以看出在执行Deployment升级的时候最好带上record参数，便于我们查看历史版本信息。<code>kubectl apply --filename=nginx-deployment.yaml --record=true</code><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;默认情况下，所有通过kubectl xxxx –record都会被kubernetes记录到etcd进行持久化，这无疑会占用资源，最重要的是，时间久了，当你kubectl get rs时，会有成百上千的垃圾RS返回，这对于运维来说维护很不便利，<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当我们在上生产时，我们最好通过设置Deployment的.spec.revisionHistoryLimit来限制最大保留的revision number，比如15个版本，回滚的时候一般只会回滚到最近的几个版本就足够了。其实rollout history中记录的revision都和ReplicaSets一一对应。如果手动delete某个ReplicaSet，对应的rollout history就会被删除，也就是还说你无法回滚到这个revison。rollout history和ReplicaSet的对应关系，可以在kubectl describe rs $RSNAME返回的revision字段中得到，这里的revision就对应着rollout history返回的revison。</p><ul><li><p>yaml例子</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">$ cat nginx-deployment.yaml </span><br><span class="line">apiVersion: apps/v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-deploy</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: nginx-demo</span><br><span class="line">spec:</span><br><span class="line">  replicas: 3</span><br><span class="line">  minReadySeconds: 5</span><br><span class="line">  revisionHistoryLimit: 10</span><br><span class="line">  strategy:</span><br><span class="line">    <span class="built_in">type</span>: RollingUpdate</span><br><span class="line">    rollingUpdate:</span><br><span class="line">      maxSurge: 1</span><br><span class="line">      maxUnavailable: 1</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: nginx</span><br><span class="line">        image: nginx:1.13.3</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br></pre></td></tr></table></figure></li><li><p>可以使用下面的命令查看单个revison的信息</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl rollout <span class="built_in">history</span> deployment nginx-deploy --revision=2</span><br><span class="line">deployment.extensions/nginx-deploy with revision <span class="comment">#2</span></span><br><span class="line">Pod Template:</span><br><span class="line">  Labels:app=nginx</span><br><span class="line">pod-template-hash=799d666985</span><br><span class="line">  Annotations:kubernetes.io/change-cause: kubectl apply --filename=nginx-deployment.yaml --record=<span class="literal">true</span></span><br><span class="line">  Containers:</span><br><span class="line">   nginx:</span><br><span class="line">    Image:nginx:1.13.3</span><br><span class="line">    Port:80/TCP</span><br><span class="line">    Host Port:0/TCP</span><br><span class="line">    Environment:&lt;none&gt;</span><br><span class="line">    Mounts:&lt;none&gt;</span><br><span class="line">  Volumes:&lt;none&gt;</span><br></pre></td></tr></table></figure></li><li><p>直接回退到当前版本的前一个版本：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl rollout undo deployment nginx-deploy</span><br><span class="line">deployment.extensions/nginx-deploy rolled back</span><br><span class="line"></span><br><span class="line"><span class="comment"># 也可以用revision回退到指定的版本</span></span><br><span class="line">$ kubectl rollout undo deployment nginx-deploy --to-revision=1</span><br><span class="line">deployment.extensions/nginx-deploy rolled back</span><br></pre></td></tr></table></figure></li><li><p>查看Deployment现在的状态</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get deployments</span><br><span class="line">NAME           READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">nginx-deploy   2/3     3            2           56m</span><br><span class="line"></span><br><span class="line">$ kubectl get rs</span><br><span class="line">NAME                      DESIRED   CURRENT   READY   AGE</span><br><span class="line">nginx-deploy-6dd86d77d    1         1         1       56m</span><br><span class="line">nginx-deploy-799d666985   3         3         1       46m</span><br><span class="line"></span><br><span class="line">$ kubectl rollout status deployment/nginx-deploy</span><br><span class="line">Waiting <span class="keyword">for</span> deployment <span class="string">"nginx-deploy"</span> rollout to finish: 2 of 3 updated replicas are available...</span><br><span class="line">Waiting <span class="keyword">for</span> deployment <span class="string">"nginx-deploy"</span> rollout to finish: 2 of 3 updated replicas are available...</span><br><span class="line">deployment <span class="string">"nginx-deploy"</span> successfully rolled out</span><br><span class="line"></span><br><span class="line"><span class="comment"># 完成后查看</span></span><br><span class="line">$ kubectl get rs</span><br><span class="line">NAME                      DESIRED   CURRENT   READY   AGE</span><br><span class="line">nginx-deploy-6dd86d77d    0         0         0       57m</span><br><span class="line">nginx-deploy-799d666985   3         3         3       47m</span><br></pre></td></tr></table></figure></li></ul><p><a href="https://kubernetes.io/docs/concepts/workloads/controllers/deployment/" target="_blank" rel="noopener">官方参考</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Deployment和rc的对比&quot;&gt;&lt;a href=&quot;#Deployment和rc的对比&quot; class=&quot;headerlink&quot; title=&quot;Deployment和rc的对比&quot;&gt;&lt;/a&gt;Deployment和rc的对比&lt;/h3&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;首先RC是Kubernetes的一个核心概念，当我们把应用部署到集群之后，需要保证应用能够持续稳定的运行，RC就是这个保证的关键，主要功能如:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;确保Pod数量: 它会确保Kubernetes中有指定数量的Pod在运行，如果少于指定数量的Pod，RC就会创建新的，反之这会删除多余的，保证Pod的副本数量不变。&lt;/li&gt;
&lt;li&gt;确保Pod健康: 当Pod不健康，比如运行出错了，总之无法提供正常服务时，RC也会杀死不健康的Pod，重新创建新的。&lt;/li&gt;
&lt;li&gt;弹性伸缩: 在业务高峰或者低峰的时候，可以用过RC来动态的调整Pod数量来提供资源的利用率，当然我们也提到过如果使用HPA这种资源对象的话可以做到自动伸缩。&lt;/li&gt;
&lt;li&gt;滚动升级: 滚动升级是一种平滑的升级方式，通过逐步替换的策略，保证整体系统的稳定性&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="kubernetes" scheme="https://xxlaila.github.io/categories/kubernetes/"/>
    
    
      <category term="Deployment" scheme="https://xxlaila.github.io/tags/Deployment/"/>
    
  </entry>
  
  <entry>
    <title>harbor私有仓库部署</title>
    <link href="https://xxlaila.github.io/2019/09/30/harbor%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93%E9%83%A8%E7%BD%B2/"/>
    <id>https://xxlaila.github.io/2019/09/30/harbor私有仓库部署/</id>
    <published>2019-09-30T06:55:28.000Z</published>
    <updated>2019-10-09T02:04:42.303Z</updated>
    
    <content type="html"><![CDATA[<h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Harbor是一个用于存储和分发Docker镜像的企业级Registry服务器，通过添加一些企业必需的功能特性，例如安全、标识和管理等，扩展了开源Docker Distribution。作为一个企业级私有Registry服务器，Harbor提供了更好的性能和安全。提升用户使用Registry构建和运行环境传输镜像的效率。Harbor支持安装在多个Registry节点的镜像资源复制，镜像全部保存在私有Registry中， 确保数据和知识产权在公司内部网络中管控。另外，Harbor也提供了高级的安全特性，诸如用户管理，访问控制和活动审计等。</p><a id="more"></a><h3 id="部署环境准备"><a href="#部署环境准备" class="headerlink" title="部署环境准备"></a>部署环境准备</h3><h4 id="服务器配置"><a href="#服务器配置" class="headerlink" title="服务器配置"></a>服务器配置</h4><table><thead><tr><th>系统</th><th>配置</th><th>ip</th></tr></thead><tbody><tr><td>centos 7.4</td><td>4/8G/200G</td><td>172.21.16.90</td></tr></tbody></table><h4 id="下载所需文件"><a href="#下载所需文件" class="headerlink" title="下载所需文件"></a>下载所需文件</h4><h5 id="docker-compose-下载"><a href="#docker-compose-下载" class="headerlink" title="docker-compose 下载"></a>docker-compose 下载</h5><p>docker compose <a href="https://github.com/docker/compose/releases" target="_blank" rel="noopener">发布页面</a>下载最新的 docker-compose 二进制文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># wget https://github.com/docker/compose/releases/download/1.24.1/docker-compose-Linux-x86_64</span></span><br><span class="line"><span class="comment"># mv ~/docker-compose-Linux-x86_64 /usr/bin/docker-compose </span></span><br><span class="line"><span class="comment"># chmod a+x  /ur/bin/docker-compose</span></span><br></pre></td></tr></table></figure><ul><li>官方的安装<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># curl -L https://github.com/docker/compose/releases/download/1.24.1/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose</span></span><br><span class="line"><span class="comment"># chmod +x /usr/local/bin/docker-compose</span></span><br></pre></td></tr></table></figure></li></ul><h5 id="harbor-下载"><a href="#harbor-下载" class="headerlink" title="harbor 下载"></a>harbor 下载</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;harbor 安装方式有两种，一种是在线安装，一种是离线安装，这里由于网络不好，使用的是离线安装，harbor<a href="https://github.com/goharbor/harbor/releases" target="_blank" rel="noopener">发布页面</a>下载最新的 harbor 离线安装包</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># wget https://storage.googleapis.com/harbor-releases/release-1.9.0/harbor-offline-installer-v1.9.0.tgz</span></span><br><span class="line"><span class="comment"># tar -zxvf harbor-offline-installer-v1.9.0.tgz</span></span><br><span class="line"><span class="comment">#</span></span><br></pre></td></tr></table></figure><h3 id="开始安装"><a href="#开始安装" class="headerlink" title="开始安装"></a>开始安装</h3><h4 id="docker-安装"><a href="#docker-安装" class="headerlink" title="docker 安装"></a>docker 安装</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># yum-config-manager   --add-repo   https://download.docker.com/linux/centos/docker-ce.repo</span></span><br><span class="line"><span class="comment"># sudo yum -y install docker-ce-18.09.6-3.el7.x86_64</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># cat /etc/sysctl.d/k8s.conf &lt;&lt;EOF</span></span><br><span class="line">net.bridge.bridge-nf-call-ip6tables: 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables: 1</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="comment"># sysctl -p /etc/sysctl.d/k8s.conf</span></span><br><span class="line"><span class="comment"># systemctl  start docker</span></span><br></pre></td></tr></table></figure><p><strong>注意</strong>: 不添加<code>/etc/sysctl.d/k8s.conf</code> 启动docker会提示<code>WARNING: bridge-nf-call-iptables is disabled  WARNING: bridge-nf-call-ip6tables is disabled</code></p><h4 id="导入-docker-images"><a href="#导入-docker-images" class="headerlink" title="导入 docker images"></a>导入 docker images</h4><p>导入离线安装包中harbor相关的 docker images：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cd harbor</span></span><br><span class="line"><span class="comment"># docker load -i harbor.v1.9.0.tar.gz </span></span><br><span class="line"><span class="comment"># docker images</span></span><br><span class="line">REPOSITORY                      TAG                        IMAGE ID            CREATED             SIZE</span><br><span class="line">goharbor/chartmuseum-photon     v0.9.0-v1.9.0              00c12627cbd7        2 weeks ago         131MB</span><br><span class="line">goharbor/harbor-migrator        v1.9.0                     75d4de5e0f16        2 weeks ago         362MB</span><br><span class="line">goharbor/redis-photon           v1.9.0                     3249afaa9965        2 weeks ago         109MB</span><br><span class="line">goharbor/clair-photon           v2.0.9-v1.9.0              e54ad567c58f        2 weeks ago         165MB</span><br><span class="line">goharbor/notary-server-photon   v0.6.1-v1.9.0              2cdecba59f38        2 weeks ago         138MB</span><br><span class="line">goharbor/notary-signer-photon   v0.6.1-v1.9.0              973378593def        2 weeks ago         135MB</span><br><span class="line">goharbor/harbor-registryctl     v1.9.0                     30a01bf0f4df        2 weeks ago         99.6MB</span><br><span class="line">goharbor/registry-photon        v2.7.1-patch-2819-v1.9.0   32571099a9fe        2 weeks ago         82.3MB</span><br><span class="line">goharbor/nginx-photon           v1.9.0                     f933d62f9952        2 weeks ago         43.9MB</span><br><span class="line">goharbor/harbor-log             v1.9.0                     28e27d511335        2 weeks ago         82.6MB</span><br><span class="line">goharbor/harbor-jobservice      v1.9.0                     f3cd0b181a89        2 weeks ago         141MB</span><br><span class="line">goharbor/harbor-core            v1.9.0                     f2814ed8aadd        2 weeks ago         155MB</span><br><span class="line">goharbor/harbor-portal          v1.9.0                     0778d4c5d27e        2 weeks ago         51.3MB</span><br><span class="line">goharbor/harbor-db              v1.9.0                     a809e14d2d49        2 weeks ago         147MB</span><br><span class="line">goharbor/prepare                v1.9.0                     aa594772c1e8        2 weeks ago         147MB</span><br></pre></td></tr></table></figure><h4 id="修改-harbor-yml-文件"><a href="#修改-harbor-yml-文件" class="headerlink" title="修改 harbor.yml 文件"></a>修改 harbor.yml 文件</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># vim harbor.yml</span></span><br><span class="line">hostname: reg.xxlaila.cn</span><br><span class="line"></span><br><span class="line"><span class="comment"># email configure</span></span><br><span class="line">email_server: smtp.exmail.qq.com</span><br><span class="line">email_server_port: 465</span><br><span class="line">email_username: admin@xxlaila.cn</span><br><span class="line">email_password: 123</span><br><span class="line">email_from: admin&lt;admin@xxlaila.cn&gt;</span><br><span class="line">email_ssl: <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># User registration is prohibited</span></span><br><span class="line">self_registration: off</span><br><span class="line"></span><br><span class="line"><span class="comment"># LDAP authentication configuration item</span></span><br><span class="line"><span class="comment">#ldap_url: ldaps://ldap.xxlaila.cn</span></span><br><span class="line"><span class="comment">#ldap_searchdn: uid=username,ou=people,dc=xxlaila,dc=com</span></span><br><span class="line"><span class="comment">#ldap_search_pwd: password</span></span><br><span class="line"><span class="comment">#ldap_basedn: ou=people,dc=xxlaila,dc=com</span></span><br><span class="line"><span class="comment">#ldap_filter: (objectClass=person)</span></span><br><span class="line"><span class="comment">#ldap_uid: uid </span></span><br><span class="line"><span class="comment">#ldap_scope: 3 </span></span><br><span class="line"><span class="comment">#ldap_timeout: 5</span></span><br></pre></td></tr></table></figure><h4 id="加载和启动-harbor-镜像"><a href="#加载和启动-harbor-镜像" class="headerlink" title="加载和启动 harbor 镜像"></a>加载和启动 harbor 镜像</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># mkdir /data</span></span><br><span class="line"><span class="comment"># chmod 777 /var/run/docker.sock /data</span></span><br><span class="line"><span class="comment"># ./install.sh </span></span><br><span class="line"></span><br><span class="line">[Step 0]: checking installation environment ...</span><br><span class="line"></span><br><span class="line">Note: docker version: 19.03.2</span><br><span class="line"></span><br><span class="line">Note: docker-compose version: 1.24.1</span><br><span class="line"></span><br><span class="line">[Step 1]: loading Harbor images ...</span><br><span class="line">Loaded image: goharbor/harbor-portal:v1.9.0</span><br><span class="line">Loaded image: goharbor/harbor-core:v1.9.0</span><br><span class="line">Loaded image: goharbor/nginx-photon:v1.9.0</span><br><span class="line">Loaded image: goharbor/notary-signer-photon:v0.6.1-v1.9.0</span><br><span class="line">Loaded image: goharbor/registry-photon:v2.7.1-patch-2819-v1.9.0</span><br><span class="line">Loaded image: goharbor/harbor-migrator:v1.9.0</span><br><span class="line">Loaded image: goharbor/chartmuseum-photon:v0.9.0-v1.9.0</span><br><span class="line">Loaded image: goharbor/prepare:v1.9.0</span><br><span class="line">Loaded image: goharbor/harbor-log:v1.9.0</span><br><span class="line">Loaded image: goharbor/harbor-db:v1.9.0</span><br><span class="line">Loaded image: goharbor/clair-photon:v2.0.9-v1.9.0</span><br><span class="line">Loaded image: goharbor/harbor-jobservice:v1.9.0</span><br><span class="line">Loaded image: goharbor/harbor-registryctl:v1.9.0</span><br><span class="line">Loaded image: goharbor/redis-photon:v1.9.0</span><br><span class="line">Loaded image: goharbor/notary-server-photon:v0.6.1-v1.9.0</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[Step 2]: preparing environment ...</span><br><span class="line">prepare base dir is <span class="built_in">set</span> to /opt/harbor</span><br><span class="line">Clearing the configuration file: /config/<span class="built_in">log</span>/logrotate.conf</span><br><span class="line">Clearing the configuration file: /config/<span class="built_in">log</span>/rsyslog_docker.conf</span><br><span class="line">Generated configuration file: /config/<span class="built_in">log</span>/logrotate.conf</span><br><span class="line">Generated configuration file: /config/<span class="built_in">log</span>/rsyslog_docker.conf</span><br><span class="line">Generated configuration file: /config/nginx/nginx.conf</span><br><span class="line">Generated configuration file: /config/core/env</span><br><span class="line">Generated configuration file: /config/core/app.conf</span><br><span class="line">Generated configuration file: /config/registry/config.yml</span><br><span class="line">Generated configuration file: /config/registryctl/env</span><br><span class="line">Generated configuration file: /config/db/env</span><br><span class="line">Generated configuration file: /config/jobservice/env</span><br><span class="line">Generated configuration file: /config/jobservice/config.yml</span><br><span class="line">Generated and saved secret to file: /secret/keys/secretkey</span><br><span class="line">Generated certificate, key file: /secret/core/private_key.pem, cert file: /secret/registry/root.crt</span><br><span class="line">Generated configuration file: /compose_location/docker-compose.yml</span><br><span class="line">Clean up the input dir</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[Step 3]: starting Harbor ...</span><br><span class="line">Creating network <span class="string">"harbor_harbor"</span> with the default driver</span><br><span class="line">Creating harbor-log ... <span class="keyword">done</span></span><br><span class="line">Creating registryctl   ... <span class="keyword">done</span></span><br><span class="line">Creating redis         ... <span class="keyword">done</span></span><br><span class="line">Creating harbor-portal ... <span class="keyword">done</span></span><br><span class="line">Creating harbor-db     ... <span class="keyword">done</span></span><br><span class="line">Creating registry      ... <span class="keyword">done</span></span><br><span class="line">Creating harbor-core   ... <span class="keyword">done</span></span><br><span class="line">Creating nginx             ... <span class="keyword">done</span></span><br><span class="line">Creating harbor-jobservice ... <span class="keyword">done</span></span><br><span class="line"></span><br><span class="line">✔ ----Harbor has been installed and started successfully.----</span><br><span class="line"></span><br><span class="line">Now you should be able to visit the admin portal at http://reg.xxlaila.cn. </span><br><span class="line">For more details, please visit https://github.com/goharbor/harbor .</span><br></pre></td></tr></table></figure><h4 id="访问管理界面"><a href="#访问管理界面" class="headerlink" title="访问管理界面"></a>访问管理界面</h4><p>确认所有组件都工作正常：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># docker-compose  ps</span></span><br><span class="line">      Name                     Command                       State                     Ports          </span><br><span class="line">------------------------------------------------------------------------------------------------------</span><br><span class="line">harbor-core         /harbor/harbor_core              Up (healthy)                                     </span><br><span class="line">harbor-db           /docker-entrypoint.sh            Up (healthy)            5432/tcp                 </span><br><span class="line">harbor-jobservice   /harbor/harbor_jobservice  ...   Up (health: starting)                            </span><br><span class="line">harbor-log          /bin/sh -c /usr/<span class="built_in">local</span>/bin/ ...   Up (healthy)            127.0.0.1:1514-&gt;10514/tcp</span><br><span class="line">harbor-portal       nginx -g daemon off;             Up (healthy)            8080/tcp                 </span><br><span class="line">nginx               nginx -g daemon off;             Up (healthy)            0.0.0.0:80-&gt;8080/tcp     </span><br><span class="line">redis               redis-server /etc/redis.conf     Up (healthy)            6379/tcp                 </span><br><span class="line">registry            /entrypoint.sh /etc/regist ...   Up (healthy)            5000/tcp                 </span><br><span class="line">registryctl         /harbor/start.sh                 Up (healthy)</span><br></pre></td></tr></table></figure><p>在浏览器访问<a href="http://reg.xxlaila.cn，" target="_blank" rel="noopener">http://reg.xxlaila.cn，</a> 用账号 admin 和 harbor.yml 配置文件中的默认密码 Harbor12345 登陆系统<br><img src="http://img.xxlaila.cn/8095d05-b9b7-4bdc-b0fc-7810db649e23.png" alt="img"><br><img src="http://img.xxlaila.cn/4bfab8be-e5de-4165-9268-fa591c5f12f8.png" alt="img"></p><h4 id="harbor-运行时产生的文件、目录"><a href="#harbor-运行时产生的文件、目录" class="headerlink" title="harbor 运行时产生的文件、目录"></a>harbor 运行时产生的文件、目录</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;harbor 将日志打印到 /var/log/harbor 的相关目录下，传统的docker logs XXX 或 docker-compose logs XXX 看不到容器的日志。只有使用常用系统命令来进行日志的查看</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># # 日志目录</span></span><br><span class="line"><span class="comment"># ls /var/log/harbor</span></span><br><span class="line">core.log  jobservice.log  portal.log  postgresql.log  proxy.log  redis.log  registryctl.log  registry.log</span><br><span class="line"></span><br><span class="line"><span class="comment"># # 数据目录，包括数据库、镜像仓库</span></span><br><span class="line"><span class="comment"># ls /data/</span></span><br><span class="line">ca_download  database  job_logs  psc  redis  registry  secret</span><br></pre></td></tr></table></figure><h4 id="其它操作"><a href="#其它操作" class="headerlink" title="其它操作"></a>其它操作</h4><p>下列操作的工作目录均为解压离线安装文件后生成的 harbor 目录。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># # 停止 harbor</span></span><br><span class="line"><span class="comment"># docker-compose down -v</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># # 启动 harbor</span></span><br><span class="line"><span class="comment"># docker-compose up -d</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># # 更修改的配置更新到 docker-compose.yml 文件</span></span><br><span class="line"><span class="comment"># ./prepare</span></span><br><span class="line">prepare base dir is <span class="built_in">set</span> to /opt/harbor</span><br><span class="line">Clearing the configuration file: /config/<span class="built_in">log</span>/logrotate.conf</span><br><span class="line">Clearing the configuration file: /config/<span class="built_in">log</span>/rsyslog_docker.conf</span><br><span class="line">Clearing the configuration file: /config/nginx/nginx.conf</span><br><span class="line">Clearing the configuration file: /config/core/env</span><br><span class="line">Clearing the configuration file: /config/core/app.conf</span><br><span class="line">Clearing the configuration file: /config/registry/config.yml</span><br><span class="line">Clearing the configuration file: /config/registry/root.crt</span><br><span class="line">Clearing the configuration file: /config/registryctl/env</span><br><span class="line">Clearing the configuration file: /config/registryctl/config.yml</span><br><span class="line">Clearing the configuration file: /config/db/env</span><br><span class="line">Clearing the configuration file: /config/jobservice/env</span><br><span class="line">Clearing the configuration file: /config/jobservice/config.yml</span><br><span class="line">Generated configuration file: /config/<span class="built_in">log</span>/logrotate.conf</span><br><span class="line">Generated configuration file: /config/<span class="built_in">log</span>/rsyslog_docker.conf</span><br><span class="line">Generated configuration file: /config/nginx/nginx.conf</span><br><span class="line">Generated configuration file: /config/core/env</span><br><span class="line">Generated configuration file: /config/core/app.conf</span><br><span class="line">Generated configuration file: /config/registry/config.yml</span><br><span class="line">Generated configuration file: /config/registryctl/env</span><br><span class="line">Generated configuration file: /config/db/env</span><br><span class="line">Generated configuration file: /config/jobservice/env</span><br><span class="line">Generated configuration file: /config/jobservice/config.yml</span><br><span class="line">loaded secret from file: /secret/keys/secretkey</span><br><span class="line">Generated configuration file: /compose_location/docker-compose.yml</span><br><span class="line">Clean up the input dir</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;介绍&quot;&gt;&lt;a href=&quot;#介绍&quot; class=&quot;headerlink&quot; title=&quot;介绍&quot;&gt;&lt;/a&gt;介绍&lt;/h3&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Harbor是一个用于存储和分发Docker镜像的企业级Registry服务器，通过添加一些企业必需的功能特性，例如安全、标识和管理等，扩展了开源Docker Distribution。作为一个企业级私有Registry服务器，Harbor提供了更好的性能和安全。提升用户使用Registry构建和运行环境传输镜像的效率。Harbor支持安装在多个Registry节点的镜像资源复制，镜像全部保存在私有Registry中， 确保数据和知识产权在公司内部网络中管控。另外，Harbor也提供了高级的安全特性，诸如用户管理，访问控制和活动审计等。&lt;/p&gt;
    
    </summary>
    
      <category term="kubernetes" scheme="https://xxlaila.github.io/categories/kubernetes/"/>
    
    
      <category term="harbor" scheme="https://xxlaila.github.io/tags/harbor/"/>
    
  </entry>
  
  <entry>
    <title>k8s pod健康检测</title>
    <link href="https://xxlaila.github.io/2019/09/27/k8s-pod%E5%81%A5%E5%BA%B7%E6%A3%80%E6%B5%8B/"/>
    <id>https://xxlaila.github.io/2019/09/27/k8s-pod健康检测/</id>
    <published>2019-09-27T05:37:53.000Z</published>
    <updated>2019-09-29T03:25:26.771Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Pod健康检测机制"><a href="#Pod健康检测机制" class="headerlink" title="Pod健康检测机制"></a>Pod健康检测机制</h3><p>对于Pod的健康状态检测，kubernetes提供了两类探针(Probe)来执行对Pod的健康状态检测:</p><ul><li><strong>LivenessProbe探针</strong>:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;用于判断容器是否存活，即Pod是否为running状态，如果LivenessProbe探针探测到容器不健康，则kubelet将kill掉容器，并根据容器的重启策略是否重启，如果一个容器不包含LivenessProbe探针，则Kubelet认为容器的LivenessProbe探针的返回值永远成功.</li></ul><a id="more"></a><ul><li><strong>ReadinessProbe探针</strong>:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;用于判断容器是否启动完成，即容器的Ready是否为True，可以接收请求，如果ReadinessProbe探测失败，则容器的Ready将为False，控制器将此Pod的Endpoint从对应的service的Endpoint列表中移除，从此不再将任何请求调度此Pod上，直到下次探测成功。</li></ul><!--more--><p>每类探针都支持三种探测方法:</p><ul><li><strong>exec</strong>: 通过执行命令来检查服务是否正常，针对复杂检测或无HTTP接口的服务，命令返回值为0则表示容器健康。</li><li><strong>httpGet</strong>: 通过发送http请求检查服务是否正常，返回200-399状态码则表明容器健康。</li><li><strong>tcpSocket</strong>: 通过容器的IP和Port执行TCP检查，如果能够建立TCP连接，则表明容器健康。</li></ul><p>探针探测的结果有以下三者之一:</p><ul><li><strong>Success</strong>: Container通过了检查</li><li><strong>Failure</strong>: Container未通过检查</li><li><strong>Unknown</strong>: 未能执行检查，因此不采取任何措施</li></ul><h3 id="LivenessProbe探针配置"><a href="#LivenessProbe探针配置" class="headerlink" title="LivenessProbe探针配置"></a>LivenessProbe探针配置</h3><h4 id="例一：通过exec方式做健康探测"><a href="#例一：通过exec方式做健康探测" class="headerlink" title="例一：通过exec方式做健康探测"></a>例一：通过exec方式做健康探测</h4><ul><li>exec-liveness.yaml<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">$ cat &gt; <span class="built_in">exec</span>-liveness.yaml &lt;&lt;EOF</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    <span class="built_in">test</span>: liveness</span><br><span class="line">  name: liveness-exec</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: liveness</span><br><span class="line">    image: busybox</span><br><span class="line">    args:</span><br><span class="line">    - /bin/sh</span><br><span class="line">    - -c</span><br><span class="line">    - touch /tmp/healthy; sleep 30; rm -rf /tmp/healthy; sleep 600</span><br><span class="line">    livenessProbe:</span><br><span class="line">      <span class="built_in">exec</span>:</span><br><span class="line">        <span class="built_in">command</span>:</span><br><span class="line">        - cat</span><br><span class="line">        - /tmp/healthy</span><br><span class="line">      initialDelaySeconds: 5</span><br><span class="line">      periodSeconds: 5</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在该配置文件中，对容器执行livenessProbe检查，periodSeconds字段指定kubelet每5s执行一次检查，检查的命令为cat /tmp/healthy，initialDelaySeconds字段告诉kubelet应该在执行第一次检查之前等待5秒，如果命令执行成功，则返回0，那么kubelet就认为容器是健康的，如果为非0，则Kubelet会Kill掉容器并根据重启策略来决定是否需要重启。</p><ul><li>当容器启动时，它会执行以下命令<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/bin/sh -c <span class="string">"touch /tmp/healthy; sleep 30; rm -rf /tmp/healthy; sleep 600"</span></span><br></pre></td></tr></table></figure></li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于容器的前30秒，有一个/tmp/healthy文件。因此，在前30秒内，该命令cat /tmp/healthy返回成功代码。30秒后，cat /tmp/healthy返回失败代码。</p><ul><li><p>创建Pod</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$  kubectl create -f  <span class="built_in">exec</span>-liveness.yaml </span><br><span class="line">pod/liveness-exec created</span><br></pre></td></tr></table></figure></li><li><p>在30秒内，查看Pod事件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl describe pod liveness-exec</span><br><span class="line">…………</span><br><span class="line">QoS Class:       BestEffort</span><br><span class="line">Node-Selectors:  &lt;none&gt;</span><br><span class="line">Tolerations:     node.kubernetes.io/not-ready:NoExecute <span class="keyword">for</span> 360s</span><br><span class="line">                 node.kubernetes.io/unreachable:NoExecute <span class="keyword">for</span> 360s</span><br><span class="line">Events:</span><br><span class="line">  Type    Reason     Age   From                   Message</span><br><span class="line">  ----    ------     ----  ----                   -------</span><br><span class="line">  Normal  Scheduled  23s   default-scheduler      Successfully assigned default/liveness-exec to 172.21.17.34</span><br><span class="line">  Normal  Pulling    20s   kubelet, 172.21.17.34  Pulling image <span class="string">"busybox"</span></span><br><span class="line">  Normal  Pulled     2s    kubelet, 172.21.17.34  Successfully pulled image <span class="string">"busybox"</span></span><br><span class="line">  Normal  Created    2s    kubelet, 172.21.17.34  Created container liveness</span><br><span class="line">  Normal  Started    1s    kubelet, 172.21.17.34  Started container liveness</span><br></pre></td></tr></table></figure></li><li><p>35秒后，再次查看Pod事件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl describe pod liveness-exec</span><br><span class="line">…………</span><br><span class="line">Tolerations:     node.kubernetes.io/not-ready:NoExecute <span class="keyword">for</span> 360s</span><br><span class="line">                 node.kubernetes.io/unreachable:NoExecute <span class="keyword">for</span> 360s</span><br><span class="line">Events:</span><br><span class="line">  Type     Reason     Age              From                   Message</span><br><span class="line">  ----     ------     ----             ----                   -------</span><br><span class="line">  Normal   Scheduled  58s              default-scheduler      Successfully assigned default/liveness-exec to 172.21.17.34</span><br><span class="line">  Normal   Pulling    55s              kubelet, 172.21.17.34  Pulling image <span class="string">"busybox"</span></span><br><span class="line">  Normal   Pulled     37s              kubelet, 172.21.17.34  Successfully pulled image <span class="string">"busybox"</span></span><br><span class="line">  Normal   Created    37s              kubelet, 172.21.17.34  Created container liveness</span><br><span class="line">  Normal   Started    36s              kubelet, 172.21.17.34  Started container liveness</span><br><span class="line">  Warning  Unhealthy  0s (x2 over 5s)  kubelet, 172.21.17.34  Liveness probe failed: cat: can<span class="string">'t open '</span>/tmp/healthy<span class="string">': No such file or directory</span></span><br></pre></td></tr></table></figure></li><li><p>再等30秒，确认Container已重新启动</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pod liveness-exec</span><br><span class="line">NAME            READY   STATUS    RESTARTS   AGE</span><br><span class="line">liveness-exec   1/1     Running   1          115s</span><br><span class="line"></span><br><span class="line">$ kubectl describe pod liveness-exec</span><br><span class="line">………………</span><br><span class="line">QoS Class:       BestEffort</span><br><span class="line">Node-Selectors:  &lt;none&gt;</span><br><span class="line">Tolerations:     node.kubernetes.io/not-ready:NoExecute <span class="keyword">for</span> 360s</span><br><span class="line">                 node.kubernetes.io/unreachable:NoExecute <span class="keyword">for</span> 360s</span><br><span class="line">Events:</span><br><span class="line">  Type     Reason     Age                 From                   Message</span><br><span class="line">  ----     ------     ----                ----                   -------</span><br><span class="line">  Normal   Scheduled  2m7s                default-scheduler      Successfully assigned default/liveness-exec to 172.21.17.34</span><br><span class="line">  Warning  Unhealthy  64s (x3 over 74s)   kubelet, 172.21.17.34  Liveness probe failed: cat: can<span class="string">'t open '</span>/tmp/healthy<span class="string">': No such file or directory</span></span><br><span class="line"><span class="string">  Normal   Killing    64s                 kubelet, 172.21.17.34  Container liveness failed liveness probe, will be restarted</span></span><br><span class="line"><span class="string">  Normal   Pulling    34s (x2 over 2m4s)  kubelet, 172.21.17.34  Pulling image "busybox"</span></span><br><span class="line"><span class="string">  Normal   Pulled     25s (x2 over 106s)  kubelet, 172.21.17.34  Successfully pulled image "busybox"</span></span><br><span class="line"><span class="string">  Normal   Created    25s (x2 over 106s)  kubelet, 172.21.17.34  Created container liveness</span></span><br><span class="line"><span class="string">  Normal   Started    25s (x2 over 105s)  kubelet, 172.21.17.34  Started container liveness</span></span><br></pre></td></tr></table></figure></li></ul><h4 id="例二-通过HTTP方式做健康探测"><a href="#例二-通过HTTP方式做健康探测" class="headerlink" title="例二: 通过HTTP方式做健康探测"></a>例二: 通过HTTP方式做健康探测</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">$ cat &gt; http-liveness.yaml &lt;&lt;EOF</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    <span class="built_in">test</span>: liveness</span><br><span class="line">  name: liveness-http</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: liveness</span><br><span class="line">    image: carlziess/liveness</span><br><span class="line">    args:</span><br><span class="line">    - /server</span><br><span class="line">    livenessProbe:</span><br><span class="line">      httpGet:</span><br><span class="line">        path: /healthz</span><br><span class="line">        port: 8080</span><br><span class="line">        httpHeaders:</span><br><span class="line">        - name: X-Custom-Header</span><br><span class="line">          value: Awesome</span><br><span class="line">      initialDelaySeconds: 3</span><br><span class="line">      periodSeconds: 3</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;创建一个Pod，其中periodSeconds字段指定kubelet每3秒执行一次探测，initialDelaySeconds字段告诉kubelet延迟等待3秒，探测方式为向容器中运行的服务发送HTTP GET请求，请求8080端口下的/healthz, 任何大于或等于200且小于400的代码表示成功。任何其他代码表示失败。</p><ul><li><p>创建pod</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl apply -f http-liveness.yaml </span><br><span class="line">pod/liveness-http created</span><br></pre></td></tr></table></figure></li><li><p>检查验证</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl describe pod liveness-http</span><br><span class="line">………………</span><br><span class="line">Node-Selectors:  &lt;none&gt;</span><br><span class="line">Tolerations:     node.kubernetes.io/not-ready:NoExecute <span class="keyword">for</span> 360s</span><br><span class="line">                 node.kubernetes.io/unreachable:NoExecute <span class="keyword">for</span> 360s</span><br><span class="line">Events:</span><br><span class="line">  Type     Reason     Age                   From                   Message</span><br><span class="line">  ----     ------     ----                  ----                   -------</span><br><span class="line">  Normal   Scheduled  2m59s                 default-scheduler      Successfully assigned default/liveness-http to 172.21.17.34</span><br><span class="line">  Normal   Pulled     119s (x3 over 2m46s)  kubelet, 172.21.17.34  Successfully pulled image <span class="string">"carlziess/liveness"</span></span><br><span class="line">  Normal   Created    119s (x3 over 2m46s)  kubelet, 172.21.17.34  Created container liveness</span><br><span class="line">  Normal   Started    118s (x3 over 2m45s)  kubelet, 172.21.17.34  Started container liveness</span><br><span class="line"></span><br><span class="line">$ kubectl get pod</span><br><span class="line">NAME            READY   STATUS    RESTARTS   AGE</span><br><span class="line">liveness-http   1/1     Running   0          26s</span><br></pre></td></tr></table></figure></li><li><p><strong>httpGet</strong>探测方式有如下可选的控制字段</p><ul><li>host: 要连接的主机名，默认为Pod IP，可以在http request head中设置host头部。</li><li>scheme: 用于连接host的协议，默认为HTTP。</li><li>path: http服务器上的访问URL</li><li>httpHeaders: 自定义HTTP请求headers，HTTP允许重复headers</li><li>port: 容器上要访问端口号或名称</li></ul></li></ul><h4 id="例三-通过TCP方式做健康探测"><a href="#例三-通过TCP方式做健康探测" class="headerlink" title="例三: 通过TCP方式做健康探测"></a>例三: 通过TCP方式做健康探测</h4><p>Kubelet将尝试在指定的端口上打开容器上的套接字，如果能建立连接，则表明容器健康。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">$ cat &gt; tcp-liveness-readiness.yaml &lt;&lt;EOF</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: goproxy</span><br><span class="line">  labels:</span><br><span class="line">    app: goproxy</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: goproxy</span><br><span class="line">    image: goproxy/goproxy</span><br><span class="line">    ports:</span><br><span class="line">    - containerPort: 8080</span><br><span class="line">    readinessProbe:</span><br><span class="line">      tcpSocket:</span><br><span class="line">        port: 8080</span><br><span class="line">      initialDelaySeconds: 5</span><br><span class="line">      periodSeconds: 10</span><br><span class="line">    livenessProbe:</span><br><span class="line">      tcpSocket:</span><br><span class="line">        port: 8080</span><br><span class="line">      initialDelaySeconds: 15</span><br><span class="line">      periodSeconds: 20</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;TCP检查方式和HTTP检查方式非常相似，示例中两种探针都使用了，在容器启动5秒后，kubelet将发送第一个readinessProbe探针，这将连接到容器的8080端口，如果探测成功，则该Pod将被标识为ready，10秒后，kubelet将进行第二次连接。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;除此，配置还包含了livenessProbe探针，在容器启动15秒后，kubelet将发送第一个livenessProbe探针，仍然尝试连接容器的8080端口，如果连接失败则重启容器。</p><ul><li><p>执行创建</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl apply -f tcp-liveness-readiness.yaml</span><br><span class="line">pod/goproxy created</span><br></pre></td></tr></table></figure></li><li><p>15秒后，查看Pod事件以验证活动探测</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl describe pod goproxy</span><br><span class="line">………………</span><br><span class="line">Node-Selectors:  &lt;none&gt;</span><br><span class="line">Tolerations:     node.kubernetes.io/not-ready:NoExecute <span class="keyword">for</span> 360s</span><br><span class="line">                 node.kubernetes.io/unreachable:NoExecute <span class="keyword">for</span> 360s</span><br><span class="line">Events:</span><br><span class="line">  Type    Reason     Age   From                    Message</span><br><span class="line">  ----    ------     ----  ----                    -------</span><br><span class="line">  Normal  Scheduled  26s   default-scheduler       Successfully assigned default/goproxy to 172.21.16.231</span><br><span class="line">  Normal  Pulling    22s   kubelet, 172.21.16.231  Pulling image <span class="string">"goproxy/goproxy"</span></span><br></pre></td></tr></table></figure></li></ul><p>当容器有多个端口时，通常会给每个端口命名，所以在使用探针探测时，也可以直接写自定义的端口名称</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ports:</span><br><span class="line">- name: liveness-port</span><br><span class="line">  containerPort: 8080</span><br><span class="line">  hostPort: 8080</span><br><span class="line">livenessProbe:</span><br><span class="line">  httpGet:</span><br><span class="line">    path: /healthz</span><br><span class="line">    port: liveness-port</span><br></pre></td></tr></table></figure><h3 id="ReadinessProbe探针配置"><a href="#ReadinessProbe探针配置" class="headerlink" title="ReadinessProbe探针配置"></a>ReadinessProbe探针配置</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ReadinessProbe探针的使用场景livenessProbe稍有不同，有的时候应用程序可能暂时无法接受请求，比如Pod已经Running了，但是容器内应用程序尚未启动成功，在这种情况下，如果没有ReadinessProbe，则Kubernetes认为它可以处理请求了，然而此时，我们知道程序还没启动成功是不能接收用户请求的，所以不希望kubernetes把请求调度给它，则使用ReadinessProbe探针。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ReadinessProbe和livenessProbe可以使用相同探测方式，只是对Pod的处置方式不同，ReadinessProbe是将Pod IP:Port从对应的EndPoint列表中删除，而livenessProbe则Kill容器并根据Pod的重启策略来决定作出对应的措施。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;探针探测容器是否已准备就绪，如果未准备就绪则kubernetes不会将流量转发给此Pod。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ReadinessProbe探针与livenessProbe一样也支持exec、httpGet、TCP的探测方式，配置方式相同，只不过是将livenessProbe字段修改为ReadinessProbe。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">readinessProbe:</span><br><span class="line">  <span class="built_in">exec</span>:</span><br><span class="line">    <span class="built_in">command</span>:</span><br><span class="line">    - cat</span><br><span class="line">    - /tmp/healthy</span><br><span class="line">  initialDelaySeconds: 5</span><br><span class="line">  periodSeconds: 5</span><br></pre></td></tr></table></figure><p>ReadinessProbe探针的HTTP、TCP的探测方式也与livenessProbe的基本一致。</p><h4 id="例四-ReadinessProbe示例"><a href="#例四-ReadinessProbe示例" class="headerlink" title="例四: ReadinessProbe示例"></a>例四: ReadinessProbe示例</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;加入ReadinessProbe探针和一个没有ReadinessProbe探针的示例，该示例中，创建了一个deploy，名为JavaApp，启动的容器运行一个java应用程序，程序监听端口为9093。</p><ul><li><p>没有ReadinessProbe</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">$ cat &gt; k8s.yaml &lt;&lt; EOF</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: biz-gateway</span><br><span class="line">  labels:</span><br><span class="line">    app: biz-gateway</span><br><span class="line">  namespace:</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - port: 9093</span><br><span class="line">    name: biz-gateway</span><br><span class="line">  selector:</span><br><span class="line">    app: biz-gateway</span><br><span class="line">---</span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: biz-gateway</span><br><span class="line">  namespace:</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: biz-gateway</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: biz-gateway</span><br><span class="line">        image: docker.io/xxlaila/biz-gateway:dev-08c8a4e</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 9093</span><br><span class="line">        env:</span><br><span class="line">        - name: RUN_ENV</span><br><span class="line">          value: dev</span><br><span class="line">        - name: CONFIG_API_SERVER</span><br><span class="line">          value: http://api.conf.xxlaila.cn</span><br><span class="line">        - name: RUN_CLUSTER</span><br><span class="line">          value: default</span><br><span class="line">        - name: RUN_MODE</span><br><span class="line">          value: AUTO</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></li><li><p>执行创建</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl apply -f k8s.yaml </span><br><span class="line">service/biz-gateway created</span><br><span class="line">deployment.extensions/biz-gateway created</span><br></pre></td></tr></table></figure></li><li><p>刚创建后，等一会后，查看Pod状态，记着要给image留下pull的时间</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pods  |grep <span class="string">"biz-gateway"</span></span><br><span class="line">NAME                          READY   STATUS    RESTARTS   AGE</span><br><span class="line">biz-gateway-95f6b677f-rnz22   1/1     Running   0          2m8s</span><br></pre></td></tr></table></figure></li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;可以看到，整个过程Pod用了2m8s，自身状态已Running，其READ字段，1/1 表示1个容器状态已准备就绪了，此时，对于kubernetes而言，已经可以接收请求了,而实际上服务还无法访问，因为JAVA程序还尚启动起来，2m8ss后方可正常访问，所以针对此类程序，必须配置ReadinessProbe。</p><ul><li>加入readinessProbe<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">$ cat &gt; k8s.yaml &lt;&lt; EOF</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: biz-gateway</span><br><span class="line">  labels:</span><br><span class="line">    app: biz-gateway</span><br><span class="line">  namespace:</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - protocol: TCP</span><br><span class="line">    port: 9093</span><br><span class="line">    name: biz-gateway</span><br><span class="line">  selector:</span><br><span class="line">    app: biz-gateway</span><br><span class="line">---</span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: biz-gateway</span><br><span class="line">  namespace:</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: biz-gateway</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: biz-gateway</span><br><span class="line">        image: docker.io/xxlaila/biz-gateway:dev-08c8a4e</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 9093</span><br><span class="line">        readinessProbe:</span><br><span class="line">          tcpSocket:</span><br><span class="line">            port: 9093</span><br><span class="line">          initialDelaySeconds: 140</span><br><span class="line">          periodSeconds: 10</span><br><span class="line">        env:</span><br><span class="line">        - name: RUN_ENV</span><br><span class="line">          value: dev</span><br><span class="line">        - name: CONFIG_API_SERVER</span><br><span class="line">          value: http://api.conf.xxlaila.cn</span><br><span class="line">        - name: RUN_CLUSTER</span><br><span class="line">          value: default</span><br><span class="line">        - name: RUN_MODE</span><br><span class="line">          value: AUTO</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在该配置文件中，ReadinessProbe探针的探测方式为tcpSocket，因为程序监听在9093端口，所以这里探测为对9093建立连接,这里第一次探测时间是在Pod Runing后140秒后，间隔10秒后执行第二次探测。</p><ul><li><p>创建</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f ./</span><br><span class="line">service/biz-gateway created</span><br><span class="line">deployment.extensions/biz-gateway created</span><br></pre></td></tr></table></figure></li><li><p>查看验证</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建后等待了60s</span></span><br><span class="line">$ kubectl get pod -o wide</span><br><span class="line">NAME                          READY   STATUS    RESTARTS   AGE   IP            NODE           NOMINATED NODE   READINESS GATES</span><br><span class="line">biz-gateway-f69cc8678-qs8s7   0/1     Running   0          60s   172.30.56.6   172.21.17.40   &lt;none&gt;           &lt;none&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 继续等待一会</span></span><br><span class="line">$ kubectl get pod -o wide</span><br><span class="line">NAME                          READY   STATUS    RESTARTS   AGE     IP            NODE           NOMINATED NODE   READINESS GATES</span><br><span class="line">biz-gateway-f69cc8678-qs8s7   1/1     Running   0          2m36s   172.30.56.6   172.21.17.40   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure></li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;可以看到在2m36秒后，pod启动ok，在第一次查看的时候，Pod虽然已处于Runnig状态，但是由于第一次探测时间未到，所以READY字段为0/1，即容器的状态为未准备就绪，在未准备就绪的情况下，其Pod对应的Service下的Endpoint也为空，所以才不会有任何请求被调度进来。</p><ul><li>查看Endpoint<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 第一次执行</span></span><br><span class="line">$ kubectl get endpoints</span><br><span class="line">NAME          ENDPOINTS                                                AGE</span><br><span class="line">biz-gateway                                                            57s</span><br><span class="line">kubernetes    172.21.16.110:6443,172.21.17.30:6443,172.21.17.31:6443   13d</span><br><span class="line"></span><br><span class="line">在2m36s后在次执行</span><br><span class="line">$ kubectl get endpoints</span><br><span class="line">NAME          ENDPOINTS                                                AGE</span><br><span class="line">biz-gateway   172.30.56.6:9093                                         2m41s</span><br><span class="line">kubernetes    172.21.16.110:6443,172.21.17.30:6443,172.21.17.31:6443   13d</span><br></pre></td></tr></table></figure></li></ul><h3 id="配置探针-Probe-相关属性"><a href="#配置探针-Probe-相关属性" class="headerlink" title="配置探针(Probe)相关属性"></a>配置探针(Probe)相关属性</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;探针(Probe)有许多可选字段，可以用来更加精确的控制Liveness和Readiness两种探针的行为(Probe)：</p><ul><li>initialDelaySeconds：Pod启动后延迟多久才进行检查，单位：秒</li><li>periodSeconds：检查的间隔时间，默认为10，单位：秒。</li><li>timeoutSeconds：探测的超时时间，默认为1，单位：秒。</li><li>successThreshold：探测失败后认为成功的最小连接成功次数，默认为1，在Liveness探针中必须为1，最小值为1。</li><li>failureThreshold：探测失败的重试次数，重试一定次数后将认为失败，在readiness探针中，Pod会被标记为未就绪，默认为3，最小值为1。</li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>之前错误参考排查介绍</strong>: 在之前安装jenkins的时候，创建pod就一值处于<code>running</code>,但是过一会，界面就报错，错误如下图<br><img src="http://img.xxlaila.cn/15008WechatIMG.png" alt="img"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;然后查看pod日志和系统系统，都没有任何问题，pod日志如下，然后就问了朋友，就说有可能是pod的健康检测机制，最后就修改了pod的健康检测机制，jenkins服务器部署ok。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">kubectl <span class="built_in">log</span> $(kubectl get pods -n kube-ops | awk <span class="string">'&#123;print $1&#125;'</span> | grep jenkins) -n kube-ops</span><br><span class="line"><span class="built_in">log</span> is DEPRECATED and will be removed <span class="keyword">in</span> a future version. Use logs instead.</span><br><span class="line">VM settings:</span><br><span class="line">    Max. Heap Size: 3.00G</span><br><span class="line">    Ergonomics Machine Class: server</span><br><span class="line">    Using VM: OpenJDK 64-Bit Server VM</span><br><span class="line"></span><br><span class="line">Running from: /usr/share/jenkins/jenkins.war</span><br><span class="line">webroot: EnvVars.masterEnvVars.get(<span class="string">"JENKINS_HOME"</span>)</span><br><span class="line">2019-09-27 03:02:24.133+0000 [id=1] INFO org.eclipse.jetty.util.log.Log<span class="comment">#initialized: Logging initialized @429ms to org.eclipse.jetty.util.log.JavaUtilLog</span></span><br><span class="line">2019-09-27 03:02:24.247+0000 [id=1] INFO winstone.Logger<span class="comment">#logInternal: Beginning extraction from war file</span></span><br></pre></td></tr></table></figure><p><strong>后续</strong>: 虽然健康检测可以取消，不加入，但是当我们在上生产环境的时候还是要加上，正如例四介绍的那样。如果我们在生产环境错故障自愈、轮询发布等。都需要这个东西，加入再升级的时候，服务器都还没起来，k8s就吧流量给调度过来，升级下一个pod，外部用户访问就会报错，那就是很尴尬</p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Pod健康检测机制&quot;&gt;&lt;a href=&quot;#Pod健康检测机制&quot; class=&quot;headerlink&quot; title=&quot;Pod健康检测机制&quot;&gt;&lt;/a&gt;Pod健康检测机制&lt;/h3&gt;&lt;p&gt;对于Pod的健康状态检测，kubernetes提供了两类探针(Probe)来执行对Pod的健康状态检测:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;LivenessProbe探针&lt;/strong&gt;:&lt;br&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;用于判断容器是否存活，即Pod是否为running状态，如果LivenessProbe探针探测到容器不健康，则kubelet将kill掉容器，并根据容器的重启策略是否重启，如果一个容器不包含LivenessProbe探针，则Kubelet认为容器的LivenessProbe探针的返回值永远成功.&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="kubernetes" scheme="https://xxlaila.github.io/categories/kubernetes/"/>
    
    
      <category term="pod" scheme="https://xxlaila.github.io/tags/pod/"/>
    
  </entry>
  
  <entry>
    <title>EFK</title>
    <link href="https://xxlaila.github.io/2019/09/25/EFK/"/>
    <id>https://xxlaila.github.io/2019/09/25/EFK/</id>
    <published>2019-09-25T07:24:18.000Z</published>
    <updated>2019-09-26T03:13:12.627Z</updated>
    
    <content type="html"><![CDATA[<h3 id="初始化配置文件准备"><a href="#初始化配置文件准备" class="headerlink" title="初始化配置文件准备"></a>初始化配置文件准备</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;将下载的 kubernetes-server-linux-amd64.tar.gz 解压后，再解压其中的 kubernetes-src.tar.gz 文件。<code>kubernetes/cluster/addons/fluentd-elasticsearch</code>这是文件所在的路径</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;es 数据默认的存储在docker里面，在用的是node节点的空间，而node节点我们不可能都准备很大的空间，那样很浪费资源，所以这里我们需要准备外部的nfs存储空间，然后通过<a href="https://xxlaila.github.io/2019/09/24/%E5%88%A9%E7%94%A8NFS%E5%8A%A8%E6%80%81%E6%8F%90%E4%BE%9BKubernetes%E5%90%8E%E7%AB%AF%E5%AD%98%E5%82%A8%E5%8D%B7/">pv</a>的模式进行挂载，数据存储到nfs服务器上，这样保障了es收集数据的可用性。</p><a id="more"></a><h3 id="创建存储介质"><a href="#创建存储介质" class="headerlink" title="创建存储介质"></a>创建存储介质</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ cat &gt; pvc.yaml &lt;&lt;EOF</span><br><span class="line">---</span><br><span class="line">apiVersion: storage.k8s.io/v1</span><br><span class="line">kind: StorageClass</span><br><span class="line">metadata:</span><br><span class="line">  name: es-nfs-data</span><br><span class="line">provisioner: fuseim.pri/ifs</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">$ kubectl apply -f pvc.yaml</span><br></pre></td></tr></table></figure><h3 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h3><ul><li><p>es-statefulset.yaml</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># RBAC authn and authz</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: elasticsearch-logging</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: elasticsearch-logging</span><br><span class="line">    kubernetes.io/cluster-service: <span class="string">"true"</span></span><br><span class="line">    addonmanager.kubernetes.io/mode: Reconcile</span><br><span class="line">---</span><br><span class="line">kind: ClusterRole</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: elasticsearch-logging</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: elasticsearch-logging</span><br><span class="line">    kubernetes.io/cluster-service: <span class="string">"true"</span></span><br><span class="line">    addonmanager.kubernetes.io/mode: Reconcile</span><br><span class="line">rules:</span><br><span class="line">- apiGroups:</span><br><span class="line">  - <span class="string">""</span></span><br><span class="line">  resources:</span><br><span class="line">  - <span class="string">"services"</span></span><br><span class="line">  - <span class="string">"namespaces"</span></span><br><span class="line">  - <span class="string">"endpoints"</span></span><br><span class="line">  verbs:</span><br><span class="line">  - <span class="string">"get"</span></span><br><span class="line">---</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  name: elasticsearch-logging</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: elasticsearch-logging</span><br><span class="line">    kubernetes.io/cluster-service: <span class="string">"true"</span></span><br><span class="line">    addonmanager.kubernetes.io/mode: Reconcile</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: elasticsearch-logging</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  apiGroup: <span class="string">""</span></span><br><span class="line">roleRef:</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: elasticsearch-logging</span><br><span class="line">  apiGroup: <span class="string">""</span></span><br><span class="line">---</span><br><span class="line"><span class="comment"># Elasticsearch deployment itself</span></span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: StatefulSet</span><br><span class="line">metadata:</span><br><span class="line">  name: elasticsearch-logging</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: elasticsearch-logging</span><br><span class="line">    version: v6.6.1</span><br><span class="line">    kubernetes.io/cluster-service: <span class="string">"true"</span></span><br><span class="line">    addonmanager.kubernetes.io/mode: Reconcile</span><br><span class="line">spec:</span><br><span class="line">  serviceName: elasticsearch-logging</span><br><span class="line">  replicas: 2</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: elasticsearch-logging</span><br><span class="line">      version: v6.6.1</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: elasticsearch-logging</span><br><span class="line">        version: v6.6.1</span><br><span class="line">        kubernetes.io/cluster-service: <span class="string">"true"</span></span><br><span class="line">    spec:</span><br><span class="line">      serviceAccountName: elasticsearch-logging</span><br><span class="line">      containers:</span><br><span class="line">      - image: elasticsearch:6.6.1</span><br><span class="line">        name: elasticsearch-logging</span><br><span class="line">        resources:</span><br><span class="line">          <span class="comment"># need more cpu upon initialization, therefore burstable class</span></span><br><span class="line">          limits:</span><br><span class="line">            cpu: 1000m</span><br><span class="line">          requests:</span><br><span class="line">            cpu: 100m</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 9200</span><br><span class="line">          name: db</span><br><span class="line">          protocol: TCP</span><br><span class="line">        - containerPort: 9300</span><br><span class="line">          name: transport</span><br><span class="line">          protocol: TCP</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: elasticsearch-logging</span><br><span class="line">          mountPath: /data</span><br><span class="line">        env:</span><br><span class="line">        - name: <span class="string">"NAMESPACE"</span></span><br><span class="line">          valueFrom:</span><br><span class="line">            fieldRef:</span><br><span class="line">              fieldPath: metadata.namespace</span><br><span class="line">      <span class="comment"># Elasticsearch requires vm.max_map_count to be at least 262144.</span></span><br><span class="line">      <span class="comment"># If your OS already sets up this number to a higher value, feel free</span></span><br><span class="line">      <span class="comment"># to remove this init container.</span></span><br><span class="line">      initContainers:</span><br><span class="line">      - image: alpine:3.6</span><br><span class="line">        <span class="built_in">command</span>: [<span class="string">"/sbin/sysctl"</span>, <span class="string">"-w"</span>, <span class="string">"vm.max_map_count=262144"</span>]</span><br><span class="line">        name: elasticsearch-logging-init</span><br><span class="line">        securityContext:</span><br><span class="line">          privileged: <span class="literal">true</span></span><br><span class="line">  volumeClaimTemplates:</span><br><span class="line">  - metadata:</span><br><span class="line">      name: elasticsearch-logging</span><br><span class="line">    spec:</span><br><span class="line">      accessModes: [ <span class="string">"ReadWriteMany"</span> ]</span><br><span class="line">      storageClassName: <span class="string">"es-nfs-data"</span></span><br><span class="line">      resources:</span><br><span class="line">        requests:</span><br><span class="line">          storage: 30Gi</span><br></pre></td></tr></table></figure></li><li><p>fluentd-es-ds.yaml</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: fluentd-es</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: fluentd-es</span><br><span class="line">    kubernetes.io/cluster-service: <span class="string">"true"</span></span><br><span class="line">    addonmanager.kubernetes.io/mode: Reconcile</span><br><span class="line">---</span><br><span class="line">kind: ClusterRole</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: fluentd-es</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: fluentd-es</span><br><span class="line">    kubernetes.io/cluster-service: <span class="string">"true"</span></span><br><span class="line">    addonmanager.kubernetes.io/mode: Reconcile</span><br><span class="line">rules:</span><br><span class="line">- apiGroups:</span><br><span class="line">  - <span class="string">""</span></span><br><span class="line">  resources:</span><br><span class="line">  - <span class="string">"namespaces"</span></span><br><span class="line">  - <span class="string">"pods"</span></span><br><span class="line">  verbs:</span><br><span class="line">  - <span class="string">"get"</span></span><br><span class="line">  - <span class="string">"watch"</span></span><br><span class="line">  - <span class="string">"list"</span></span><br><span class="line">---</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: fluentd-es</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: fluentd-es</span><br><span class="line">    kubernetes.io/cluster-service: <span class="string">"true"</span></span><br><span class="line">    addonmanager.kubernetes.io/mode: Reconcile</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: fluentd-es</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  apiGroup: <span class="string">""</span></span><br><span class="line">roleRef:</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: fluentd-es</span><br><span class="line">  apiGroup: <span class="string">""</span></span><br><span class="line">---</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: DaemonSet</span><br><span class="line">metadata:</span><br><span class="line">  name: fluentd-es-v2.4.0</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: fluentd-es</span><br><span class="line">    version: v2.4.0</span><br><span class="line">    kubernetes.io/cluster-service: <span class="string">"true"</span></span><br><span class="line">    addonmanager.kubernetes.io/mode: Reconcile</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: fluentd-es</span><br><span class="line">      version: v2.4.0</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: fluentd-es</span><br><span class="line">        kubernetes.io/cluster-service: <span class="string">"true"</span></span><br><span class="line">        version: v2.4.0</span><br><span class="line">      <span class="comment"># This annotation ensures that fluentd does not get evicted if the node</span></span><br><span class="line">      <span class="comment"># supports critical pod annotation based priority scheme.</span></span><br><span class="line">      <span class="comment"># Note that this does not guarantee admission on the nodes (#40573).</span></span><br><span class="line">      annotations:</span><br><span class="line">        scheduler.alpha.kubernetes.io/critical-pod: <span class="string">''</span></span><br><span class="line">        seccomp.security.alpha.kubernetes.io/pod: <span class="string">'docker/default'</span></span><br><span class="line">    spec:</span><br><span class="line">      priorityClassName: system-node-critical</span><br><span class="line">      serviceAccountName: fluentd-es</span><br><span class="line">      containers:</span><br><span class="line">      - name: fluentd-es</span><br><span class="line">        image: docker.io/xxlaila/fluentd-elasticsearch:v2.4.0</span><br><span class="line">        env:</span><br><span class="line">        - name: FLUENTD_ARGS</span><br><span class="line">          value: --no-supervisor -q</span><br><span class="line">        resources:</span><br><span class="line">          limits:</span><br><span class="line">            memory: 500Mi</span><br><span class="line">          requests:</span><br><span class="line">            cpu: 100m</span><br><span class="line">            memory: 200Mi</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: varlog</span><br><span class="line">          mountPath: /var/<span class="built_in">log</span></span><br><span class="line">        - name: varlibdockercontainers</span><br><span class="line">          mountPath: /var/lib/docker/containers</span><br><span class="line">          readOnly: <span class="literal">true</span></span><br><span class="line">        - name: config-volume</span><br><span class="line">          mountPath: /etc/fluent/config.d</span><br><span class="line">      terminationGracePeriodSeconds: 30</span><br><span class="line">      volumes:</span><br><span class="line">      - name: varlog</span><br><span class="line">        hostPath:</span><br><span class="line">          path: /var/<span class="built_in">log</span></span><br><span class="line">      - name: varlibdockercontainers</span><br><span class="line">        hostPath:</span><br><span class="line">          path: /var/lib/docker/containers</span><br><span class="line">      - name: config-volume</span><br><span class="line">        configMap:</span><br><span class="line">          name: fluentd-es-config-v0.2.0</span><br></pre></td></tr></table></figure></li><li><p>kibana-deployment.yaml<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;注释里面的两行配置,不注释的话，打开kibana的时候会提示<code>kibana {&quot;statusCode&quot;:404,&quot;error&quot;:&quot;Not Found&quot;,&quot;message&quot;:&quot;Not Found&quot;}</code>,参考<a href="https://github.com/kubernetes-sigs/kubespray/issues/3322" target="_blank" rel="noopener">解决方案</a>,注释配置如下:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">- name: SERVER_BASEPATH</span><br><span class="line">  value: /api/v1/namespaces/kube-system/services/kibana-logging/proxy</span><br></pre></td></tr></table></figure></li></ul><h4 id="执行创建"><a href="#执行创建" class="headerlink" title="执行创建"></a>执行创建</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl apply -f ./</span><br></pre></td></tr></table></figure><h4 id="查看创建"><a href="#查看创建" class="headerlink" title="查看创建"></a>查看创建</h4><ul><li><p>查看pod</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pods -n kube-system |egrep <span class="string">"kibana|elasticsearch|fluentd"</span></span><br><span class="line">elasticsearch-logging-0                       1/1     Running   0          65m</span><br><span class="line">elasticsearch-logging-1                       1/1     Running   0          61m</span><br><span class="line">fluentd-es-v2.4.0-4fp28                       1/1     Running   0          30m</span><br><span class="line">fluentd-es-v2.4.0-b7k67                       1/1     Running   0          30m</span><br><span class="line">fluentd-es-v2.4.0-f8jzp                       1/1     Running   0          30m</span><br><span class="line">fluentd-es-v2.4.0-shwzm                       1/1     Running   0          30m</span><br><span class="line">fluentd-es-v2.4.0-ww8r8                       1/1     Running   0          30m</span><br><span class="line">kibana-logging-57b55f58bc-xh5lp               1/1     Running   0          6m35s</span><br></pre></td></tr></table></figure></li><li><p>查看service</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get svc -n kube-system |egrep <span class="string">"kibana|elasticsearch"</span></span><br><span class="line">elasticsearch-logging     ClusterIP   10.254.30.110    &lt;none&gt;        9200/TCP                 9s</span><br><span class="line">kibana-logging            ClusterIP   10.254.188.5     &lt;none&gt;        5601/TCP                 16h</span><br></pre></td></tr></table></figure></li><li><p>查看pv，pvc</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$  kubectl get pv,pvc -n kube-system</span><br><span class="line">NAME                                                        CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                                                       STORAGECLASS   REASON   AGE</span><br><span class="line">persistentvolume/pvc-65fdd14e-dffc-11e9-bc90-fa163e5af833   30Gi       RWX            Delete           Bound    kube-system/elasticsearch-logging-elasticsearch-logging-0   es-nfs-data             21m</span><br><span class="line">persistentvolume/pvc-fe818f55-dffc-11e9-bc90-fa163e5af833   30Gi       RWX            Delete           Bound    kube-system/elasticsearch-logging-elasticsearch-logging-1   es-nfs-data             16m</span><br><span class="line"></span><br><span class="line">NAME                                                                  STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE</span><br><span class="line">persistentvolumeclaim/elasticsearch-logging-elasticsearch-logging-0   Bound    pvc-65fdd14e-dffc-11e9-bc90-fa163e5af833   30Gi       RWX            es-nfs-data    21m</span><br><span class="line">persistentvolumeclaim/elasticsearch-logging-elasticsearch-logging-1   Bound    pvc-fe818f55-dffc-11e9-bc90-fa163e5af833   30Gi       RWX            es-nfs-data    17m</span><br></pre></td></tr></table></figure></li></ul><h3 id="创建web访问"><a href="#创建web访问" class="headerlink" title="创建web访问"></a>创建web访问</h3><ul><li><p>kibana-Ingress.yaml</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">$ cat &gt; kibana-Ingress.yaml &lt;&lt;EOF</span><br><span class="line">---</span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: kibana-web-ui</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  annotations:</span><br><span class="line">    kubernetes.io/ingress.class: traefik</span><br><span class="line">spec:</span><br><span class="line">  rules:</span><br><span class="line">  - host: kibana.xxlaila.cn</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - path: /</span><br><span class="line">        backend:</span><br><span class="line">          serviceName: kibana-logging</span><br><span class="line">          servicePort: 5601</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></li><li><p>es-Ingress.yaml </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">$ cat &gt; es-Ingress &lt;&lt;EOF</span><br><span class="line">---</span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: es-web-ui</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  annotations:</span><br><span class="line">    kubernetes.io/ingress.class: traefik</span><br><span class="line">spec:</span><br><span class="line">  rules:</span><br><span class="line">  - host: es.xxlaila.cn</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - path: /</span><br><span class="line">        backend:</span><br><span class="line">          serviceName: elasticsearch-logging</span><br><span class="line">          servicePort: 9200</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></li><li><p>执行创建</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl apply -f es-Ingress.yaml kibana-Ingress.yaml</span><br></pre></td></tr></table></figure></li><li><p>在浏览器访问es<br><img src="http://img.xxlaila.cn/1569462606884.jpg" alt="img"></p></li><li><p>浏览器访问kibana<br><img src="http://img.xxlaila.cn/1569464839630.jpg" alt="img"><br>建立索引，默认的索引是根据天来自动创建在es里面，这里我是在kibana里面是根据月来却分的<br><img src="http://img.xxlaila.cn/1569464950776.jpg" alt="img"></p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;初始化配置文件准备&quot;&gt;&lt;a href=&quot;#初始化配置文件准备&quot; class=&quot;headerlink&quot; title=&quot;初始化配置文件准备&quot;&gt;&lt;/a&gt;初始化配置文件准备&lt;/h3&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;将下载的 kubernetes-server-linux-amd64.tar.gz 解压后，再解压其中的 kubernetes-src.tar.gz 文件。&lt;code&gt;kubernetes/cluster/addons/fluentd-elasticsearch&lt;/code&gt;这是文件所在的路径&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;es 数据默认的存储在docker里面，在用的是node节点的空间，而node节点我们不可能都准备很大的空间，那样很浪费资源，所以这里我们需要准备外部的nfs存储空间，然后通过&lt;a href=&quot;https://xxlaila.github.io/2019/09/24/%E5%88%A9%E7%94%A8NFS%E5%8A%A8%E6%80%81%E6%8F%90%E4%BE%9BKubernetes%E5%90%8E%E7%AB%AF%E5%AD%98%E5%82%A8%E5%8D%B7/&quot;&gt;pv&lt;/a&gt;的模式进行挂载，数据存储到nfs服务器上，这样保障了es收集数据的可用性。&lt;/p&gt;
    
    </summary>
    
      <category term="kubernetes" scheme="https://xxlaila.github.io/categories/kubernetes/"/>
    
    
      <category term="efk" scheme="https://xxlaila.github.io/tags/efk/"/>
    
  </entry>
  
  <entry>
    <title>网络状态监控</title>
    <link href="https://xxlaila.github.io/2019/09/25/%E7%BD%91%E7%BB%9C%E7%8A%B6%E6%80%81%E7%9B%91%E6%8E%A7/"/>
    <id>https://xxlaila.github.io/2019/09/25/网络状态监控/</id>
    <published>2019-09-25T05:27:04.000Z</published>
    <updated>2019-09-26T03:13:12.554Z</updated>
    
    <content type="html"><![CDATA[<h3 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;监控IDC机房网络质量情况，本地区到其他地区，其他地区到本节点，或者各省市时间网络、运营商网络状态，监视网络性能，包括常规的 ping，用 fping、echoping、tracert 监视 www 服务器性能，监视 dns 查询性能，监视 ssh 性能等。底层也是 rrdtool 做支持，特点是画的图非常漂亮，网络丢包和延迟用颜色和阴影来表示。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Smokeping。最新版本的 Smokeping 支持多个节点的检测结果从一个图上画出来</p><a id="more"></a><h3 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h3><h4 id="安装yum源"><a href="#安装yum源" class="headerlink" title="安装yum源"></a>安装yum源</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rpmforge-release-0.5.3-1.el6.rf.x86_64.rpm               </span></span><br><span class="line"><span class="comment"># rpm –Uvh http://mirrors.neusoft.edu.cn/epel/6/i386/epel-release-6-8.noarch.rpm</span></span><br></pre></td></tr></table></figure><h4 id="安装依赖包"><a href="#安装依赖包" class="headerlink" title="安装依赖包"></a>安装依赖包</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># yum –y install perl perl-Net-Telnet perl-Net-DNS perl-LDAP perl-libwww-perl perl-RadiusPerl perl-IO-Socket-SSL perl-Socket6 perl-CGI-SpeedyCGI perl-FCGI perl-CGI-SpeedCGI perl-Time-HiRes perl-ExtUtils-MakeMaker perl-RRD-Simple rrdtool rrdtool-perl curl fping echo</span></span><br><span class="line">ping  httpd httpd-devel gcc make  wget libxml2-devel libpng-devel glib pango pango-devel freetype freetype-devel fontconfig cairo cairo-devel libart_lgpl libart_lgpl-devel mod_fastcgi</span><br></pre></td></tr></table></figure><h3 id="安装smokeping"><a href="#安装smokeping" class="headerlink" title="安装smokeping"></a>安装smokeping</h3><h4 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># wget http://oss.oetiker.ch/smokeping/pub/smokeping-2.6.11.tar.gz 这里下载的最新版</span></span><br></pre></td></tr></table></figure><h4 id="安装FCGI"><a href="#安装FCGI" class="headerlink" title="安装FCGI"></a>安装FCGI</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># tar zxf CGI-4.33.tar.gz</span></span><br><span class="line"><span class="comment"># cd CGI-4.33</span></span><br><span class="line"><span class="comment"># perl Makefile.PL</span></span><br><span class="line"><span class="comment"># make &amp;&amp; make install</span></span><br></pre></td></tr></table></figure><h4 id="安装Config-Grammar"><a href="#安装Config-Grammar" class="headerlink" title="安装Config-Grammar"></a>安装Config-Grammar</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># tar zxf Config-Grammar-1.10.tar.gz</span></span><br><span class="line"><span class="comment"># cd Config-Grammar-1.10</span></span><br><span class="line"><span class="comment"># perl Makefile.PL</span></span><br><span class="line"><span class="comment"># make &amp;&amp; make install</span></span><br></pre></td></tr></table></figure><h4 id="安装ExtUtils-MakeMaker"><a href="#安装ExtUtils-MakeMaker" class="headerlink" title="安装ExtUtils-MakeMaker"></a>安装ExtUtils-MakeMaker</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># tar zxf ExtUtils-MakeMaker-7.24.tar.gz</span></span><br><span class="line"><span class="comment"># cd ExtUtils-MakeMaker</span></span><br><span class="line"><span class="comment"># perl Makefile.PL</span></span><br><span class="line"><span class="comment"># make &amp;&amp; make install</span></span><br></pre></td></tr></table></figure><h4 id="安装Simple"><a href="#安装Simple" class="headerlink" title="安装Simple"></a>安装Simple</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># tar zxf Test-Simple-1.302056.tar.gz</span></span><br><span class="line"><span class="comment"># cd Test-Simple-1.302056</span></span><br><span class="line"><span class="comment"># perl Makefile.PL</span></span><br><span class="line"><span class="comment"># make &amp;&amp; make install</span></span><br><span class="line">`</span><br></pre></td></tr></table></figure><h4 id="安装Net-OpenSSH"><a href="#安装Net-OpenSSH" class="headerlink" title="安装Net-OpenSSH"></a>安装Net-OpenSSH</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># tar zxf Net-OpenSSH-0.73.tar.gz</span></span><br><span class="line"><span class="comment"># cd Net-OpenSSH-0.73</span></span><br><span class="line"><span class="comment"># perl Makefile.PL</span></span><br><span class="line"><span class="comment"># make &amp;&amp; make install</span></span><br></pre></td></tr></table></figure><h4 id="安装Net-SNMP"><a href="#安装Net-SNMP" class="headerlink" title="安装Net-SNMP"></a>安装Net-SNMP</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># tar Net-SNMP-v6.0.1.tar.gz</span></span><br><span class="line"><span class="comment"># cd Net-SNMP-v6.0.1</span></span><br><span class="line"><span class="comment"># perl Makefile.PL</span></span><br><span class="line"><span class="comment"># make &amp;&amp; make install</span></span><br></pre></td></tr></table></figure><h4 id="安装perl-ldap"><a href="#安装perl-ldap" class="headerlink" title="安装perl-ldap"></a>安装perl-ldap</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># tar zxf perl-ldap-0.65.tar.gz</span></span><br><span class="line"><span class="comment"># cd perl-ldap-0.65</span></span><br><span class="line"><span class="comment"># ./install-nomake</span></span><br></pre></td></tr></table></figure><h4 id="安装Net-DNS"><a href="#安装Net-DNS" class="headerlink" title="安装Net-DNS"></a>安装Net-DNS</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># tar zxf Net-DNS-1.06.tar.gz</span></span><br><span class="line"><span class="comment"># cd Net-DNS-1.06</span></span><br><span class="line"><span class="comment"># perl Makefile.PL</span></span><br><span class="line"><span class="comment"># make &amp;&amp; make install</span></span><br></pre></td></tr></table></figure><h4 id="安装IO-Tty"><a href="#安装IO-Tty" class="headerlink" title="安装IO-Tty"></a>安装IO-Tty</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># tar IO-Tty-1.12.tar.gz</span></span><br><span class="line"><span class="comment"># cd IO-Tty-1.12</span></span><br><span class="line"><span class="comment"># perl Makefile.PL</span></span><br><span class="line"><span class="comment"># make &amp;&amp; make install</span></span><br></pre></td></tr></table></figure><h4 id="安装libwww-perl"><a href="#安装libwww-perl" class="headerlink" title="安装libwww-perl"></a>安装libwww-perl</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># tar zxf libwww-perl-6.15.tar.gz</span></span><br><span class="line"><span class="comment"># cd libwww-perl-6.15</span></span><br><span class="line"><span class="comment"># perl Makefile.PL</span></span><br><span class="line"><span class="comment"># make &amp;&amp; make install</span></span><br></pre></td></tr></table></figure><h4 id="安装smokeping-1"><a href="#安装smokeping-1" class="headerlink" title="安装smokeping"></a>安装smokeping</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># tar zxf smokeping-2.6.11.tar.gz</span></span><br><span class="line"><span class="comment"># cd smokeping-2.6.11</span></span><br><span class="line"><span class="comment"># ./configure --prefix=/usr/local/smokeping</span></span><br><span class="line"><span class="comment"># /usr/bin/gmake install</span></span><br></pre></td></tr></table></figure><p>上面是手动安装，针对网络不能翻墙。也可以采取smokeping一键安装的方式进行安装</p><h3 id="smokeping一键安装"><a href="#smokeping一键安装" class="headerlink" title="smokeping一键安装"></a>smokeping一键安装</h3><h4 id="安装smokeping-2"><a href="#安装smokeping-2" class="headerlink" title="安装smokeping"></a>安装smokeping</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># tar zxf smokeping-2.6.11.tar.gz</span></span><br><span class="line"><span class="comment"># cd smokeping-2.6.11</span></span><br><span class="line"><span class="comment"># ./setup/build-perl-modules.sh /usr/local/smokeping/thirdparty</span></span><br><span class="line"><span class="comment"># ./configure --prefix=/usr/local/smokeping</span></span><br><span class="line"><span class="comment"># /usr/bin/gmake install</span></span><br></pre></td></tr></table></figure><h3 id="配置smkeping"><a href="#配置smkeping" class="headerlink" title="配置smkeping"></a>配置smkeping</h3><h4 id="创建cache、data、var目录"><a href="#创建cache、data、var目录" class="headerlink" title="创建cache、data、var目录"></a>创建cache、data、var目录</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cd /usr/local/smokeping/</span></span><br><span class="line"><span class="comment"># mkdir &#123;cache,data,var&#125;</span></span><br></pre></td></tr></table></figure><h4 id="创建日志文件"><a href="#创建日志文件" class="headerlink" title="创建日志文件"></a>创建日志文件</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># touch /var/log/smokeping.log</span></span><br></pre></td></tr></table></figure><h4 id="赋权限"><a href="#赋权限" class="headerlink" title="赋权限"></a>赋权限</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># chown apache:apache cache/ data/ var/</span></span><br><span class="line"><span class="comment"># chown  apache:apache /var/log/smokeping.log</span></span><br><span class="line"><span class="comment"># chmod 755 cache/ data/ var/    #这里也要赋权限，会影响图片无法加载</span></span><br></pre></td></tr></table></figure><h4 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># /usr/local/smokeping/htdocs</span></span><br><span class="line"><span class="comment"># cp -arp smokeping.fcgi.dist smokeping.fcgi</span></span><br><span class="line"><span class="comment"># cd ../etc/</span></span><br><span class="line"><span class="comment"># cp -arp config.dist config</span></span><br><span class="line"><span class="comment"># chmod 600 /usr/local/smokeping/etc/smokeping_secrets.dist</span></span><br><span class="line"><span class="comment"># vim config</span></span><br><span class="line">*** General ***</span><br><span class="line">owner    = Peter Random</span><br><span class="line">contact  = some@address.nowhere</span><br><span class="line">mailhost = my.mail.host</span><br><span class="line">sendmail = /usr/sbin/sendmail</span><br><span class="line"><span class="comment"># <span class="doctag">NOTE:</span> do not put the Image Cache below cgi-bin</span></span><br><span class="line"><span class="comment"># since all files under cgi-bin will be executed ... this is not</span></span><br><span class="line"><span class="comment"># good for images.</span></span><br><span class="line">imgcache = /usr/<span class="built_in">local</span>/smokeping/cache</span><br><span class="line">imgurl   = http://172.16.1.100/cache                                                      <span class="comment">#这里如果不配置正确，会影响后面出图，这里一个坑</span></span><br><span class="line">datadir  = /usr/<span class="built_in">local</span>/smokeping/data</span><br><span class="line">piddir  = /usr/<span class="built_in">local</span>/smokeping/var</span><br><span class="line">cgiurl   = http://172.16.1.100/smokeping/smokeping.cgi</span><br><span class="line"><span class="comment">#cgiurl   = http://some.url/smokeping.cgi</span></span><br><span class="line">smokemail = /usr/<span class="built_in">local</span>/smokeping/etc/smokemail.dist</span><br><span class="line">tmail = /usr/<span class="built_in">local</span>/smokeping/etc/tmail.dist</span><br><span class="line"><span class="comment"># specify this to get syslog logging</span></span><br><span class="line">syslogfacility = local0</span><br><span class="line"><span class="comment"># each probe is now run in its own process</span></span><br><span class="line"><span class="comment"># disable this to revert to the old behaviour</span></span><br><span class="line"><span class="comment"># concurrentprobes = no</span></span><br><span class="line">*** Alerts ***</span><br><span class="line">to = alertee@address.somewhere</span><br><span class="line">from = smokealert@company.xy</span><br><span class="line">+someloss</span><br><span class="line"><span class="built_in">type</span> = loss</span><br><span class="line"><span class="comment"># in percent</span></span><br><span class="line">pattern = &gt;0%,*12*,&gt;0%,*12*,&gt;0%</span><br><span class="line">comment = loss 3 <span class="built_in">times</span>  <span class="keyword">in</span> a row</span><br><span class="line">*** Database ***</span><br><span class="line">step     = 60                                              <span class="comment">#检测时间，默认300</span></span><br><span class="line">pings    = 20</span><br></pre></td></tr></table></figure><p>配置文件上述修改带有注视部分，其他参数参考官方，而且都能看懂。后面有很多配置不全部贴出来</p><h3 id="配置apache"><a href="#配置apache" class="headerlink" title="配置apache"></a>配置apache</h3><h4 id="配置httpd-conf"><a href="#配置httpd-conf" class="headerlink" title="配置httpd.conf"></a>配置httpd.conf</h4><p>在DocumentRoot “/var/www/html”这行增加如下内容</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># vim /etc/httpd/conf/httpd.conf</span></span><br><span class="line">Alias /cache <span class="string">"/usr/local/smokeping/cache"</span></span><br><span class="line">Alias /cropper <span class="string">"/usr/local/smokeping/htdocs/cropper"</span></span><br><span class="line">Alias /smokeping <span class="string">"/usr/local/smokeping/htdocs/smokeping.fcgi"</span></span><br><span class="line">&lt;Directory <span class="string">"/usr/local/smokeping"</span>&gt;</span><br><span class="line">        AllowOverride None</span><br><span class="line">        Options All</span><br><span class="line">        AddHandler cgi-script .fcgi .cgi</span><br><span class="line">        Order allow,deny</span><br><span class="line">        Allow from all</span><br><span class="line">        AuthName <span class="string">"Smokeping"</span></span><br><span class="line">        AuthType Basic</span><br><span class="line">        AuthUserFile /usr/<span class="built_in">local</span>/smokeping/htdocs/htpasswd</span><br><span class="line">        Require valid-user</span><br><span class="line">        DirectoryIndex smokeping.fcgi</span><br><span class="line">&lt;/Directory&gt;</span><br></pre></td></tr></table></figure><h4 id="apache登录认证"><a href="#apache登录认证" class="headerlink" title="apache登录认证"></a>apache登录认证</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># /usr/local/smokeping/htdocs</span></span><br><span class="line"><span class="comment"># htpasswd -c /usr/local/smokeping/htdocs/htpasswd admin                   #回车设置admin账户的密码</span></span><br></pre></td></tr></table></figure><h4 id="安装网页支持的中文字体"><a href="#安装网页支持的中文字体" class="headerlink" title="安装网页支持的中文字体"></a>安装网页支持的中文字体</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># yum -y install wqy-zenhei-fonts.noarch</span></span><br></pre></td></tr></table></figure><h4 id="smokeping开机脚本"><a href="#smokeping开机脚本" class="headerlink" title="smokeping开机脚本"></a>smokeping开机脚本</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># vim /etc/init.d/smokeping</span></span><br><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">PIDFILE=/usr/<span class="built_in">local</span>/smokeping/var/smokeping.pid</span><br><span class="line">SMOKEPING=/usr/<span class="built_in">local</span>/smokeping/bin/smokeping</span><br><span class="line">ERROR=0</span><br><span class="line">RUNNING=0</span><br><span class="line">ARGV=<span class="string">"<span class="variable">$@</span>"</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="string">"x<span class="variable">$ARGV</span>"</span> = <span class="string">"x"</span> ] ; <span class="keyword">then</span></span><br><span class="line">ARGS=<span class="built_in">help</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="keyword">for</span> ARG <span class="keyword">in</span> <span class="variable">$@</span> <span class="variable">$ARGS</span></span><br><span class="line"><span class="keyword">do</span></span><br><span class="line"><span class="keyword">if</span> [ -f <span class="variable">$PIDFILE</span> ] ; <span class="keyword">then</span></span><br><span class="line">PID=`cat <span class="variable">$PIDFILE</span>`</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">kill</span> -0 <span class="variable">$PID</span> 2&gt;/dev/null ; <span class="keyword">then</span></span><br><span class="line"><span class="comment"># smokeping is running</span></span><br><span class="line">RUNNING=1</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="comment"># smokeping not running but PID file exists =&gt; delete PID file</span></span><br><span class="line">rm -f <span class="variable">$PIDFILE</span></span><br><span class="line">RUNNING=0</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="comment"># smokeping (no pid file) not running</span></span><br><span class="line">RUNNING=0</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="keyword">case</span> <span class="variable">$ARG</span> <span class="keyword">in</span></span><br><span class="line">start)</span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$RUNNING</span> -eq 0 ] ; <span class="keyword">then</span></span><br><span class="line"><span class="keyword">if</span> <span class="variable">$SMOKEPING</span> &gt; /dev/null; <span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"<span class="variable">$0</span> <span class="variable">$ARG</span>: smokeping started"</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"<span class="variable">$0</span> <span class="variable">$ARG</span>: smokeping could not be started"</span></span><br><span class="line">ERROR=1</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"<span class="variable">$0</span> <span class="variable">$ARG</span>: smokeping is running with PID <span class="variable">$PID</span>"</span></span><br><span class="line">ERROR=2</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line">;;</span><br><span class="line">stop)</span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$RUNNING</span> -eq 1 ] ; <span class="keyword">then</span></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">kill</span> <span class="variable">$PID</span> ; <span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"<span class="variable">$0</span> <span class="variable">$ARG</span>: smokeping (<span class="variable">$PID</span>) stopped"</span></span><br><span class="line">rm <span class="variable">$PIDFILE</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"<span class="variable">$0</span> <span class="variable">$ARG</span>: smokeping could not be stopped"</span></span><br><span class="line">ERROR=3</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"<span class="variable">$0</span> <span class="variable">$ARG</span>: smokeping not running"</span></span><br><span class="line">ERROR=4</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line">;;</span><br><span class="line">restart)</span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$RUNNING</span> -eq 1 ] ; <span class="keyword">then</span></span><br><span class="line"><span class="keyword">if</span> <span class="variable">$SMOKEPING</span> --restart &gt; /dev/null; <span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"<span class="variable">$0</span> <span class="variable">$ARG</span>: smokeping restarted"</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"<span class="variable">$0</span> <span class="variable">$ARG</span>: smokeping could not be started"</span></span><br><span class="line">ERROR=5</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="variable">$0</span> start</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line">;;</span><br><span class="line">strace_debug)</span><br><span class="line">rm -f /tmp/strace_smokeping</span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$RUNNING</span> -eq 1 ] ; <span class="keyword">then</span></span><br><span class="line"><span class="keyword">if</span> strace -o/tmp/strace_smokeping <span class="variable">$SMOKEPING</span> --restart &gt;/dev/null; <span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"<span class="variable">$0</span> <span class="variable">$ARG</span>: smokeping restarted with strace debug in /tmp/strace_smokeping"</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"<span class="variable">$0</span> <span class="variable">$ARG</span>: smokeping strace debug could not be started"</span></span><br><span class="line">ERROR=6</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="keyword">if</span> strace -o/tmp/strace_smokeping <span class="variable">$SMOKEPING</span> &gt;/dev/null; <span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"<span class="variable">$0</span> <span class="variable">$ARG</span>: smokeping started with strace debug in /tmp/strace_smokeping"</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"<span class="variable">$0</span> <span class="variable">$ARG</span>: smokeping strace debug could not be started"</span></span><br><span class="line">ERROR=7</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line">;;</span><br><span class="line">status)</span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$RUNNING</span> -eq 1 ] ; <span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"<span class="variable">$0</span> <span class="variable">$ARG</span>: smokeping is running with PID (<span class="variable">$PID</span>)"</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"<span class="variable">$0</span> <span class="variable">$ARG</span>: smokeping is not running"</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line">;;</span><br><span class="line">*)</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"usage: <span class="variable">$0</span> (start|stop|restart|status|strace_debug|help)"</span></span><br><span class="line">cat</span><br><span class="line">start - start smokeping</span><br><span class="line">stop - stop smokeping</span><br><span class="line">restart - restart smokeping <span class="keyword">if</span> running or start <span class="keyword">if</span> not running</span><br><span class="line">status - show status <span class="keyword">if</span> smokeping is running or not</span><br><span class="line"><span class="built_in">help</span> - this screen</span><br><span class="line">EOF</span><br><span class="line">;;</span><br><span class="line"><span class="keyword">esac</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"><span class="built_in">exit</span> <span class="variable">$ERROR</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># chmod +x /etc/init.d/smokeping</span></span><br></pre></td></tr></table></figure><h4 id="启动服务"><a href="#启动服务" class="headerlink" title="启动服务"></a>启动服务</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># service httpd start</span></span><br><span class="line"><span class="comment"># /etc/init.d/smokeping start</span></span><br></pre></td></tr></table></figure><p>打开浏览器测试http://{ip}/smokeping  会提示输入用户和密码<br><img src="http://img.xxlaila.cn/74D2C8DE-129F-4219-87C5-D6A771D19484.png" alt="img"><br><img src="http://img.xxlaila.cn/91D9FA70-65B1-4752-8F15-68A158E72A49.png" alt="img"></p><h4 id="配置文件添加"><a href="#配置文件添加" class="headerlink" title="配置文件添加"></a>配置文件添加</h4><p>配置文件添介绍，在配置文件里面+表示一级++表示二级+++三级<br>本次添加的内容</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br></pre></td><td class="code"><pre><span class="line">+ Other</span><br><span class="line">menu = 其他网络监控</span><br><span class="line">title = 其他所有网络监控列表</span><br><span class="line">++ dianxin</span><br><span class="line">menu = 电信网络监控</span><br><span class="line">title = 电信网络监控列表</span><br><span class="line">host = /Other/dianxin/dianxin-hlj /Other/dianxin/dianxin-gd /Other/dianxin/dianxin-gs /Other/dianxin/dianxin-sh /Other/dianxin/dianxin-sc /Other/dianxin/dianxin-cq /Other/dianxin/dianxin-gz /Other/dianxin/dianxin-ln /Other/dianxin/dianxin-zj /Other/dianxin/dianxin-sd /Other/dianxin/dianxin-hib /Other/dianxin/dianxin-ah /Other/dianxin/dianxin-hb /Other/dianxin/dianxin-jl /Other/dianxin/dianxin-jx</span><br><span class="line">+++ dianxin-hlj</span><br><span class="line">menu = 黑龙江电信</span><br><span class="line">title = 黑龙江电信</span><br><span class="line">alerts = someloss</span><br><span class="line"><span class="comment">#slaves = boomer slave2</span></span><br><span class="line">host = 219.150.32.132</span><br><span class="line">+++ dianxin-gd</span><br><span class="line">menu = 广东电信</span><br><span class="line">title = 广东电信</span><br><span class="line">alerts = someloss</span><br><span class="line"><span class="comment">#slaves = boomer slave2</span></span><br><span class="line">host = 202.96.134.133</span><br><span class="line">+++ dianxin-gs</span><br><span class="line">menu = 甘肃电信</span><br><span class="line">title = 甘肃电信</span><br><span class="line">alerts = someloss</span><br><span class="line"><span class="comment">#slaves = boomer slave2</span></span><br><span class="line">host = 202.100.64.68</span><br><span class="line">+++ dianxin-sh</span><br><span class="line">menu = 上海电信</span><br><span class="line">title = 上海电信</span><br><span class="line">alerts = someloss</span><br><span class="line"><span class="comment">#slaves = boomer slave2</span></span><br><span class="line">host = 202.96.209.5</span><br><span class="line">+++ dianxin-sc</span><br><span class="line">menu = 四川电信</span><br><span class="line">title = 四川电信</span><br><span class="line">alerts = someloss</span><br><span class="line">host = 218.6.145.111</span><br><span class="line">+++ dianxin-cq</span><br><span class="line">menu = 重庆电信</span><br><span class="line">title = 重庆电信</span><br><span class="line">alerts = someloss</span><br><span class="line">host = 61.128.128.68</span><br><span class="line">+++ dianxin-gz</span><br><span class="line">menu = 贵州电信</span><br><span class="line">title = 贵州电信</span><br><span class="line">alerts = someloss</span><br><span class="line">host = 202.98.192.68</span><br><span class="line">+++ dianxin-ln</span><br><span class="line">menu = 辽宁电信</span><br><span class="line">title = 辽宁电信</span><br><span class="line">alerts = someloss</span><br><span class="line">host = 219.149.6.99</span><br><span class="line">+++ dianxin-zj</span><br><span class="line">menu = 浙江电信</span><br><span class="line">title = 浙江电信</span><br><span class="line">alerts = someloss</span><br><span class="line">host = 202.96.96.68</span><br><span class="line">+++ dianxin-sd</span><br><span class="line">menu = 山东电信</span><br><span class="line">title = 山东电信</span><br><span class="line">alerts = someloss</span><br><span class="line">host = 222.173.95.53</span><br><span class="line">+++ dianxin-hib</span><br><span class="line">menu = 湖北电信</span><br><span class="line">title = 湖北电信</span><br><span class="line">alerts = someloss</span><br><span class="line">host = 202.103.0.68</span><br><span class="line">+++ dianxin-ah</span><br><span class="line">menu = 安徽电信</span><br><span class="line">title = 安徽电信</span><br><span class="line">alerts = someloss</span><br><span class="line">host = 220.178.75.134</span><br><span class="line">+++ dianxin-hb</span><br><span class="line">menu = 河北电信</span><br><span class="line">title = 河北电信</span><br><span class="line">alerts = someloss</span><br><span class="line">host = 202.99.160.68</span><br><span class="line">+++ dianxin-jl</span><br><span class="line">menu = 吉林电信</span><br><span class="line">title = 吉林电信</span><br><span class="line">alerts = someloss</span><br><span class="line">host =  219.149.194.55</span><br><span class="line">+++ dianxin-jx</span><br><span class="line">menu = 江西电信</span><br><span class="line">title = 江西电信</span><br><span class="line">alerts = someloss</span><br><span class="line">host = 202.101.224.68</span><br><span class="line"><span class="comment">#+++ dianxin-multi</span></span><br><span class="line"><span class="comment">#menu = 多个电信网络监控列表</span></span><br><span class="line"><span class="comment">#title = 多个电信网络监控列表</span></span><br><span class="line"><span class="comment">#alerts = someloss</span></span><br><span class="line"><span class="comment">#slaves = boomer slave2</span></span><br><span class="line"><span class="comment">#host = /Other/dianxin/dianxin-hlj /Other/dianxin/dianxin-gd /Other/dianxin/dianxin-gs /Other/dianxin/dianxin-sh</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line">++ liantong</span><br><span class="line">menu = 联通网络监控</span><br><span class="line">title = 联通网络监控列表</span><br><span class="line">host = /Other/liantong/liantong-hlj /Other/liantong/liantong-gd /Other/liantong/liantong-gs /Other/liantong/liantong-sh /Other/liantong/liantong-sc /Other/liantong/liantong-cq /Other/liantong/liantong-gz /Other/liantong/liantong-ln /Other/liantong/liantong-zj /Other/liantong/liantong-sd /Other/liantong/liantong-hib /Other/liantong/liantong-ah /Other/liantong/liantong-hb /Other/liantong/liantong-jl /Other/liantong/liantong-jx</span><br><span class="line">+++ liantong-hlj</span><br><span class="line">menu = 黑龙江联通</span><br><span class="line">title = 黑龙江联通</span><br><span class="line">alerts = someloss</span><br><span class="line"><span class="comment">#slaves = boomer slave2</span></span><br><span class="line">host = 202.97.224.68</span><br><span class="line">+++ liantong-gd</span><br><span class="line">menu = 广东联通</span><br><span class="line">title = 广东联通</span><br><span class="line">alerts = someloss</span><br><span class="line"><span class="comment">#slaves = boomer slave2</span></span><br><span class="line">host = 221.4.66.66</span><br><span class="line">+++ liantong-gs</span><br><span class="line">menu = 甘肃联通</span><br><span class="line">title = 甘肃联通</span><br><span class="line">alerts = someloss</span><br><span class="line"><span class="comment">#slaves = boomer slave2</span></span><br><span class="line">host = 221.7.34.10</span><br><span class="line">+++ liantong-sh</span><br><span class="line">menu = 上海联通</span><br><span class="line">title = 上海联通</span><br><span class="line">alerts = someloss</span><br><span class="line"><span class="comment">#slaves = boomer slave2</span></span><br><span class="line">host = 210.22.70.3</span><br><span class="line">+++ liantong-sc</span><br><span class="line">menu = 四川联通</span><br><span class="line">title = 四川联通</span><br><span class="line">alerts = someloss</span><br><span class="line">host = 119.6.6.6</span><br><span class="line">+++ liantong-cq</span><br><span class="line">menu = 重庆联通</span><br><span class="line">title = 重庆联通</span><br><span class="line">alerts = someloss</span><br><span class="line">host = 221.7.92.98</span><br><span class="line">+++ liantong-gz</span><br><span class="line">menu = 贵州联通</span><br><span class="line">title = 贵州联通</span><br><span class="line">alerts = someloss</span><br><span class="line">host = 221.13.30.242</span><br><span class="line">+++ liantong-ln</span><br><span class="line">menu = 辽宁联通</span><br><span class="line">title = 辽宁联通</span><br><span class="line">alerts = someloss</span><br><span class="line">host = 124.161.97.234</span><br><span class="line">+++ liantong-zj</span><br><span class="line">menu = 浙江联通</span><br><span class="line">title = 浙江联通</span><br><span class="line">alerts = someloss</span><br><span class="line">host = 221.12.33.227</span><br><span class="line">+++ liantong-sd</span><br><span class="line">menu = 山东联通</span><br><span class="line">title = 山东联通</span><br><span class="line">alerts = someloss</span><br><span class="line">host = 202.102.152.3</span><br><span class="line">+++ liantong-hib</span><br><span class="line">menu = 湖北联通</span><br><span class="line">title = 湖北联通</span><br><span class="line">alerts = someloss</span><br><span class="line">host = 218.104.111.114</span><br><span class="line">+++ liantong-ah</span><br><span class="line">menu = 安徽联通</span><br><span class="line">title = 安徽联通</span><br><span class="line">alerts = someloss</span><br><span class="line">host = 211.91.88.129</span><br><span class="line">+++ liantong-hb</span><br><span class="line">menu = 河北联通</span><br><span class="line">title = 河北联通</span><br><span class="line">alerts = someloss</span><br><span class="line">host = 202.99.160.68</span><br><span class="line">+++ liantong-jl</span><br><span class="line">menu = 吉林联通</span><br><span class="line">title = 吉林联通</span><br><span class="line">alerts = someloss</span><br><span class="line">host = 202.98.5.6</span><br><span class="line">+++ liantong-jx</span><br><span class="line">menu = 江西联通</span><br><span class="line">title = 江西联通</span><br><span class="line">alerts = someloss</span><br><span class="line">host = 220.248.192.12</span><br><span class="line"><span class="comment">#+++ liantong-multi</span></span><br><span class="line"><span class="comment">#menu = 多个联通网络监控列表</span></span><br><span class="line"><span class="comment">#title = 多个联通网络监控列表</span></span><br><span class="line"><span class="comment">#alerts = someloss</span></span><br><span class="line"><span class="comment">#slaves = boomer slave2</span></span><br><span class="line"><span class="comment">#host = /Other/liantong/liantong-hlj /Other/liantong/liantong-gd /Other/liantong/liantong-gs /Other/liantong/liantong-sh</span></span><br><span class="line">++ yidong</span><br><span class="line">menu = 移动网络监控</span><br><span class="line">title = 移动网络监控列表</span><br><span class="line">host = /Other/yidong/yidong-hlj /Other/yidong/yidong-gd /Other/yidong/yidong-gs /Other/yidong/yidong-sh /Other/yidong/yidong-sc /Other/yidong/yidong-cq /Other/yidong/yidong-gz /Other/yidong/yidong-ln /Other/yidong/yidong-zj /Other/yidong/yidong-sd /Other/yidong/yidong-hib /Other/yidong/yidong-ah /Other/yidong/yidong-hb</span><br><span class="line">+++ yidong-hlj</span><br><span class="line">menu = 黑龙江移动</span><br><span class="line">title = 黑龙江移动</span><br><span class="line">alerts = someloss</span><br><span class="line"><span class="comment">#slaves = boomer slave2</span></span><br><span class="line">host = 211.137.241.34</span><br><span class="line">+++ yidong-gd</span><br><span class="line">menu = 广东移动</span><br><span class="line">title = 广东移动</span><br><span class="line">alerts = someloss</span><br><span class="line"><span class="comment">#slaves = boomer slave2</span></span><br><span class="line">host = 211.137.241.34</span><br><span class="line">+++ yidong-gs</span><br><span class="line">menu = 甘肃移动</span><br><span class="line">title = 甘肃移动</span><br><span class="line">alerts = someloss</span><br><span class="line"><span class="comment">#slaves = boomer slave2</span></span><br><span class="line">host = 218.203.160.194</span><br><span class="line">+++ yidong-sh</span><br><span class="line">menu = 上海移动</span><br><span class="line">title = 上海移动</span><br><span class="line">alerts = someloss</span><br><span class="line"><span class="comment">#slaves = boomer slave2</span></span><br><span class="line">host = 117.131.0.22</span><br><span class="line">+++ yidong-sc</span><br><span class="line">menu = 四川移动</span><br><span class="line">title = 四川移动</span><br><span class="line">alerts = someloss</span><br><span class="line">host = 211.137.96.205</span><br><span class="line">+++ yidong-cq</span><br><span class="line">menu = 重庆移动</span><br><span class="line">title = 重庆移动</span><br><span class="line">alerts = someloss</span><br><span class="line">host = 218.201.4.3</span><br><span class="line">+++ yidong-gz</span><br><span class="line">menu = 贵州移动</span><br><span class="line">title = 贵州移动</span><br><span class="line">alerts = someloss</span><br><span class="line">host = 211.139.1.3</span><br><span class="line">+++ yidong-ln</span><br><span class="line">menu = 辽宁移动</span><br><span class="line">title = 辽宁移动</span><br><span class="line">alerts = someloss</span><br><span class="line">host = 218.59.181.182</span><br><span class="line">+++ yidong-zj</span><br><span class="line">menu = 浙江移动</span><br><span class="line">title = 浙江移动</span><br><span class="line">alerts = someloss</span><br><span class="line">host = 211.140.10.2</span><br><span class="line">+++ yidong-sd</span><br><span class="line">menu = 山东移动</span><br><span class="line">title = 山东移动</span><br><span class="line">alerts = someloss</span><br><span class="line">host = 211.137.191.26</span><br><span class="line">+++ yidong-hib</span><br><span class="line">menu = 湖北移动</span><br><span class="line">title = 湖北移动</span><br><span class="line">alerts = someloss</span><br><span class="line">host = 211.137.76.68</span><br><span class="line">+++ yidong-ah</span><br><span class="line">menu = 安徽移动</span><br><span class="line">title = 安徽移动</span><br><span class="line">alerts = someloss</span><br><span class="line">host = 211.138.180.2</span><br><span class="line">+++ yidong-hb</span><br><span class="line">menu = 河北移动</span><br><span class="line">title = 河北移动</span><br><span class="line">alerts = someloss</span><br><span class="line">host = 211.98.2.4</span><br><span class="line"><span class="comment">#+++ yidong-multi</span></span><br><span class="line"><span class="comment">#menu = 多个移动网络监控列表</span></span><br><span class="line"><span class="comment">#title = 多个移动网络监控列表</span></span><br><span class="line"><span class="comment">#alerts = someloss</span></span><br><span class="line"><span class="comment">#slaves = boomer slave2</span></span><br><span class="line"><span class="comment">#host = /Other/yidong/yidong-hlj /Other/yidong/yidong-gd /Other/yidong/yidong-gs /Other/yidong/yidong-sh</span></span><br><span class="line">++ jiaoyu</span><br><span class="line">menu = 教育网络监控</span><br><span class="line">title = 教育网络监控列表</span><br><span class="line">host = /Other/jiaoyu/jiaoyu-qh /Other/jiaoyu/jiaoyu-sh /Other/jiaoyu/jiaoyu-wh /Other/jiaoyu/jiaoyu-hn</span><br><span class="line">+++ jiaoyu-qh</span><br><span class="line">menu = 清华大学</span><br><span class="line">title = 清华大学</span><br><span class="line">alerts = someloss</span><br><span class="line"><span class="comment">#slaves = boomer slave2</span></span><br><span class="line">host = 166.111.8.28</span><br><span class="line">+++ jiaoyu-sh</span><br><span class="line">menu = 上海交大</span><br><span class="line">title = 上海交大</span><br><span class="line">alerts = someloss</span><br><span class="line"><span class="comment">#slaves = boomer slave2</span></span><br><span class="line">host = 202.112.26.34</span><br><span class="line">+++ jiaoyu-wh</span><br><span class="line">menu = 武汉科技大学</span><br><span class="line">title = 武汉科技大学</span><br><span class="line">alerts = someloss</span><br><span class="line"><span class="comment">#slaves = boomer slave2</span></span><br><span class="line">host = 202.114.240.6</span><br><span class="line">+++ jiaoyu-hn</span><br><span class="line">menu = 华南农业大学</span><br><span class="line">title = 华南农业大学</span><br><span class="line">alerts = someloss</span><br><span class="line"><span class="comment">#slaves = boomer slave2</span></span><br><span class="line">host = 202.116.160.33</span><br><span class="line"><span class="comment">#+++ jiaoyu-multi</span></span><br><span class="line"><span class="comment">#menu = 多个教育网络监控列表</span></span><br><span class="line"><span class="comment">#title = 多个教育网络监控列表</span></span><br><span class="line"><span class="comment">#alerts = someloss</span></span><br><span class="line"><span class="comment">#slaves = boomer slave2</span></span><br><span class="line"><span class="comment">#host = /Other/jiaoyu/jiaoyu-qh /Other/jiaoyu/jiaoyu-sh /Other/jiaoyu/jiaoyu-wh /Other/jiaoyu/jiaoyu-hn</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;需求&quot;&gt;&lt;a href=&quot;#需求&quot; class=&quot;headerlink&quot; title=&quot;需求&quot;&gt;&lt;/a&gt;需求&lt;/h3&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;监控IDC机房网络质量情况，本地区到其他地区，其他地区到本节点，或者各省市时间网络、运营商网络状态，监视网络性能，包括常规的 ping，用 fping、echoping、tracert 监视 www 服务器性能，监视 dns 查询性能，监视 ssh 性能等。底层也是 rrdtool 做支持，特点是画的图非常漂亮，网络丢包和延迟用颜色和阴影来表示。&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Smokeping。最新版本的 Smokeping 支持多个节点的检测结果从一个图上画出来&lt;/p&gt;
    
    </summary>
    
      <category term="监控" scheme="https://xxlaila.github.io/categories/%E7%9B%91%E6%8E%A7/"/>
    
    
  </entry>
  
  <entry>
    <title>Linux 常用命令学习</title>
    <link href="https://xxlaila.github.io/2019/09/25/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E5%AD%A6%E4%B9%A0/"/>
    <id>https://xxlaila.github.io/2019/09/25/Linux常用命令学习/</id>
    <published>2019-09-25T03:38:07.000Z</published>
    <updated>2019-09-25T04:24:42.792Z</updated>
    
    <content type="html"><![CDATA[<h4 id="查找文件使用命令"><a href="#查找文件使用命令" class="headerlink" title="查找文件使用命令"></a>查找文件使用命令</h4><ul><li><p>查找目录下面大小超过5M的文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find /home/ -size +5M</span><br></pre></td></tr></table></figure></li><li><p>查找目录下100天之前修改过的文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find /home/ -mtime +100</span><br></pre></td></tr></table></figure></li><li><p>查找目录下60天未被访问过的文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find /home/ \! atime -60</span><br></pre></td></tr></table></figure></li></ul><a id="more"></a><ul><li>查找目录下面文件“core“，如果发现无需提示直接删除。<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">find / -name core -<span class="built_in">exec</span> rm &#123;&#125; \</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查找排除某一个文件然后进行删除</span></span><br><span class="line">find / -<span class="built_in">type</span> f ! -name <span class="string">"test"</span> -<span class="built_in">exec</span> rm &#123;&#125; \;</span><br><span class="line">find ./ -mtime +3 -name <span class="string">"*.log"</span> -<span class="built_in">exec</span> rm -rf &#123;&#125; \;</span><br><span class="line">find /tmp -mtime +30 -<span class="built_in">type</span> f -name *.sh[ab] -<span class="built_in">exec</span> rm -f &#123;&#125; \;</span><br></pre></td></tr></table></figure></li></ul><p>在一个目录中保留最近30天的文件，30天前的文件自动删除</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find /tmp -mtime +30 -<span class="built_in">type</span> f -name *.sh[ab] -<span class="built_in">exec</span> rm -f &#123;&#125; \;</span><br></pre></td></tr></table></figure><ul><li>/tmp  –设置查找的目录；</li><li>-mtime +30 –设置时间为30天前；</li><li>-type f –设置查找的类型为文件；</li><li>-name *.sh[ab] –设置文件名称中包含sha或者shb；</li><li>-exec rm -f –查找完毕后执行删除操作；</li><li><strong>提示</strong>：将此命令写入crontab后即可自动完成查找并删除的工作</li></ul><ul><li>显示目录文件的文件名和它们的拥有者<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ll | awk <span class="string">'&#123;print $3,"owns",$9&#125;'</span></span><br></pre></td></tr></table></figure></li></ul><p>显示你的系统上PCI总线和附加设备的信息。指定-v，-vv或-vvv来获取越来越详细的输出</p><ul><li><p>lspci 安装</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">$ yum whatprovides */lspci</span><br><span class="line">pciutils-3.5.1-2.el7.x86_64 : PCI bus related utilities</span><br><span class="line">Repo        : base</span><br><span class="line">Matched from:</span><br><span class="line">Filename    : /usr/sbin/lspci</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">pciutils-3.5.1-3.el7.x86_64 : PCI bus related utilities</span><br><span class="line">Repo        : base</span><br><span class="line">Matched from:</span><br><span class="line">Filename    : /usr/sbin/lspci</span><br><span class="line"></span><br><span class="line">$ yum install pciutils</span><br><span class="line"></span><br><span class="line">lspci 更多[详细使用](https://blog.csdn.net/styshoo/article/details/51281437)</span><br><span class="line"></span><br><span class="line">``` bash</span><br><span class="line">lspci -vvvvv</span><br></pre></td></tr></table></figure></li><li><p>查看当前的Linux服务器的运行级别</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ who -r</span><br><span class="line">$ who -b </span><br><span class="line"><span class="comment"># 查看系统最后一次启动的时间</span></span><br><span class="line"></span><br><span class="line">$ last reboot</span><br><span class="line"><span class="comment"># 查看系统历史启动的时间</span></span><br></pre></td></tr></table></figure></li><li><p>查看系统运行了多长时间</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ cat /proc/uptime| awk -F. <span class="string">'&#123;run_days=$1 / 86400;run_hour=($1 % 86400)/3600;run_minute=($1 % 3600)/60;run_second=$1 % 60;printf("系统已运行：%d天%d时%d分%d秒",run_days,run_hour,run_minute,run_second)&#125;'</span></span><br><span class="line">$ w</span><br><span class="line">$ uptime</span><br></pre></td></tr></table></figure></li><li><p>查看系统启动的日期</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ date -d <span class="string">"<span class="variable">$(awk -F. '&#123;print $1&#125;' /proc/uptime)</span> second ago"</span> +<span class="string">"%Y-%m-%d %H:%M:%S"</span></span><br></pre></td></tr></table></figure></li><li><p>查找目录下文件内容没有包括“nginx”、“msgType”字符串的文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">grep -r -l -v <span class="string">"nginx"</span> /data/</span><br><span class="line">grep -r  -v <span class="string">"msgType"</span> /data/</span><br></pre></td></tr></table></figure></li><li><p>查找目录下文件内容包括”nginx”字符串的文件。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">grep -r <span class="string">"nginx"</span> /data/                                             会把<span class="string">"nginx"</span>字符串所在这行的内容显示出来</span><br><span class="line">grep -o “nginx” /data/</span><br><span class="line">grep -r -l <span class="string">"nginx"</span> /data/                                          不显示<span class="string">"nginx"</span>字符串所在行，是显示文件</span><br></pre></td></tr></table></figure></li><li><p>cat使用</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$cat</span> sentry.conf.py |grep -v <span class="string">"^#"</span>          查看配置文件不包括注释内容</span><br><span class="line">$ cat -b `find /var/<span class="built_in">log</span>/httpd/ -cmin -60 -<span class="built_in">print</span> |sed <span class="string">"1d"</span>`\ |awk <span class="string">'&#123;print $2&#125;'</span>|sort |uniq -c |sort -n -k 1 -r |head -n 1               统计当前目录下日志文件里面I平访问量最多的一个IP</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看某一个时间段的IP地址访问排名前10</span></span><br><span class="line">$ cat nginx_access.log|grep <span class="string">'+0800'</span>|awk <span class="string">'&#123;split($1,array,"[");if(array[2]&gt;="25/Jul/2017:14:17:30" &amp;&amp; array[2]&lt;="25/Jul/2017:20:17:30")&#123;print $0&#125;&#125;'</span>|awk -F<span class="string">"^`"</span> &amp;&amp; <span class="string">"-"</span> &amp;&amp; <span class="string">"^`"</span> <span class="string">'&#123;print $1&#125;'</span>|sort|uniq -c|sort -n -k 1 -r|head -n 10</span><br><span class="line"></span><br><span class="line"><span class="comment"># 统计当前日志ip访问前10</span></span><br><span class="line">$ cat nginx_access.log |awk -F<span class="string">"^"</span> <span class="string">'&#123;print $1&#125;'</span>|sort|uniq -c|sort -n -k 1 -r|head -n 10</span><br></pre></td></tr></table></figure></li><li><p>获取IP地址通用</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ifconfig |sed -n 2p |awk <span class="string">'&#123;print $1$2&#125;'</span>|sed <span class="string">'s/^.*[^0-9]\([0-9]\&#123;1,3\&#125;\)\.\([0-9]\&#123;1,3\&#125;\)\.\([0-9]\&#123;1,3\&#125;\)\.\([0-9]\&#123;1,3\&#125;\)$/\1\.\2\.\3\.\4/g'</span></span><br></pre></td></tr></table></figure></li><li><p>curl使用</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 监控网页的响应时间</span></span><br><span class="line">$ curl -o /dev/null -s -w <span class="string">"time_connect: %&#123;time_connect&#125;\ntime_starttransfer: %&#123;time_starttransfer&#125;\ntime_total: %&#123;time_total&#125;\n"</span> <span class="string">"http://www.baidu.com"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 监控站点可用性</span></span><br><span class="line">$ curl -o /dev/null -s -w %&#123;http_code&#125; <span class="string">"http://www.baidu.com"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 开启gzip请求</span></span><br><span class="line">$ curl -I http://www.sina.com.cn/ -H Accept-Encoding:gzip,defalte</span><br></pre></td></tr></table></figure></li><li><p>每10秒显示一次复制的大小</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">watch -n 10 du -sh /root</span><br></pre></td></tr></table></figure></li><li><p>统计目录(包括子目录)下面文件个数</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">find ./ -<span class="built_in">type</span> f | wc -l</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用find命令查找当前目录下是文件类型的文件，然后用wc来计数</span></span><br><span class="line">$ ls -lR|grep <span class="string">"^-"</span>|wc -l</span><br><span class="line"><span class="comment"># ls命令加R参数，列出下级子目录，使用grep命令过滤以“-”开头的，如果是目录就改成“^d”，后面用wc计数。</span></span><br><span class="line"></span><br><span class="line">$ find ./ -name <span class="string">"*.*"</span> |xargs cat|grep -v ^$|wc -l</span><br><span class="line">$ find . \( ! -name <span class="string">'*.png'</span> ! -name <span class="string">'*.gif'</span> ! -name <span class="string">'*.jpg'</span> ! -name <span class="string">'*.swf'</span> \) -<span class="built_in">type</span> f |wc -l</span><br><span class="line"></span><br><span class="line"><span class="comment"># 统计目录下所有文件的的行数，去掉空行</span></span><br><span class="line">$ find ./ -name <span class="string">"*.*"</span> |xargs cat|wc -l   </span><br><span class="line">$ find . \( ! -name <span class="string">'*.png'</span> ! -name <span class="string">'*.gif'</span> ! -name <span class="string">'*.jpg'</span> ! -name <span class="string">'*.swf'</span> \) -<span class="built_in">type</span> f |xargs cat|wc -l</span><br></pre></td></tr></table></figure></li><li><p>查看系统tcp连接中各个状态的连接数</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># netstat -an | awk '/^tcp/ &#123;++S[$NF]&#125; END &#123;for(a in S) print a, S[a]&#125;'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出每个IP的连接数，以及总的各个状态的连接数</span></span><br><span class="line">$ netstat -n | awk <span class="string">'/^tcp/ &#123;n=split($(NF-1),array,":");if(n&lt;=2)++S[array[(1)]];else++S[array[(4)]];++s[$NF];++N&#125; END &#123;for(a in S)&#123;printf("%-20s %s\n", a, S[a]);++I&#125;printf("%-20s %s\n","TOTAL_IP",I);for(a in s) printf("%-20s %s\n",a, s[a]);printf("%-20s %s\n","TOTAL_LINK",N);&#125;'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 统计当前tcp/ip链接数排名前10的IP</span></span><br><span class="line">$ netstat -n|awk <span class="string">'/^tcp/ &#123;print $5&#125;'</span>|awk -F<span class="string">':'</span> <span class="string">'&#123;print $1&#125;'</span>|sort|uniq -c|sort -n -k 1 -r|head -n 10</span><br><span class="line"></span><br><span class="line"><span class="comment"># 利用grep统计当前文件里面所有的IP地址</span></span><br><span class="line">$ grep -E -o <span class="string">"(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)"</span> nginx_access.log</span><br></pre></td></tr></table></figure></li></ul><p>查看系统当前进程打开的文件句柄数，按照最大的进行排序</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ lsof -n | awk <span class="string">'&#123;print $2&#125;'</span> | sort | uniq -c | sort -nr | more</span><br></pre></td></tr></table></figure><ul><li>ping命令显示时间以及日期<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ping www.sina.com.cn -i 3 | awk <span class="string">'&#123; print $0"\t" strftime("%Y-%m-%d %H:%M:%S",systime()) &#125; '</span> &gt; /opt/sina.log &amp;</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;查找文件使用命令&quot;&gt;&lt;a href=&quot;#查找文件使用命令&quot; class=&quot;headerlink&quot; title=&quot;查找文件使用命令&quot;&gt;&lt;/a&gt;查找文件使用命令&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;查找目录下面大小超过5M的文件&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;find /home/ -size +5M&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;查找目录下100天之前修改过的文件&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;find /home/ -mtime +100&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;查找目录下60天未被访问过的文件&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;find /home/ \! atime -60&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="linux" scheme="https://xxlaila.github.io/categories/linux/"/>
    
    
      <category term="shell" scheme="https://xxlaila.github.io/tags/shell/"/>
    
  </entry>
  
  <entry>
    <title>iptables</title>
    <link href="https://xxlaila.github.io/2019/09/25/iptables/"/>
    <id>https://xxlaila.github.io/2019/09/25/iptables/</id>
    <published>2019-09-25T02:19:11.000Z</published>
    <updated>2019-09-25T03:34:08.113Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Iptables"><a href="#Iptables" class="headerlink" title="Iptables"></a>Iptables</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Iptalbes 是用来设置、维护和检查Linux内核的IP包过滤规则的。可以定义不同的表，每个表都包含几个内部的链，也能包含用户定义的链。每个链都是一个规则列表，对对应的包进行匹配：每条规则指定应当如何处理与之相匹配的包。这被称作’target’（目标），也可以跳向同一个表内的用户定义的链。</p><a id="more"></a><h4 id="iptables限制IP访问特定端口"><a href="#iptables限制IP访问特定端口" class="headerlink" title="iptables限制IP访问特定端口"></a>iptables限制IP访问特定端口</h4><ul><li><p>允许某个IP （192.168.6.100）的机器进行SSH连接：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ iptables -A INPUT -s 192.168.6.100 -p tcp --dport 22 -j ACCEPT</span><br><span class="line">$ iptables -L -n</span><br><span class="line">Chain INPUT (policy ACCEPT)</span><br><span class="line">target prot opt <span class="built_in">source</span> destination</span><br><span class="line">ACCEPT tcp -- 192.168.6.100 0.0.0.0/0 tcp dpt:22</span><br></pre></td></tr></table></figure></li><li><p>允许某一段的IP 访问SSH</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ iptables -A INPUT -s 192.168.6.0/24 -p tcp --dport 22 -j ACCEPT</span><br><span class="line">$ iptables -L -n</span><br><span class="line">Chain INPUT (policy ACCEPT)</span><br><span class="line">target prot opt <span class="built_in">source</span> destination</span><br><span class="line">ACCEPT tcp -- 192.168.6.0/24 0.0.0.0/0 tcp dpt:22</span><br></pre></td></tr></table></figure></li><li><p>限制某一IP 访问SSH</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ iptables -A INPUT -p tcp -s ! 192.168.6.100 --dport 22 -j ACCEPT --注意！号有个空格</span><br><span class="line">$ iptables -L -n</span><br><span class="line">Chain INPUT (policy ACCEPT)</span><br><span class="line">target prot opt <span class="built_in">source</span> destination</span><br><span class="line">ACCEPT tcp -- 192.168.6.0/24 0.0.0.0/0 tcp dpt:22</span><br></pre></td></tr></table></figure></li></ul><h3 id="配置一个NAT表放火墙"><a href="#配置一个NAT表放火墙" class="headerlink" title="配置一个NAT表放火墙"></a>配置一个NAT表放火墙</h3><ul><li><p>防止外网用内网IP欺骗</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ iptables -t nat -A PREROUTING -i eth0 -s 10.0.0.0/8 -j DROP</span><br><span class="line">$ iptables -t nat -A PREROUTING -i eth0 -s 172.16.0.0/12 -j DROP</span><br><span class="line">$ iptables -t nat -A PREROUTING -i eth0 -s 192.168.0.0/16 -j DROP</span><br></pre></td></tr></table></figure></li><li><p>禁止与211.101.46.253的所有连接</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ iptables -t nat -A PREROUTING -d 211.101.46.253 -j DROP</span><br></pre></td></tr></table></figure></li><li><p>禁用FTP(21)端口</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ iptables -t nat -A PREROUTING -p tcp --dport 21 -j DROP</span><br><span class="line"><span class="comment"># 这样写范围太大了,我们可以更精确的定义.</span></span><br><span class="line">$ iptables -t nat -A PREROUTING -p tcp --dport 21 -d 211.101.46.253 -j DROP</span><br><span class="line"><span class="comment"># 这样只禁用211.101.46.253地址的FTP连接,其他连接还可以.如web(80端口)连接.</span></span><br></pre></td></tr></table></figure></li><li><p>iptables白名单</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ iptables -A INPUT -s 0.0.0.0/0 -p tcp --dport 80 -j DROP</span><br><span class="line"><span class="comment"># 拒绝所有IP链接80端口</span></span><br><span class="line"></span><br><span class="line">$ iptables -A INPUT -s 58.17.245.222 -p tcp --dport 80 -j ACCEPT</span><br><span class="line"><span class="comment"># 允许指定IP访问80端口</span></span><br></pre></td></tr></table></figure></li><li><p>允许所有已经建立的和相关的连接</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT</span><br><span class="line">$ iptables -A OUTPUT -m state --state ESTABLISHED,RELATED -j ACCEPT</span><br></pre></td></tr></table></figure></li><li><p>drop非法连接</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ iptables -A INPUT -m state --state INVALID -j DROP</span><br><span class="line">$ iptables -A OUTPUT -m state --state INVALID -j DROP</span><br><span class="line">$ iptables -A FORWARD -m state --state INVALID -j DROP</span><br></pre></td></tr></table></figure></li></ul><h3 id="端口映射"><a href="#端口映射" class="headerlink" title="端口映射"></a>端口映射</h3><ul><li>这里使用的是FTP服务(36542)<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ iptables -t nat -A PREROUTING -p tcp --dport 36542 -j DNAT --to 192.168.50.2:36542</span><br><span class="line">$ iptables -t nat -A POSTROUTING -p tcp --dport 36542 -j MASQUERADE</span><br><span class="line"><span class="comment"># 因为FTP使用了两个端口21和20，21只是用于连接，20是执行命令的。20没办法修改，这里使用了被动模式连接。</span></span><br><span class="line"></span><br><span class="line">$ iptables -t nat -I PREROUTING -p tcp --dport 60000:65000 -j DNAT --to 192.168.50.2</span><br><span class="line"><span class="comment"># 被动连接端口60000-65000全部转发给50.2</span></span><br><span class="line"></span><br><span class="line">$ iptables -t nat -I POSTROUTING -p tcp --dport 60000:65000 -j MASQUERADE</span><br><span class="line"><span class="comment"># 需要开放60000:65000端口，</span></span><br></pre></td></tr></table></figure></li></ul><h3 id="端口转发"><a href="#端口转发" class="headerlink" title="端口转发"></a>端口转发</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;公司有一台服务器连接外网，其他的服务器都不能上外网，我们可以通过这个外网服务器用作网关服务器，做端口转发，连接到内网服务器</p><ul><li><p>这里使用数据库的3306映射到外网的的36544</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ iptables -t nat -A PREROUTING  -m tcp -p tcp --dport 36544 -j DNAT --to-destination 172.16.1.11:3306</span><br><span class="line">$ iptables -t nat -A POSTROUTING -m tcp -p tcp --dport 3306 -d 172.16.1.11 -j SNAT --to-source 172.16.1.1</span><br></pre></td></tr></table></figure></li><li><p>添加连续端口</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ iptables -A INPUT -p tcp --dport 60000:65000 -j ACCEPT</span><br><span class="line"><span class="comment"># 冒号表示添加一个连续的端口</span></span><br><span class="line"></span><br><span class="line">$ iptables -A INPUT -p tcp -m multiport –dport 21:25,135:139 -j DROP</span><br><span class="line"><span class="comment">#使用multiport参数配置不连续端口和多个端口</span></span><br></pre></td></tr></table></figure></li><li><p>代理上网<br>内网机子无法上网，通过一台可以上网的电脑，在可以访问外网的server上iptables让其一个网段内的机子访问外网，这里是阿里云环境来做的，开启IP转发功能</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sed -i <span class="string">'s/net.ipv4.ip_forward = 0/net.ipv4.ip_forward = 1/g'</span> /etc/sysctl.conf</span><br><span class="line">$ iptables -t nat -I POSTROUTING -s 172.16.3.0/24 -j SNAT --to-source 172.16.3.2</span><br></pre></td></tr></table></figure></li></ul><h4 id="操作iptables的nat规则"><a href="#操作iptables的nat规则" class="headerlink" title="操作iptables的nat规则"></a>操作iptables的nat规则</h4><ul><li><p>查看规则</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ iptables -nvL -t nat</span><br><span class="line">$ iptables -t nat -L -n --line-numbers</span><br></pre></td></tr></table></figure></li><li><p>删除规则</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ iptables -t nat -D POSTROUTING 1</span><br><span class="line"></span><br><span class="line"><span class="comment"># iptables的规则号</span></span><br><span class="line">$ iptables -nL --line-number</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改/替换规则</span></span><br><span class="line">$ iptbales -R INPUT &#123;1&#125; -j ACCEPT</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除规则</span></span><br><span class="line">$ iptables -D INPUT &#123;1&#125;</span><br></pre></td></tr></table></figure></li><li><p>iptales端口通过一张网卡出去</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ iptables -A INPUT -i eth0 -p tcp -s 192.168.100.0/24 --dport 22 -m state --state NEW,ESTABLESHED -j ACCEPT</span><br><span class="line">$ iptables -A OUTPUT -o eth0 -p tcp --sport 22 -m state --state ESTABLISHED -j ACCEPT</span><br></pre></td></tr></table></figure></li><li><p>本机端口，映射到本机端口</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ iptables -t nat -A PREROUTING -i eth0 -p tcp --dport 25 -j REDIRECT --to-port 2525</span><br><span class="line">$ iptables -t nat -I PREROUTING --src 0/0 --dst 192.168.1.5 -p tcp --dport 80 -j REDIRECT --to-ports 8123</span><br><span class="line">$ iptables -t nat -I OUTPUT --src 0/0 --dst 192.168.1.5 -p tcp --dport 80 -j REDIRECT --to-ports 8123</span><br></pre></td></tr></table></figure></li><li><p>保存防火墙</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo /usr/libexec/iptables/iptables.init save</span><br></pre></td></tr></table></figure></li><li><p>奇葩需求，开放ssh端口指定的IP地址访问，其他端口太多不想添加能对外访问</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">$ cat /etc/sysconfig/iptables</span><br><span class="line"></span><br><span class="line"><span class="comment"># sample configuration for iptables service</span></span><br><span class="line"><span class="comment"># you can edit this manually or use system-config-firewall</span></span><br><span class="line"><span class="comment"># please do not ask us to add additional ports/services to this default configuration</span></span><br><span class="line">*filter</span><br><span class="line">:INPUT ACCEPT [0:0]</span><br><span class="line">:FORWARD ACCEPT [0:0]</span><br><span class="line">:OUTPUT ACCEPT [0:0]</span><br><span class="line">-A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT</span><br><span class="line">-A INPUT -s 192.168.10.1/32 -p tcp -m tcp --dport 22 -j ACCEPT</span><br><span class="line">-A INPUT -p tcp -m tcp --dport 22 -j  REJECT --reject-with icmp-port-unreachable</span><br><span class="line"><span class="comment">#-A INPUT -j REJECT --reject-with icmp-host-prohibited</span></span><br><span class="line"><span class="comment">#-A FORWARD -j REJECT --reject-with icmp-host-prohibited</span></span><br><span class="line">COMMIT</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Iptables&quot;&gt;&lt;a href=&quot;#Iptables&quot; class=&quot;headerlink&quot; title=&quot;Iptables&quot;&gt;&lt;/a&gt;Iptables&lt;/h3&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Iptalbes 是用来设置、维护和检查Linux内核的IP包过滤规则的。可以定义不同的表，每个表都包含几个内部的链，也能包含用户定义的链。每个链都是一个规则列表，对对应的包进行匹配：每条规则指定应当如何处理与之相匹配的包。这被称作’target’（目标），也可以跳向同一个表内的用户定义的链。&lt;/p&gt;
    
    </summary>
    
      <category term="linux" scheme="https://xxlaila.github.io/categories/linux/"/>
    
    
      <category term="iptables" scheme="https://xxlaila.github.io/tags/iptables/"/>
    
  </entry>
  
  <entry>
    <title>交换机做端口聚合</title>
    <link href="https://xxlaila.github.io/2019/09/25/%E4%BA%A4%E6%8D%A2%E6%9C%BA%E5%81%9A%E7%AB%AF%E5%8F%A3%E8%81%9A%E5%90%88/"/>
    <id>https://xxlaila.github.io/2019/09/25/交换机做端口聚合/</id>
    <published>2019-09-25T02:09:47.000Z</published>
    <updated>2019-09-26T03:13:12.855Z</updated>
    
    <content type="html"><![CDATA[<p><strong>应用场景</strong>：h3c s5500 (Switch A)。huawei s5720S-SI-AC（Switch B）</p><p>Switch A 作为上行交换机，Switch B作为下行交换机</p><p><strong>组网</strong>：两个交换机的id、vlan号这里使用的是相同</p><a id="more"></a><p><img src="http://img.xxlaila.cn/2846sjdhausiy84yhks.png" alt="img"></p><h3 id="Switch-A配置"><a href="#Switch-A配置" class="headerlink" title="Switch A配置"></a>Switch A配置</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[Switch A-SW]vlan 50</span><br><span class="line">[Switch A-SW-vlan50]quit</span><br><span class="line">[Switch A-SW]interface Bridge-Aggregation 50</span><br><span class="line">[Switch A-SW-Bridge-Aggregation50]port access vlan 50</span><br><span class="line">[Switch A-SW]interface GigabitEthernet 1/0/19</span><br><span class="line">[Switch A-SW-GigabitEthernet1/0/19]port link-aggregation group 50</span><br><span class="line">[Switch A-SW-GigabitEthernet1/0/19] port access vlan 50</span><br><span class="line">[Switch A-SW]interface GigabitEthernet 1/0/20</span><br><span class="line">[Switch A-SW-GigabitEthernet1/0/20]port link-aggregation group 50</span><br><span class="line">[Switch A-SW-GigabitEthernet1/0/20]port access vlan 50</span><br><span class="line">[Switch A-SW]link-aggregation load-sharing mode <span class="built_in">source</span>-mac destination-mac</span><br></pre></td></tr></table></figure><ul><li>查看端口聚合<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[Switch A-SW]dis link-aggregation verbose</span><br></pre></td></tr></table></figure></li></ul><h3 id="Switch-B配置"><a href="#Switch-B配置" class="headerlink" title="Switch B配置"></a>Switch B配置</h3><h4 id="1、创建eth-trunk接口并加入成员"><a href="#1、创建eth-trunk接口并加入成员" class="headerlink" title="1、创建eth-trunk接口并加入成员"></a>1、创建eth-trunk接口并加入成员</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[Switch B] interface eth-trunk 50</span><br><span class="line">[Switch B-Eth-Trunk1] trunkport gigabitethernet 0/0/1 to 0/0/3</span><br><span class="line">[Switch B-Eth-Trunk1] quit</span><br></pre></td></tr></table></figure><h4 id="2、创建vlan并吧串行加入vlan"><a href="#2、创建vlan并吧串行加入vlan" class="headerlink" title="2、创建vlan并吧串行加入vlan"></a>2、创建vlan并吧串行加入vlan</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[Switch B] vlan batch 50</span><br><span class="line">[Switch B] interface eth-trunk 50</span><br><span class="line">[Switch B-Eth-Trunk1] port link-type trunk</span><br><span class="line">[Switch B-Eth-Trunk1] port trunk allow-pass vlan 50</span><br><span class="line">[Switch B-Eth-Trunk1] quit</span><br></pre></td></tr></table></figure><h4 id="3、配置eth-trunk的负载分担方式"><a href="#3、配置eth-trunk的负载分担方式" class="headerlink" title="3、配置eth-trunk的负载分担方式"></a>3、配置eth-trunk的负载分担方式</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[Switch B] interface eth-trunk 1</span><br><span class="line">[Switch B-Eth-Trunk1] load-balance src-dst-mac</span><br><span class="line">[Switch B-Eth-Trunk1] quit</span><br></pre></td></tr></table></figure><h3 id="Switch-A配置地址段"><a href="#Switch-A配置地址段" class="headerlink" title="Switch A配置地址段"></a>Switch A配置地址段</h3><p>在vlan里面起一个网络，但不启用dhcp服务</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[Switch A-SW]int vlan 50</span><br><span class="line">[Switch A-SW-Vlan-interface50]ip ad 172.21.16.1 20</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;应用场景&lt;/strong&gt;：h3c s5500 (Switch A)。huawei s5720S-SI-AC（Switch B）&lt;/p&gt;
&lt;p&gt;Switch A 作为上行交换机，Switch B作为下行交换机&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;组网&lt;/strong&gt;：两个交换机的id、vlan号这里使用的是相同&lt;/p&gt;
    
    </summary>
    
      <category term="网络设备" scheme="https://xxlaila.github.io/categories/%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87/"/>
    
    
      <category term="交换机" scheme="https://xxlaila.github.io/tags/%E4%BA%A4%E6%8D%A2%E6%9C%BA/"/>
    
  </entry>
  
  <entry>
    <title>pv pvc</title>
    <link href="https://xxlaila.github.io/2019/09/25/pv-pvc/"/>
    <id>https://xxlaila.github.io/2019/09/25/pv-pvc/</id>
    <published>2019-09-25T01:46:10.000Z</published>
    <updated>2019-09-25T01:59:18.795Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1、介绍"><a href="#1、介绍" class="headerlink" title="1、介绍"></a>1、介绍</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;PersistentVolume（pv）和PersistentVolumeClaim（pvc）是k8s提供的两种API资源，用于抽象存储细节。管理员关注于如何通过pv提供存储功能而无需关注用户如何使用，同样的用户只需要挂载pvc到容器中而不需要关注存储卷采用何种技术实现。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;pvc和pv的关系与pod和node关系类似，前者消耗后者的资源。pvc可以向pv申请指定大小的存储资源并设置访问模式,这就可以通过Provision -&gt; Claim 的方式，来对存储资源进行控制。</p><a id="more"></a><h3 id="2、生命周期"><a href="#2、生命周期" class="headerlink" title="2、生命周期"></a>2、生命周期</h3><p>pv和pvc遵循以下生命周期:</p><ul><li>供应准备。通过集群外的存储系统或者云平台来提供存储持久化支持。<ul><li><strong>静态提供</strong>: 管理员手动创建多个PV，供PVC使用。</li><li><strong>动态提供</strong>: 动态创建PVC特定的PV，并绑定。</li></ul></li><li>绑定。用户创建pvc并指定需要的资源和访问模式。在找到可用pv之前，pvc会保持未绑定状态。</li><li>使用。用户可在pod中像volume一样使用pvc。</li><li>释放。用户删除pvc来回收存储资源，pv将变成“released”状态。由于还保留着之前的数据，这些数据需要根据不同的策略来处理，否则这些存储资源无法被其他pvc使用。</li><li>回收(Reclaiming)。pv可以设置三种回收策略：保留（Retain），回收（Recycle）和删除（Delete）。</li></ul><ul><li><strong>保留策略</strong>: 允许人工处理保留的数据。</li><li><strong>删除策略</strong>: 将删除pv和外部关联的存储资源，需要插件支持。</li><li><strong>回收策略</strong>: 将执行清除操作，之后可以被新的pvc使用，需要插件支持。</li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;目前只有NFS和HostPath类型卷支持回收策略，AWS EBS,GCE PD,Azure Disk和Cinder支持删除(Delete)策略。</p><h4 id="2-1、Provisioning"><a href="#2-1、Provisioning" class="headerlink" title="2.1、Provisioning"></a>2.1、Provisioning</h4><p>两种方式提供的PV资源供给：</p><ul><li><p>static:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过集群管理者创建多个PV，为集群“使用者”提供存储能力而隐藏真实存储的细节。并且存在于kubenretes api中，可被直接使用。</p></li><li><p>dynamic:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;动态卷供给是kubernetes独有的功能，这一功能允许按需创建存储建。在此之前，集群管理员需要事先在集群外由存储提供者或者云提供商创建<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;存储卷，成功之后再创建PersistentVolume对象，才能够在kubernetes中使用。动态卷供给能让集群管理员不必进行预先创建存储卷，而是随着用户需求进行创建。在1.5版本提高了动态卷的弹性和可用性。</p></li></ul><h3 id="PV类型"><a href="#PV类型" class="headerlink" title="PV类型"></a>PV类型</h3><p>pv支持以下类型:</p><ul><li>GCEPersistentDisk</li><li>AWSElasticBlockStore</li><li>NFS</li><li>iSCSI</li><li>RBD (Ceph Block Device)</li><li>Glusterfs</li><li>AzureFile</li><li>AzureDisk</li><li>CephFS</li><li>cinder</li><li>FC</li><li>FlexVolume</li><li>Flocker</li><li>PhotonPersistentDisk</li><li>Quobyte</li><li>VsphereVolume</li><li>HostPath (single node testing only – local storage is not supported in any way and WILL NOT WORK in a multi-node cluster)</li></ul><h4 id="3-1、PV属性"><a href="#3-1、PV属性" class="headerlink" title="3.1、PV属性"></a>3.1、PV属性</h4><ul><li>访问模式,与pv的语义相同。在请求资源时使用特定模式。</li><li>资源,申请的存储资源数额。</li></ul><h4 id="3-2、PV卷阶段状态"><a href="#3-2、PV卷阶段状态" class="headerlink" title="3.2、PV卷阶段状态"></a>3.2、PV卷阶段状态</h4><ul><li>Available – 资源尚未被claim使用</li><li>Bound – 卷已经被绑定到claim了</li><li>Released – claim被删除，卷处于释放状态，但未被集群回收。</li><li>Failed – 卷自动回收失败</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;1、介绍&quot;&gt;&lt;a href=&quot;#1、介绍&quot; class=&quot;headerlink&quot; title=&quot;1、介绍&quot;&gt;&lt;/a&gt;1、介绍&lt;/h3&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;PersistentVolume（pv）和PersistentVolumeClaim（pvc）是k8s提供的两种API资源，用于抽象存储细节。管理员关注于如何通过pv提供存储功能而无需关注用户如何使用，同样的用户只需要挂载pvc到容器中而不需要关注存储卷采用何种技术实现。&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;pvc和pv的关系与pod和node关系类似，前者消耗后者的资源。pvc可以向pv申请指定大小的存储资源并设置访问模式,这就可以通过Provision -&amp;gt; Claim 的方式，来对存储资源进行控制。&lt;/p&gt;
    
    </summary>
    
      <category term="kubernetes" scheme="https://xxlaila.github.io/categories/kubernetes/"/>
    
    
      <category term="pv, pvc" scheme="https://xxlaila.github.io/tags/pv-pvc/"/>
    
  </entry>
  
  <entry>
    <title>利用NFS动态提供Kubernetes后端存储卷</title>
    <link href="https://xxlaila.github.io/2019/09/24/%E5%88%A9%E7%94%A8NFS%E5%8A%A8%E6%80%81%E6%8F%90%E4%BE%9BKubernetes%E5%90%8E%E7%AB%AF%E5%AD%98%E5%82%A8%E5%8D%B7/"/>
    <id>https://xxlaila.github.io/2019/09/24/利用NFS动态提供Kubernetes后端存储卷/</id>
    <published>2019-09-24T09:53:32.000Z</published>
    <updated>2019-09-25T04:32:59.526Z</updated>
    
    <content type="html"><![CDATA[<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;nfs-client-provisioner是一个automatic provisioner，使用NFS作为存储，自动创建PV和对应的PVC，本身不提供NFS存储，需要外部先有一套NFS存储服务。</p><ul><li>PV以 ${namespace}-${pvcName}-${pvName}的命名格式提供（在NFS服务器上）</li><li>PV回收的时候以 archieved-${namespace}-${pvcName}-${pvName} 的命名格式（在NFS服务器上）</li></ul><p><a href="https://github.com/kubernetes-incubator/external-storage/tree/master/nfs-client" target="_blank" rel="noopener">官方访问地址</a></p><a id="more"></a><h3 id="1、权限体系构建"><a href="#1、权限体系构建" class="headerlink" title="1、权限体系构建"></a>1、权限体系构建</h3><h4 id="1-1、创建serviceaccount"><a href="#1-1、创建serviceaccount" class="headerlink" title="1.1、创建serviceaccount"></a>1.1、创建serviceaccount</h4><p>ServiceAccount也是一种账号, 供运行在pod中的进程使用, 为pod中的进程提供必要的身份证明</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ cat &gt; serviceaccount.yaml &lt;&lt;EOF</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: nfs-client-provisioner</span><br><span class="line">  namespace: kube-ops</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h4 id="1-2、创建role"><a href="#1-2、创建role" class="headerlink" title="1.2、创建role"></a>1.2、创建role</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">$ cat &gt;clusterrole.yaml&lt;&lt;EOF</span><br><span class="line">kind: ClusterRole</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: nfs-client-provisioner-runner</span><br><span class="line">  namespace: kube-ops</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups: [<span class="string">""</span>]</span><br><span class="line">    resources: [<span class="string">"persistentvolumes"</span>]</span><br><span class="line">    verbs: [<span class="string">"get"</span>, <span class="string">"list"</span>, <span class="string">"watch"</span>, <span class="string">"create"</span>, <span class="string">"delete"</span>]</span><br><span class="line">  - apiGroups: [<span class="string">""</span>]</span><br><span class="line">    resources: [<span class="string">"persistentvolumeclaims"</span>]</span><br><span class="line">    verbs: [<span class="string">"get"</span>, <span class="string">"list"</span>, <span class="string">"watch"</span>, <span class="string">"update"</span>]</span><br><span class="line">  - apiGroups: [<span class="string">"storage.k8s.io"</span>]</span><br><span class="line">    resources: [<span class="string">"storageclasses"</span>]</span><br><span class="line">    verbs: [<span class="string">"get"</span>, <span class="string">"list"</span>, <span class="string">"watch"</span>]</span><br><span class="line">  - apiGroups: [<span class="string">""</span>]</span><br><span class="line">    resources: [<span class="string">"events"</span>]</span><br><span class="line">    verbs: [<span class="string">"watch"</span>, <span class="string">"create"</span>, <span class="string">"update"</span>, <span class="string">"patch"</span>]</span><br><span class="line">  - apiGroups: [<span class="string">""</span>]</span><br><span class="line">    resources: [<span class="string">"services"</span>, <span class="string">"endpoints"</span>]</span><br><span class="line">    verbs: [<span class="string">"get"</span>, <span class="string">"create"</span>,<span class="string">"list"</span>, <span class="string">"watch"</span>,<span class="string">"update"</span>]</span><br><span class="line">  - apiGroups: [<span class="string">"extensions"</span>]</span><br><span class="line">    resources: [<span class="string">"podsecuritypolicies"</span>]</span><br><span class="line">    resourceNames: [<span class="string">"nfs-client-provisioner"</span>]</span><br><span class="line">    verbs: [<span class="string">"use"</span>]</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h4 id="1-3、账户和角色绑定"><a href="#1-3、账户和角色绑定" class="headerlink" title="1.3、账户和角色绑定"></a>1.3、账户和角色绑定</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">$ cat &gt;clusterrolebinding.yaml &lt;&lt;EOF</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  namespace: kube-ops</span><br><span class="line">  name: run-nfs-client-provisioner</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: nfs-client-provisioner</span><br><span class="line">    namespace: kube-ops</span><br><span class="line">roleRef:</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: nfs-client-provisioner-runner</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h4 id="1-4、执行创建"><a href="#1-4、执行创建" class="headerlink" title="1.4、执行创建"></a>1.4、执行创建</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl create -f serviceaccount.yaml -f clusterrole.yaml -f clusterrolebinding.yaml</span><br><span class="line">serviceaccount/nfs-client-provisioner created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/nfs-client-provisioner-runner created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/run-nfs-client-provisioner created</span><br></pre></td></tr></table></figure><h3 id="2、安装部署"><a href="#2、安装部署" class="headerlink" title="2、安装部署"></a>2、安装部署</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;下载deployment.yaml文件,需要修改NFS服务器所在的IP地址（10.10.10.60），以及NFS服务器共享的路径（/ifs/kubernetes），两处都需要修改为你实际的NFS服务器和共享目录</p><h4 id="2-1、部署存储供应卷"><a href="#2-1、部署存储供应卷" class="headerlink" title="2.1、部署存储供应卷"></a>2.1、部署存储供应卷</h4><p>根据PVC的请求, 动态创建PV存储.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">$ cat &gt; deployment.yaml &lt;&lt;EOF</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  namespace: kube-ops</span><br><span class="line">  name: nfs-client-provisioner</span><br><span class="line">---</span><br><span class="line">kind: Deployment</span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  namespace: kube-ops</span><br><span class="line">  name: nfs-client-provisioner</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  strategy:</span><br><span class="line">    <span class="built_in">type</span>: Recreate</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nfs-client-provisioner</span><br><span class="line">    spec:</span><br><span class="line">      serviceAccountName: nfs-client-provisioner</span><br><span class="line">      containers:</span><br><span class="line">        - name: nfs-client-provisioner</span><br><span class="line">          image: quay.io/external_storage/nfs-client-provisioner:latest</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - name: nfs-client-root</span><br><span class="line">              mountPath: /persistentvolumes</span><br><span class="line">          env:</span><br><span class="line">            - name: PROVISIONER_NAME</span><br><span class="line">              value: fuseim.pri/ifs</span><br><span class="line">            - name: NFS_SERVER</span><br><span class="line">              value: 172.21.17.39</span><br><span class="line">            - name: NFS_PATH</span><br><span class="line">              value: /opt</span><br><span class="line">      volumes:</span><br><span class="line">        - name: nfs-client-root</span><br><span class="line">          nfs:</span><br><span class="line">            server: /opt</span><br><span class="line">            path: 172.21.17.39</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><ul><li>修改StorageClass文件并部署class.yaml</li></ul><p>此处可以不修改，或者修改provisioner的名字，需要与上面的deployment的PROVISIONER_NAME名字一致</p><h4 id="2-2、创建storageclass"><a href="#2-2、创建storageclass" class="headerlink" title="2.2、创建storageclass"></a>2.2、创建storageclass</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ cat &gt; class.yaml &lt;&lt;EOF</span><br><span class="line">apiVersion: storage.k8s.io/v1</span><br><span class="line">kind: StorageClass</span><br><span class="line">metadata:</span><br><span class="line">  name: managed-nfs-storage</span><br><span class="line">provisioner: fuseim.pri/ifs <span class="comment"># or choose another name, must match deployment's env PROVISIONER_NAME'</span></span><br><span class="line">parameters:</span><br><span class="line">  archiveOnDelete: <span class="string">"false"</span></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h4 id="2-3、执行创建"><a href="#2-3、执行创建" class="headerlink" title="2.3、执行创建"></a>2.3、执行创建</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl apply -f deployment.yaml </span><br><span class="line">serviceaccount/nfs-client-provisioner created</span><br><span class="line">deployment.extensions/nfs-client-provisioner created</span><br><span class="line"></span><br><span class="line">$ kubectl apply -f class.yaml </span><br><span class="line">storageclass.storage.k8s.io/managed-nfs-storage created</span><br></pre></td></tr></table></figure><h5 id="2-3-1、查看StorageClass"><a href="#2-3-1、查看StorageClass" class="headerlink" title="2.3.1、查看StorageClass"></a>2.3.1、查看StorageClass</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get storageclass</span><br><span class="line">NAME                  PROVISIONER      AGE</span><br><span class="line">managed-nfs-storage   fuseim.pri/ifs   18s</span><br></pre></td></tr></table></figure><h5 id="2-3-2、设置默认后端存储"><a href="#2-3-2、设置默认后端存储" class="headerlink" title="2.3.2、设置默认后端存储"></a>2.3.2、设置默认后端存储</h5><p>设置这个default名字的SC为Kubernetes的默认存储后端</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl patch storageclass managed-nfs-storage -p <span class="string">'&#123;"metadata": &#123;"annotations":&#123;"storageclass.kubernetes.io/is-default-class":"true"&#125;&#125;&#125;'</span></span><br><span class="line">storageclass.storage.k8s.io/managed-nfs-storage patched</span><br></pre></td></tr></table></figure><ul><li>storage.yaml (和上面一样)<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ cat &gt; storage.yaml &lt;&lt;EOF</span><br><span class="line">apiVersion: storage.k8s.io/v1</span><br><span class="line">kind: StorageClass</span><br><span class="line">metadata:</span><br><span class="line">  name: managed-nfs-storage</span><br><span class="line">  annotations:</span><br><span class="line">    storageclass.kubernetes.io/is-default-class: <span class="string">"true"</span></span><br><span class="line">provisioner: fuseim.pri/ifs</span><br><span class="line">parameters:</span><br><span class="line">  archiveOnDelete: <span class="string">"false"</span></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></li></ul><h4 id="2-3-3、查看验证"><a href="#2-3-3、查看验证" class="headerlink" title="2.3.3、查看验证"></a>2.3.3、查看验证</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get all -n kube-ops</span><br><span class="line">NAME                                          READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod/nfs-client-provisioner-77f678858b-8d2d6   1/1     Running   0          26m</span><br><span class="line"></span><br><span class="line">NAME                                     READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">deployment.apps/nfs-client-provisioner   1/1     1            1           29m</span><br><span class="line"></span><br><span class="line">NAME                                                DESIRED   CURRENT   READY   AGE</span><br><span class="line">replicaset.apps/nfs-client-provisioner-77f678858b   1         1         1       26m</span><br></pre></td></tr></table></figure><h3 id="3、验证测试"><a href="#3、验证测试" class="headerlink" title="3、验证测试"></a>3、验证测试</h3><h4 id="3-1、创建一个测试存储"><a href="#3-1、创建一个测试存储" class="headerlink" title="3.1、创建一个测试存储"></a>3.1、创建一个测试存储</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">$ cat &gt; <span class="built_in">test</span>-claim.yaml &lt;&lt;EOF</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: <span class="built_in">test</span>-claim</span><br><span class="line">  namespace: kube-ops</span><br><span class="line">  annotations:</span><br><span class="line">    volume.beta.kubernetes.io/storage-class: <span class="string">"managed-nfs-storage"</span></span><br><span class="line">spec:</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteMany</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 1Mi</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h4 id="3-2、启动测试POD"><a href="#3-2、启动测试POD" class="headerlink" title="3.2、启动测试POD"></a>3.2、启动测试POD</h4><p>POD文件如下，作用就是在test-claim的PV里touch一个SUCCESS文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">$ cat  &gt; <span class="built_in">test</span>-pod.yaml &lt;&lt;EOF</span><br><span class="line">kind: Pod</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: <span class="built_in">test</span>-pod</span><br><span class="line">  namespace: kube-ops</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: <span class="built_in">test</span>-pod</span><br><span class="line">    image: docker.io/busybox:1.24</span><br><span class="line">    <span class="built_in">command</span>:</span><br><span class="line">      - <span class="string">"/bin/sh"</span></span><br><span class="line">    args:</span><br><span class="line">      - <span class="string">"-c"</span></span><br><span class="line">      - <span class="string">"touch /mnt/SUCCESS &amp;&amp; exit 0 || exit 1"</span></span><br><span class="line">    volumeMounts:</span><br><span class="line">      - name: nfs-pvc</span><br><span class="line">        mountPath: <span class="string">"/mnt"</span></span><br><span class="line">  restartPolicy: <span class="string">"Never"</span></span><br><span class="line">  volumes:</span><br><span class="line">    - name: nfs-pvc</span><br><span class="line">      persistentVolumeClaim:</span><br><span class="line">        claimName: <span class="built_in">test</span>-claim</span><br></pre></td></tr></table></figure><h4 id="3-3、执行创建"><a href="#3-3、执行创建" class="headerlink" title="3.3、执行创建"></a>3.3、执行创建</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl apply -f ./</span><br><span class="line">persistentvolumeclaim/<span class="built_in">test</span>-claim created</span><br><span class="line">pod/<span class="built_in">test</span>-pod created</span><br></pre></td></tr></table></figure><h4 id="3-4、查看验证"><a href="#3-4、查看验证" class="headerlink" title="3.4、查看验证"></a>3.4、查看验证</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pod,pv -n kube-ops</span><br><span class="line">NAME                                          READY   STATUS      RESTARTS   AGE</span><br><span class="line">pod/nfs-client-provisioner-77f678858b-8d2d6   1/1     Running     0          3h26m</span><br><span class="line">pod/<span class="built_in">test</span>-pod                                  0/1     Completed   0          172m</span><br><span class="line"></span><br><span class="line">NAME                                                        CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                 STORAGECLASS          REASON   AGE</span><br><span class="line">persistentvolume/pvc-2f0057b0-df35-11e9-ad62-fa163e53d4c8   1Mi        RWX            Retain           Bound    kube-ops/<span class="built_in">test</span>-claim   managed-nfs-storage            172m</span><br></pre></td></tr></table></figure><ul><li>登录nfs服务器查看是否成功的创建目录<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ ls /opt/</span><br><span class="line">kube-ops-test-claim-pvc-2f0057b0-df35-11e9-ad62-fa163e53d4c8</span><br></pre></td></tr></table></figure></li></ul><h4 id="3-5、更改PersistentVolumes-中的一个回收策略"><a href="#3-5、更改PersistentVolumes-中的一个回收策略" class="headerlink" title="3.5、更改PersistentVolumes 中的一个回收策略"></a>3.5、更改PersistentVolumes 中的一个回收策略</h4><ul><li><p>查看集群中PersistentVolumes</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pv -n kube-ops</span><br><span class="line">NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                 STORAGECLASS          REASON   AGE</span><br><span class="line">pvc-2f0057b0-df35-11e9-ad62-fa163e53d4c8   1Mi        RWX            Delete           Bound    kube-ops/<span class="built_in">test</span>-claim   managed-nfs-storage            3m6s</span><br></pre></td></tr></table></figure></li><li><p>更改PersistentVolumes</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl patch pv pvc-2f0057b0-df35-11e9-ad62-fa163e53d4c8  -p <span class="string">'&#123;"spec":&#123;"persistentVolumeReclaimPolicy":"Retain"&#125;&#125;'</span></span><br><span class="line">persistentvolume/pvc-2f0057b0-df35-11e9-ad62-fa163e53d4c8 patched</span><br><span class="line"></span><br><span class="line">$ kubectl get pv -n kube-ops</span><br><span class="line">NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                 STORAGECLASS          REASON   AGE</span><br><span class="line">pvc-2f0057b0-df35-11e9-ad62-fa163e53d4c8   1Mi        RWX            Retain           Bound    kube-ops/<span class="built_in">test</span>-claim   managed-nfs-storage            3m54s</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;nfs-client-provisioner是一个automatic provisioner，使用NFS作为存储，自动创建PV和对应的PVC，本身不提供NFS存储，需要外部先有一套NFS存储服务。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PV以 ${namespace}-${pvcName}-${pvName}的命名格式提供（在NFS服务器上）&lt;/li&gt;
&lt;li&gt;PV回收的时候以 archieved-${namespace}-${pvcName}-${pvName} 的命名格式（在NFS服务器上）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/kubernetes-incubator/external-storage/tree/master/nfs-client&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;官方访问地址&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="kubernetes" scheme="https://xxlaila.github.io/categories/kubernetes/"/>
    
    
      <category term="pvc,pv" scheme="https://xxlaila.github.io/tags/pvc-pv/"/>
    
  </entry>
  
  <entry>
    <title>k8s v1.14 prometheus</title>
    <link href="https://xxlaila.github.io/2019/09/20/k8s-v1-14-prometheus/"/>
    <id>https://xxlaila.github.io/2019/09/20/k8s-v1-14-prometheus/</id>
    <published>2019-09-20T08:12:48.000Z</published>
    <updated>2019-09-26T03:13:12.713Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Prometheus、Grafana-部署"><a href="#Prometheus、Grafana-部署" class="headerlink" title="Prometheus、Grafana 部署"></a>Prometheus、Grafana 部署</h1><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Grafana是一个开源的度量分析与可视化套件。经常被用作基础设施的时间序列数据和应用程序分析的可视化，我们这里用它来做Kubernetes集群监控数据的可视化。</p><h3 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;截至当前，prometheus、grafana均采用最新的镜像包，在在第一次部署的时候grafana报了一个错误<code>mkdir: cannot create directory &#39;/var/lib/grafana/plugins&#39;: No such file or directory</code>,这是因为Grafana启动使用的用户和用户组都是472，造成对外挂存储没有权限。<a href="https://grafana.com/docs/installation/docker/#migration-from-a-previous-version-of-the-docker-container-to-5-1-or-later" target="_blank" rel="noopener">参考官方</a></p><a id="more"></a><h3 id="开始部署"><a href="#开始部署" class="headerlink" title="开始部署"></a>开始部署</h3><p>新建yaml文件</p><ul><li>monitor-namespace.yaml<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat  monitor-namespace.yaml </span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Namespace</span><br><span class="line">metadata:</span><br><span class="line">  name: monitoring</span><br></pre></td></tr></table></figure></li></ul><p>其他的文件均采用以前历史的，然后稍加修改，其他<a href="https://github.com/xxlaila/kubernetes-yaml.git" target="_blank" rel="noopener">yaml</a>文件,移除<code>grafana-ingress.yaml</code>、<code>prometheus-ingress.yaml</code></p><h3 id="文件修改"><a href="#文件修改" class="headerlink" title="文件修改"></a>文件修改</h3><ul><li><p>grafana-deploy.yaml</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: grafana-core</span><br><span class="line">  namespace: monitoring</span><br><span class="line">  labels:</span><br><span class="line">    app: grafana</span><br><span class="line">    component: core</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: grafana</span><br><span class="line">        component: core</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - image: grafana/grafana:latest</span><br><span class="line">        name: grafana-core</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        <span class="comment"># env:</span></span><br><span class="line">        resources:</span><br><span class="line">          <span class="comment"># keep request = limit to keep this container in guaranteed class</span></span><br><span class="line">          limits:</span><br><span class="line">            cpu: 100m</span><br><span class="line">            memory: 100Mi</span><br><span class="line">          requests:</span><br><span class="line">            cpu: 100m</span><br><span class="line">            memory: 100Mi</span><br><span class="line">        env:</span><br><span class="line">          <span class="comment"># The following env variables set up basic auth twith the default admin user and admin password.</span></span><br><span class="line">          - name: GF_AUTH_BASIC_ENABLED</span><br><span class="line">            value: <span class="string">"true"</span></span><br><span class="line">          - name: GF_AUTH_ANONYMOUS_ENABLED</span><br><span class="line">            value: <span class="string">"false"</span></span><br><span class="line">          <span class="comment"># - name: GF_AUTH_ANONYMOUS_ORG_ROLE</span></span><br><span class="line">          <span class="comment">#   value: Admin</span></span><br><span class="line">          <span class="comment"># does not really work, because of template variables in exported dashboards:</span></span><br><span class="line">          <span class="comment"># - name: GF_DASHBOARDS_JSON_ENABLED</span></span><br><span class="line">          <span class="comment">#   value: "true"</span></span><br><span class="line">        readinessProbe:</span><br><span class="line">          httpGet:</span><br><span class="line">            path: /login</span><br><span class="line">            port: 3000</span><br><span class="line">          <span class="comment"># initialDelaySeconds: 30</span></span><br><span class="line">          <span class="comment"># timeoutSeconds: 1</span></span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: grafana-persistent-storage</span><br><span class="line">          mountPath: /var/lib/grafana</span><br><span class="line">      volumes:</span><br><span class="line">      - name: grafana-persistent-storage</span><br><span class="line">        emptyDir: &#123;&#125;</span><br></pre></td></tr></table></figure></li><li><p>prometheus-deploy.yaml</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">spec:</span><br><span class="line">      containers:</span><br><span class="line">      - image: prom/prometheus:latest</span><br><span class="line">        name: prometheus</span><br><span class="line">        <span class="built_in">command</span>:</span><br><span class="line">        - <span class="string">"/bin/prometheus"</span></span><br></pre></td></tr></table></figure></li><li><p>prometheus-svc.yaml</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">kind: Service</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: prometheus</span><br><span class="line">  name: prometheus</span><br><span class="line">  namespace: monitoring</span><br><span class="line">spec:</span><br><span class="line">  <span class="comment">#type: NodePort</span></span><br><span class="line">  ports:</span><br><span class="line">  - port: 9090</span><br><span class="line">    targetPort: 9090</span><br><span class="line">    <span class="comment">#nodePort: 30005</span></span><br><span class="line">  selector:</span><br><span class="line">    app: prometheus</span><br></pre></td></tr></table></figure></li><li><p>grafana-svc.yaml</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat grafana-svc.yaml</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: grafana</span><br><span class="line">  namespace: monitoring</span><br><span class="line">  labels:</span><br><span class="line">    app: grafana</span><br><span class="line">    component: core</span><br><span class="line">spec:</span><br><span class="line">  <span class="comment">#type: NodePort</span></span><br><span class="line">  ports:</span><br><span class="line">    - port: 3000</span><br><span class="line">  selector:</span><br><span class="line">    app: grafana</span><br><span class="line">    component: core</span><br></pre></td></tr></table></figure></li></ul><h3 id="执行创建"><a href="#执行创建" class="headerlink" title="执行创建"></a>执行创建</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl apply -f ./</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 多执行几次</span></span><br></pre></td></tr></table></figure><h3 id="检查部署"><a href="#检查部署" class="headerlink" title="检查部署"></a>检查部署</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl get pod,svc,deploy -n monitoring</span></span><br><span class="line">NAME                                READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod/grafana-core-7b5989cf9d-snbk5   1/1     Running   0          2m31s</span><br><span class="line">pod/node-exporter-dddv7             1/1     Running   0          12m</span><br><span class="line">pod/node-exporter-fhfp6             1/1     Running   0          12m</span><br><span class="line">pod/node-exporter-m46bf             1/1     Running   0          12m</span><br><span class="line">pod/node-exporter-xkrzp             1/1     Running   0          12m</span><br><span class="line">pod/node-exporter-zfcxh             1/1     Running   0          12m</span><br><span class="line">pod/prometheus-67bcf457db-999ns     1/1     Running   0          12m</span><br><span class="line"></span><br><span class="line">NAME                    TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE</span><br><span class="line">service/grafana         ClusterIP   10.254.95.151    &lt;none&gt;        3000/TCP         12m</span><br><span class="line">service/node-exporter   ClusterIP   10.254.114.12    &lt;none&gt;        9100/TCP         12m</span><br><span class="line">service/prometheus      ClusterIP   10.254.104.216   &lt;none&gt;        9090/TCP         12m</span><br><span class="line"></span><br><span class="line">NAME                                 READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">deployment.extensions/grafana-core   1/1     1            1           12m</span><br><span class="line">deployment.extensions/prometheus     1/1     1            1           12m</span><br></pre></td></tr></table></figure><h3 id="创建Ingress"><a href="#创建Ingress" class="headerlink" title="创建Ingress"></a>创建Ingress</h3><h4 id="prometheus-Ingress"><a href="#prometheus-Ingress" class="headerlink" title="prometheus Ingress"></a>prometheus Ingress</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat prometheus-Ingress.yaml </span></span><br><span class="line">---</span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: prometheus-web-ui</span><br><span class="line">  namespace: monitoring</span><br><span class="line">  annotations:</span><br><span class="line">    kubernetes.io/ingress.class: traefik</span><br><span class="line">spec:</span><br><span class="line">  rules:</span><br><span class="line">  - host: prometheus.xxlaila.cn</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - path: /</span><br><span class="line">        backend:</span><br><span class="line">          serviceName: prometheus</span><br><span class="line">          servicePort: 9090</span><br></pre></td></tr></table></figure><h4 id="grafana-Ingress"><a href="#grafana-Ingress" class="headerlink" title="grafana Ingress"></a>grafana Ingress</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat grafana-Ingress.yaml </span></span><br><span class="line">---</span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: grafana-web-ui</span><br><span class="line">  namespace: monitoring</span><br><span class="line">  annotations:</span><br><span class="line">    kubernetes.io/ingress.class: traefik</span><br><span class="line">spec:</span><br><span class="line">  rules:</span><br><span class="line">  - host: grafana.xxlaila.cn</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - path: /</span><br><span class="line">        backend:</span><br><span class="line">          serviceName: grafana</span><br><span class="line">          servicePort: 3000</span><br></pre></td></tr></table></figure><h4 id="执行创建-1"><a href="#执行创建-1" class="headerlink" title="执行创建"></a>执行创建</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl apply -f prometheus-Ingress.yaml </span></span><br><span class="line">ingress.extensions/prometheus-web-ui created</span><br><span class="line"></span><br><span class="line"><span class="comment"># kubectl apply -f grafana-Ingress.yaml </span></span><br><span class="line">ingress.extensions/grafana-web-ui created</span><br></pre></td></tr></table></figure><p>在浏览器输入prometheus.xxlaila.cn访问prometheus，输入grafana.xxlaila.cn访问grafana。</p><h3 id="访问prometheus"><a href="#访问prometheus" class="headerlink" title="访问prometheus"></a>访问prometheus</h3><p><img src="http://img.xxlaila.cn/1569218750254.jpg" alt="img"></p><h3 id="配置grafana"><a href="#配置grafana" class="headerlink" title="配置grafana"></a>配置grafana</h3><p><img src="http://img.xxlaila.cn/1568968344227.jpg" alt="img"></p><p>到grafana的官方下载对应的模版文件导入，就可以出图啦<br><img src="http://img.xxlaila.cn/1568968420655.jpg" alt="img"></p><p><a href="https://github.com/kubernetes/kubernetes/tree/master/cluster/addons/prometheus" target="_blank" rel="noopener">后续利用pvc</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Prometheus、Grafana-部署&quot;&gt;&lt;a href=&quot;#Prometheus、Grafana-部署&quot; class=&quot;headerlink&quot; title=&quot;Prometheus、Grafana 部署&quot;&gt;&lt;/a&gt;Prometheus、Grafana 部署&lt;/h1&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Grafana是一个开源的度量分析与可视化套件。经常被用作基础设施的时间序列数据和应用程序分析的可视化，我们这里用它来做Kubernetes集群监控数据的可视化。&lt;/p&gt;
&lt;h3 id=&quot;准备工作&quot;&gt;&lt;a href=&quot;#准备工作&quot; class=&quot;headerlink&quot; title=&quot;准备工作&quot;&gt;&lt;/a&gt;准备工作&lt;/h3&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;截至当前，prometheus、grafana均采用最新的镜像包，在在第一次部署的时候grafana报了一个错误&lt;code&gt;mkdir: cannot create directory &amp;#39;/var/lib/grafana/plugins&amp;#39;: No such file or directory&lt;/code&gt;,这是因为Grafana启动使用的用户和用户组都是472，造成对外挂存储没有权限。&lt;a href=&quot;https://grafana.com/docs/installation/docker/#migration-from-a-previous-version-of-the-docker-container-to-5-1-or-later&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;参考官方&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="kubenertes" scheme="https://xxlaila.github.io/categories/kubenertes/"/>
    
    
      <category term="k8s v1.14,prometheus" scheme="https://xxlaila.github.io/tags/k8s-v1-14-prometheus/"/>
    
  </entry>
  
  <entry>
    <title>k8s v1.14 weave-scope</title>
    <link href="https://xxlaila.github.io/2019/09/20/k8s-v1-14-weave-scope/"/>
    <id>https://xxlaila.github.io/2019/09/20/k8s-v1-14-weave-scope/</id>
    <published>2019-09-20T03:49:59.000Z</published>
    <updated>2019-09-26T03:13:13.186Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前沿"><a href="#前沿" class="headerlink" title="前沿"></a>前沿</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Kubernetes 集群并部署容器化应用只是第一步。一旦集群运行起来，我们需要确保一起正常，所有必要组件就位并各司其职，有足够的资源满足应用的需求。Kubernetes 是一个复杂系统，运维团队需要有一套工具帮助他们获知集群的实时状态，并为故障排查提供及时和准确的数据支持。</p><h3 id="weave-scope-介绍"><a href="#weave-scope-介绍" class="headerlink" title="weave scope 介绍"></a>weave scope 介绍</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Weave Scope是Docker和Kubernetes的可视化和监控工具。它提供了一个自上而下的应用程序以及整个基础架构视图，并允许您在部署到云提供商时实时诊断分布式容器化应用程序的任何问题。</p><a id="more"></a><h3 id="功能介绍"><a href="#功能介绍" class="headerlink" title="功能介绍"></a>功能介绍</h3><ul><li>pod拓扑映射</li><li>图形或表格模式</li><li>灵活过滤</li><li>强大的搜索功能</li><li>实时应用和容器指标</li><li>排除故障并管理容器</li><li>使用Plugin API生成自定义指标</li></ul><p><a href="https://www.weave.works/docs/scope/latest/features/" target="_blank" rel="noopener">介绍参考</a></p><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>在 K8s 集群中安装 Scope 的方法很简单，使用下面的命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl apply -f "https://cloud.weave.works/k8s/scope.yaml?k8s-version=$(kubectl version | base64 | tr -d '\n')"</span></span><br><span class="line">namespace/weave created</span><br><span class="line">serviceaccount/weave-scope created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/weave-scope created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/weave-scope created</span><br><span class="line">deployment.apps/weave-scope-app created</span><br><span class="line">service/weave-scope-app created</span><br><span class="line">deployment.apps/weave-scope-cluster-agent created</span><br><span class="line">daemonset.extensions/weave-scope-agent created</span><br></pre></td></tr></table></figure><h3 id="检查"><a href="#检查" class="headerlink" title="检查"></a>检查</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl get pod,svc,deploy -n weave</span></span><br><span class="line">NAME                                             READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod/weave-scope-agent-2t4m5                      1/1     Running   0          15m</span><br><span class="line">pod/weave-scope-agent-6tfp5                      1/1     Running   0          15m</span><br><span class="line">pod/weave-scope-agent-fxj5f                      1/1     Running   0          15m</span><br><span class="line">pod/weave-scope-agent-gkxc6                      1/1     Running   0          15m</span><br><span class="line">pod/weave-scope-agent-qnbbv                      1/1     Running   0          15m</span><br><span class="line">pod/weave-scope-app-b99fb9585-wld6n              1/1     Running   0          15m</span><br><span class="line">pod/weave-scope-cluster-agent-77bc946585-8fcjj   1/1     Running   0          15m</span><br><span class="line"></span><br><span class="line">NAME                      TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE</span><br><span class="line">service/weave-scope-app   ClusterIP   10.254.184.106   &lt;none&gt;        80/TCP    15m</span><br><span class="line"></span><br><span class="line">NAME                                              READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">deployment.extensions/weave-scope-app             1/1     1            1           15m</span><br><span class="line">deployment.extensions/weave-scope-cluster-agent   1/1     1            1           15m</span><br></pre></td></tr></table></figure><h3 id="创建weave-scope-ingress"><a href="#创建weave-scope-ingress" class="headerlink" title="创建weave-scope ingress"></a>创建weave-scope ingress</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat weave-scope.yaml </span></span><br><span class="line">---</span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: weave-web-ui</span><br><span class="line">  namespace: weave</span><br><span class="line">  annotations:</span><br><span class="line">    kubernetes.io/ingress.class: traefik</span><br><span class="line">spec:</span><br><span class="line">  rules:</span><br><span class="line">  - host: weave-scope.xxlaila.cn</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - path: /</span><br><span class="line">        backend:</span><br><span class="line">          serviceName: weave-scope-app</span><br><span class="line">          servicePort: 80</span><br><span class="line"></span><br><span class="line"><span class="comment"># kubectl apply -f weave-scope.yaml </span></span><br><span class="line">ingress.extensions/weave-web-ui created</span><br></pre></td></tr></table></figure><p>在浏览输入<code>weave-scope.xxlaila.cn</code>即可访问<br><img src="http://img.xxlaila.cn/1568958836846.jpg" alt="img"></p><h4 id="拓扑结构"><a href="#拓扑结构" class="headerlink" title="拓扑结构"></a>拓扑结构</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Scope 会自动构建应用和集群的逻辑拓扑。比如点击顶部 Pods，会显示所有 Pod 以及 Pod 之间的依赖关系<br><img src="http://img.xxlaila.cn/1568958666089.jpg" alt="img"><br>点击 Hosts，会显示各个节点之间的关系，可以在 Scope 中查看资源的 CPU 和内存使用情况。<br><img src="http://img.xxlaila.cn/1568958913275.jpg" alt="img"></p><h3 id="在线操作"><a href="#在线操作" class="headerlink" title="在线操作"></a>在线操作</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Scope 还提供了便捷的在线操作功能，比如选中某个 Host，点击 &gt;_按钮可以直接在浏览器中打开节点的命令行终端：<br><img src="http://img.xxlaila.cn/1568959004395.jpg" alt="img"></p><ul><li><p>点击 Deployment 的 + 可以执行新增一个pod实列<br><img src="http://img.xxlaila.cn/1568959269040.jpg" alt="img"></p></li><li><p>查看pod的日志<br><img src="http://img.xxlaila.cn/1568959359334.jpg" alt="img"></p></li><li><p>attach、restart、stop 容器，以及直接在 Scope 中排查问题<br><img src="http://img.xxlaila.cn/1568959467442.jpg" alt="img"></p></li></ul><p>更多功呢个请<a href="https://www.weave.works/docs/scope/latest/plugins/" target="_blank" rel="noopener">参考官方</a>,或者实操</p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;前沿&quot;&gt;&lt;a href=&quot;#前沿&quot; class=&quot;headerlink&quot; title=&quot;前沿&quot;&gt;&lt;/a&gt;前沿&lt;/h3&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Kubernetes 集群并部署容器化应用只是第一步。一旦集群运行起来，我们需要确保一起正常，所有必要组件就位并各司其职，有足够的资源满足应用的需求。Kubernetes 是一个复杂系统，运维团队需要有一套工具帮助他们获知集群的实时状态，并为故障排查提供及时和准确的数据支持。&lt;/p&gt;
&lt;h3 id=&quot;weave-scope-介绍&quot;&gt;&lt;a href=&quot;#weave-scope-介绍&quot; class=&quot;headerlink&quot; title=&quot;weave scope 介绍&quot;&gt;&lt;/a&gt;weave scope 介绍&lt;/h3&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Weave Scope是Docker和Kubernetes的可视化和监控工具。它提供了一个自上而下的应用程序以及整个基础架构视图，并允许您在部署到云提供商时实时诊断分布式容器化应用程序的任何问题。&lt;/p&gt;
    
    </summary>
    
      <category term="kubernetes" scheme="https://xxlaila.github.io/categories/kubernetes/"/>
    
    
      <category term="k8s v1.14, weave-scope" scheme="https://xxlaila.github.io/tags/k8s-v1-14-weave-scope/"/>
    
  </entry>
  
  <entry>
    <title>k8s v1.14 traefik部署</title>
    <link href="https://xxlaila.github.io/2019/09/20/k8s-v1-14-traefik%E9%83%A8%E7%BD%B2/"/>
    <id>https://xxlaila.github.io/2019/09/20/k8s-v1-14-traefik部署/</id>
    <published>2019-09-20T01:20:25.000Z</published>
    <updated>2019-09-20T06:27:47.673Z</updated>
    
    <content type="html"><![CDATA[<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;traefix 前篇是可以使用，这里k8s v1.14 之前的拿来用不上，然后折腾了一下，参考官方的折腾起来了</p><h3 id="基于角色的访问控制配置（仅限Kubernetes-1-6-）"><a href="#基于角色的访问控制配置（仅限Kubernetes-1-6-）" class="headerlink" title="基于角色的访问控制配置（仅限Kubernetes 1.6+）"></a>基于角色的访问控制配置（仅限Kubernetes 1.6+）</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Kubernetes在1.6+中引入了基于角色的访问控制（RBAC），以允许对Kubernetes资源和API进行细粒度控制。群集配置了RBAC，则需要授权Traefik使用Kubernetes API。有两种方法可以设置适当的权限：通过特定于命名空间的RoleBindings或单个全局ClusterRoleBinding。</p><a id="more"></a><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;每个命名空间的RoleBinding可以限制授予权限，只有Traefik正在监视的名称空间才能使用，从而遵循最小权限原则。如果Traefik不应该监视所有名称空间，并且名称空间集不会动态更改，那么这是首选方法。否则，必须使用单个ClusterRoleBinding。</p><p><a href="https://xxlaila.github.io/2019/09/05/traefik-ingress%E4%BD%BF%E7%94%A8/">traefik学习</a><br><a href="https://docs.traefik.io/v1.7/user-guide/kubernetes/" target="_blank" rel="noopener">traefik官方</a></p><h3 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h3><p>下载trarfix代码，然后切换到v1.7的分支</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># git clone https://github.com/containous/traefik.git</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># git branch --all</span></span><br><span class="line">* master</span><br><span class="line">  remotes/origin/HEAD -&gt; origin/master</span><br><span class="line">  remotes/origin/add-plugin-support</span><br><span class="line">  remotes/origin/gh-pages</span><br><span class="line">  remotes/origin/master</span><br><span class="line">  remotes/origin/v1.0</span><br><span class="line">  remotes/origin/v1.1</span><br><span class="line">  remotes/origin/v1.2</span><br><span class="line">  remotes/origin/v1.3</span><br><span class="line">  remotes/origin/v1.4</span><br><span class="line">  remotes/origin/v1.5</span><br><span class="line">  remotes/origin/v1.6</span><br><span class="line">  remotes/origin/v1.7</span><br><span class="line">  remotes/origin/v2.0</span><br><span class="line"></span><br><span class="line"><span class="comment"># git checkout v1.7</span></span><br><span class="line">Branch <span class="string">'v1.7'</span> <span class="built_in">set</span> up to track remote branch <span class="string">'v1.7'</span> from <span class="string">'origin'</span>.</span><br><span class="line">Switched to a new branch <span class="string">'v1.7'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># /root/traefik/examples/k8s</span></span><br></pre></td></tr></table></figure><h3 id="安装部署"><a href="#安装部署" class="headerlink" title="安装部署"></a>安装部署</h3><h4 id="使用ClusterRoleBinding"><a href="#使用ClusterRoleBinding" class="headerlink" title="使用ClusterRoleBinding"></a>使用ClusterRoleBinding</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl apply -f traefik-rbac.yaml </span></span><br><span class="line">clusterrole.rbac.authorization.k8s.io/traefik-ingress-controller created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/traefik-ingress-controller created</span><br></pre></td></tr></table></figure><p>对于命名空间限制，每个监视命名空间需要一个RoleBinding以及Traefik kubernetes.namespaces参数的相应配置。</p><h4 id="使用Deployments部署或部署DaemonSet"><a href="#使用Deployments部署或部署DaemonSet" class="headerlink" title="使用Deployments部署或部署DaemonSet"></a>使用Deployments部署或部署DaemonSet</h4><p>可以将Traefik与Deployment或DaemonSet对象一起使用，而这两个选项各有利弊：</p><ul><li>使用部署时，可伸缩性可以更好，因为在使用DaemonSet时您将拥有每个节点的Single-Pod模型，而在使用部署时，可能需要更少的基于环境的副本。</li><li>当节点加入群集时，DaemonSet会自动扩展到新节点，而部署窗格仅在需要时在新节点上进行调度。</li><li>DaemonSets确保只有一个pod副本在任何单个节点上运行。如果要确保两个pod不在同一节点上，则部署需要关联设置</li><li>可以使用该NET_BIND_SERVICE功能运行DaemonSet ，这将允许它绑定到每个主机上的端口80/443 / etc。这将允许绕过kube-proxy，并减少流量跳跃。请注意，这违反了Kubernetes最佳实践指南，并提出了调度/扩展问题的可能性。尽管存在潜在问题，但这仍然是大多数入口控制器的选择。</li></ul><h4 id="Deployments部署"><a href="#Deployments部署" class="headerlink" title="Deployments部署"></a>Deployments部署</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl  apply -f  traefik-deployment.yaml</span></span><br><span class="line">serviceaccount/traefik-ingress-controller created</span><br><span class="line">deployment.extensions/traefik-ingress-controller created</span><br><span class="line">service/traefik-ingress-service created</span><br></pre></td></tr></table></figure><h4 id="DaemonSets-部署-可选"><a href="#DaemonSets-部署-可选" class="headerlink" title="DaemonSets 部署(可选)"></a>DaemonSets 部署(可选)</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl apply -f traefik-ds.yaml</span></span><br></pre></td></tr></table></figure><ul><li>Deployments和DaemonSets之间存在一些显着差异:<ul><li>部署具有更容易的向上和向下扩展可能性。它可以实现完整的pod生命周期，并支持Kubernetes 1.2的滚动更新。运行部署至少需要一个Pod。</li><li>DaemonSet会自动扩展到满足特定选择器的所有节点，并保证一次填充一个节点。Kubernetes 1.7也完全支持滚动更新，适用于DaemonSets</li></ul></li></ul><h3 id="检查部署"><a href="#检查部署" class="headerlink" title="检查部署"></a>检查部署</h3><ul><li><p>查看pod</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl --namespace=kube-system get pods</span></span><br><span class="line">NAME                                         READY   STATUS    RESTARTS   AGE</span><br><span class="line">coredns-5579b8778b-xw8m9                     1/1     Running   2          3d21h</span><br><span class="line">kubernetes-dashboard-65dfbf6f4f-hcgbb        1/1     Running   0          2d16h</span><br><span class="line">metrics-server-94ff5d4cc-b97l5               1/1     Running   1          3d</span><br><span class="line">tiller-deploy-5cbcf75545-rbzld               1/1     Running   0          17h</span><br><span class="line">traefik-ingress-controller-c595665d6-cm7kh   1/1     Running   0          3m20s</span><br></pre></td></tr></table></figure></li><li><p>查看services</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl get services --namespace=kube-system</span></span><br><span class="line">NAME                      TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                       AGE</span><br><span class="line">kube-dns                  ClusterIP   10.254.0.2       &lt;none&gt;        53/UDP,53/TCP,9153/TCP        3d21h</span><br><span class="line">kubernetes-dashboard      NodePort    10.254.214.153   &lt;none&gt;        443:32533/TCP                 3d21h</span><br><span class="line">metrics-server            ClusterIP   10.254.61.132    &lt;none&gt;        443/TCP                       3d</span><br><span class="line">tiller-deploy             ClusterIP   10.254.207.227   &lt;none&gt;        44134/TCP                     17h</span><br><span class="line">traefik-ingress-service   NodePort    10.254.246.158   &lt;none&gt;        80:32146/TCP,8080:30455/TCP   3m53s</span><br></pre></td></tr></table></figure></li></ul><p>这里使用的是nodeport模式进行部署的，可以看到端口为32146，这里访问会返回<code>404 page not found</code>,那是因为我们还没有给Traefik任何配置。</p><h3 id="创建一个服务和一个将公开Traefik-Web-UI的Ingres"><a href="#创建一个服务和一个将公开Traefik-Web-UI的Ingres" class="headerlink" title="创建一个服务和一个将公开Traefik Web UI的Ingres"></a>创建一个服务和一个将公开Traefik Web UI的Ingres</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl apply -f ui.yaml </span></span><br><span class="line">service/traefik-web-ui created</span><br><span class="line">ingress.extensions/traefik-web-ui created</span><br></pre></td></tr></table></figure><p>在/etc/hosts 文件设置一个路由条目<code>traefik-ui.minikube</code></p><p>在浏览器进行访问可以看到Traefik Web UI</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;traefix 前篇是可以使用，这里k8s v1.14 之前的拿来用不上，然后折腾了一下，参考官方的折腾起来了&lt;/p&gt;
&lt;h3 id=&quot;基于角色的访问控制配置（仅限Kubernetes-1-6-）&quot;&gt;&lt;a href=&quot;#基于角色的访问控制配置（仅限Kubernetes-1-6-）&quot; class=&quot;headerlink&quot; title=&quot;基于角色的访问控制配置（仅限Kubernetes 1.6+）&quot;&gt;&lt;/a&gt;基于角色的访问控制配置（仅限Kubernetes 1.6+）&lt;/h3&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Kubernetes在1.6+中引入了基于角色的访问控制（RBAC），以允许对Kubernetes资源和API进行细粒度控制。群集配置了RBAC，则需要授权Traefik使用Kubernetes API。有两种方法可以设置适当的权限：通过特定于命名空间的RoleBindings或单个全局ClusterRoleBinding。&lt;/p&gt;
    
    </summary>
    
      <category term="kubernetes" scheme="https://xxlaila.github.io/categories/kubernetes/"/>
    
    
      <category term="k8s v1.14, traefik" scheme="https://xxlaila.github.io/tags/k8s-v1-14-traefik/"/>
    
  </entry>
  
  <entry>
    <title>k8s v1.14 metrics-server</title>
    <link href="https://xxlaila.github.io/2019/09/17/k8s-v1-14-metrics-server/"/>
    <id>https://xxlaila.github.io/2019/09/17/k8s-v1-14-metrics-server/</id>
    <published>2019-09-17T01:06:18.000Z</published>
    <updated>2019-09-20T05:47:25.885Z</updated>
    
    <content type="html"><![CDATA[<p>metrics-server这里不详细介绍，可以参考<a href="https://xxlaila.github.io/2019/09/04/metrics-server安装季/">metrics-server安装季</a></p><h3 id="安装metrics-server"><a href="#安装metrics-server" class="headerlink" title="安装metrics-server"></a>安装metrics-server</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这里安装和之前的<strong>metrics-server安装季</strong>稍微有点不一样，之前集群安装没有使用https证书，后面去各种生成的证书和踩坑，这里是在安装的时候一开始就使用了https全证书,所有稍微有一点区别，这里只列出有区别的地方，其他的完全可以参考<a href="https://xxlaila.github.io/2019/09/04/metrics-server安装季/">metrics-server安装季</a>，这里https证书<strong>不需要</strong>重新生成；</p><a id="more"></a><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;配置文件也不需要添加，在v1.14安装的时候就已经吧配置文件添加进去了，所以这里配置文件也不需要增加</p><h3 id="文件的修改"><a href="#文件的修改" class="headerlink" title="文件的修改"></a>文件的修改</h3><ul><li><p>修改 metrics-server-deployment.yaml</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat metrics-server-deployment.yaml</span></span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: metrics-server</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: metrics-server</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: metrics-server</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: metrics-server</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      name: metrics-server</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: metrics-server</span><br><span class="line">    spec:</span><br><span class="line">      serviceAccountName: metrics-server</span><br><span class="line">      hostNetwork: <span class="literal">true</span> 这个还是需要增加</span><br><span class="line">      volumes:</span><br><span class="line">      <span class="comment"># mount in tmp so we can safely use from-scratch images and/or read-only containers</span></span><br><span class="line">      - name: tmp-dir</span><br><span class="line">        emptyDir: &#123;&#125;</span><br><span class="line">      containers:</span><br><span class="line">      - name: metrics-server</span><br><span class="line">        image: mirrorgooglecontainers/metrics-server-amd64:v0.3.4</span><br><span class="line">        imagePullPolicy: Always</span><br><span class="line">        args:  <span class="comment"># 这里不一样</span></span><br><span class="line">        - --metric-resolution=30s</span><br><span class="line">        - --kubelet-preferred-address-types=InternalIP,Hostname,InternalDNS,ExternalDNS,ExternalIP</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: tmp-dir</span><br><span class="line">          mountPath: /tmp</span><br></pre></td></tr></table></figure></li><li><p>–metric-resolution=30s：从 kubelet 采集数据的周期；</p></li><li><p>–kubelet-preferred-address-types：优先使用 InternalIP 来访问 kubelet，这样可以避免节点名称没有 DNS 解析记录时，通过节点名称调用节点 kubelet API 失败的情况（未配置时默认的情况）；</p></li><li><p><strong>hostNetwork: true:</strong> 这个不增加的会提示：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Error from server (ServiceUnavailable): the server is currently unable to handle the request</span><br></pre></td></tr></table></figure></li><li><p>修改 resource-reader.yaml</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat resource-reader.yaml </span></span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  name: system:metrics-server</span><br><span class="line">rules:</span><br><span class="line">- apiGroups:</span><br><span class="line">  - <span class="string">""</span></span><br><span class="line">  resources:</span><br><span class="line">  - pods</span><br><span class="line">  - nodes</span><br><span class="line">  - nodes/stats</span><br><span class="line">  - namespaces</span><br><span class="line">  verbs:</span><br><span class="line">  - get</span><br><span class="line">  - list</span><br><span class="line">  - watch</span><br><span class="line">- apiGroups: <span class="comment"># 增加</span></span><br><span class="line">  - <span class="string">"extensions"</span></span><br><span class="line">  resources:</span><br><span class="line">  - deployments</span><br><span class="line">  verbs:</span><br><span class="line">  - get</span><br><span class="line">  - list</span><br><span class="line">  - update</span><br><span class="line">  - watch</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: system:metrics-server</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:metrics-server</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: metrics-server</span><br><span class="line">  namespace: kube-system</span><br></pre></td></tr></table></figure></li></ul><h3 id="执行创建"><a href="#执行创建" class="headerlink" title="执行创建"></a>执行创建</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl apply -f ./</span></span><br></pre></td></tr></table></figure><h3 id="查看运行情况"><a href="#查看运行情况" class="headerlink" title="查看运行情况"></a>查看运行情况</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl -n kube-system get pods -l k8s-app=metrics-server</span></span><br><span class="line">NAME                             READY   STATUS    RESTARTS   AGE</span><br><span class="line">metrics-server-94ff5d4cc-b97l5   1/1     Running   0          21m</span><br><span class="line"></span><br><span class="line"><span class="comment">#  kubectl get svc -n kube-system  metrics-server</span></span><br><span class="line">NAME             TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE</span><br><span class="line">metrics-server   ClusterIP   10.254.61.132   &lt;none&gt;        443/TCP   27m</span><br></pre></td></tr></table></figure><h3 id="获取v1beta1-metrics-k8s-io并验证"><a href="#获取v1beta1-metrics-k8s-io并验证" class="headerlink" title="获取v1beta1.metrics.k8s.io并验证"></a>获取v1beta1.metrics.k8s.io并验证</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl get apiservice</span></span><br><span class="line">NAME                                   SERVICE                      AVAILABLE   AGE</span><br><span class="line">v1.                                    Local                        True        23h</span><br><span class="line">v1.apps                                Local                        True        23h</span><br><span class="line">v1.authentication.k8s.io               Local                        True        23h</span><br><span class="line">v1.authorization.k8s.io                Local                        True        23h</span><br><span class="line">v1.autoscaling                         Local                        True        23h</span><br><span class="line">v1.batch                               Local                        True        23h</span><br><span class="line">v1.coordination.k8s.io                 Local                        True        23h</span><br><span class="line">v1.networking.k8s.io                   Local                        True        23h</span><br><span class="line">v1.rbac.authorization.k8s.io           Local                        True        23h</span><br><span class="line">v1.scheduling.k8s.io                   Local                        True        23h</span><br><span class="line">v1.storage.k8s.io                      Local                        True        23h</span><br><span class="line">v1alpha1.auditregistration.k8s.io      Local                        True        23h</span><br><span class="line">v1alpha1.node.k8s.io                   Local                        True        23h</span><br><span class="line">v1alpha1.rbac.authorization.k8s.io     Local                        True        23h</span><br><span class="line">v1alpha1.scheduling.k8s.io             Local                        True        23h</span><br><span class="line">v1alpha1.settings.k8s.io               Local                        True        23h</span><br><span class="line">v1alpha1.storage.k8s.io                Local                        True        23h</span><br><span class="line">v1beta1.admissionregistration.k8s.io   Local                        True        23h</span><br><span class="line">v1beta1.apiextensions.k8s.io           Local                        True        23h</span><br><span class="line">v1beta1.apps                           Local                        True        23h</span><br><span class="line">v1beta1.authentication.k8s.io          Local                        True        23h</span><br><span class="line">v1beta1.authorization.k8s.io           Local                        True        23h</span><br><span class="line">v1beta1.batch                          Local                        True        23h</span><br><span class="line">v1beta1.certificates.k8s.io            Local                        True        23h</span><br><span class="line">v1beta1.coordination.k8s.io            Local                        True        23h</span><br><span class="line">v1beta1.events.k8s.io                  Local                        True        23h</span><br><span class="line">v1beta1.extensions                     Local                        True        23h</span><br><span class="line">v1beta1.metrics.k8s.io                 kube-system/metrics-server   True        27m</span><br><span class="line">v1beta1.networking.k8s.io              Local                        True        23h</span><br><span class="line">v1beta1.node.k8s.io                    Local                        True        23h</span><br><span class="line">v1beta1.policy                         Local                        True        23h</span><br><span class="line">v1beta1.rbac.authorization.k8s.io      Local                        True        23h</span><br><span class="line">v1beta1.scheduling.k8s.io              Local                        True        23h</span><br><span class="line">v1beta1.storage.k8s.io                 Local                        True        23h</span><br><span class="line">v1beta2.apps                           Local                        True        23h</span><br><span class="line">v2alpha1.batch                         Local                        True        23h</span><br><span class="line">v2beta1.autoscaling                    Local                        True        23h</span><br><span class="line">v2beta2.autoscaling                    Local                        True        23h</span><br></pre></td></tr></table></figure><h3 id="metrics-server-的命令行参数"><a href="#metrics-server-的命令行参数" class="headerlink" title="metrics-server 的命令行参数"></a>metrics-server 的命令行参数</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl exec --namespace kube-system -it metrics-server-94ff5d4cc-b97l5 -- /metrics-server --help</span></span><br><span class="line">Launch metrics-server</span><br><span class="line"></span><br><span class="line">Usage:</span><br><span class="line">   [flags]</span><br><span class="line"></span><br><span class="line">Flags:</span><br><span class="line">      --alsologtostderr                                         <span class="built_in">log</span> to standard error as well as files</span><br><span class="line">      --authentication-kubeconfig string                        kubeconfig file pointing at the <span class="string">'core'</span> kubernetes server with enough rights to create tokenaccessreviews.authentication.k8s.io.</span><br><span class="line">      --authentication-skip-lookup                              If <span class="literal">false</span>, the authentication-kubeconfig will be used to lookup missing authentication configuration from the cluster.</span><br><span class="line">      --authentication-token-webhook-cache-ttl duration         The duration to cache responses from the webhook token authenticator. (default 10s)</span><br><span class="line">      --authentication-tolerate-lookup-failure                  If <span class="literal">true</span>, failures to look up missing authentication configuration from the cluster are not considered fatal. Note that this can result <span class="keyword">in</span> authentication that treats all requests as anonymous.</span><br><span class="line">      --authorization-always-allow-paths strings                A list of HTTP paths to skip during authorization, i.e. these are authorized without contacting the <span class="string">'core'</span> kubernetes server.</span><br><span class="line">      --authorization-kubeconfig string                         kubeconfig file pointing at the <span class="string">'core'</span> kubernetes server with enough rights to create subjectaccessreviews.authorization.k8s.io.</span><br><span class="line">      --authorization-webhook-cache-authorized-ttl duration     The duration to cache <span class="string">'authorized'</span> responses from the webhook authorizer. (default 10s)</span><br><span class="line">      --authorization-webhook-cache-unauthorized-ttl duration   The duration to cache <span class="string">'unauthorized'</span> responses from the webhook authorizer. (default 10s)</span><br><span class="line">      --<span class="built_in">bind</span>-address ip                                         The IP address on <span class="built_in">which</span> to listen <span class="keyword">for</span> the --secure-port port. The associated interface(s) must be reachable by the rest of the cluster, and by CLI/web clients. If blank, all interfaces will be used (0.0.0.0 <span class="keyword">for</span> all IPv4 interfaces and :: <span class="keyword">for</span> all IPv6 interfaces). (default 0.0.0.0)</span><br><span class="line">      --cert-dir string                                         The directory <span class="built_in">where</span> the TLS certs are located. If --tls-cert-file and --tls-private-key-file are provided, this flag will be ignored. (default <span class="string">"apiserver.local.config/certificates"</span>)</span><br><span class="line">      --client-ca-file string                                   If <span class="built_in">set</span>, any request presenting a client certificate signed by one of the authorities <span class="keyword">in</span> the client-ca-file is authenticated with an identity corresponding to the CommonName of the client certificate.</span><br><span class="line">      --contention-profiling                                    Enable lock contention profiling, <span class="keyword">if</span> profiling is enabled</span><br><span class="line">  -h, --<span class="built_in">help</span>                                                    <span class="built_in">help</span> <span class="keyword">for</span> this <span class="built_in">command</span></span><br><span class="line">      --http2-max-streams-per-connection int                    The <span class="built_in">limit</span> that the server gives to clients <span class="keyword">for</span> the maximum number of streams <span class="keyword">in</span> an HTTP/2 connection. Zero means to use golang<span class="string">'s default.</span></span><br><span class="line"><span class="string">      --kubeconfig string                                       The path to the kubeconfig used to connect to the Kubernetes API server and the Kubelets (defaults to in-cluster config)</span></span><br><span class="line"><span class="string">      --kubelet-certificate-authority string                    Path to the CA to use to validate the Kubelet'</span>s serving certificates.</span><br><span class="line">      --kubelet-insecure-tls                                    Do not verify CA of serving certificates presented by Kubelets.  For testing purposes only.</span><br><span class="line">      --kubelet-port int                                        The port to use to connect to Kubelets. (default 10250)</span><br><span class="line">      --kubelet-preferred-address-types strings                 The priority of node address types to use when determining <span class="built_in">which</span> address to use to connect to a particular node (default [Hostname,InternalDNS,InternalIP,ExternalDNS,ExternalIP])</span><br><span class="line">      --<span class="built_in">log</span>-flush-frequency duration                            Maximum number of seconds between <span class="built_in">log</span> flushes (default 5s)</span><br><span class="line">      --log_backtrace_at traceLocation                          when logging hits line file:N, emit a stack trace (default :0)</span><br><span class="line">      --log_dir string                                          If non-empty, write <span class="built_in">log</span> files <span class="keyword">in</span> this directory</span><br><span class="line">      --log_file string                                         If non-empty, use this <span class="built_in">log</span> file</span><br><span class="line">      --logtostderr                                             <span class="built_in">log</span> to standard error instead of files (default <span class="literal">true</span>)</span><br><span class="line">      --metric-resolution duration                              The resolution at <span class="built_in">which</span> metrics-server will retain metrics. (default 1m0s)</span><br><span class="line">      --profiling                                               Enable profiling via web interface host:port/debug/pprof/ (default <span class="literal">true</span>)</span><br><span class="line">      --requestheader-allowed-names strings                     List of client certificate common names to allow to provide usernames <span class="keyword">in</span> headers specified by --requestheader-username-headers. If empty, any client certificate validated by the authorities <span class="keyword">in</span> --requestheader-client-ca-file is allowed.</span><br><span class="line">      --requestheader-client-ca-file string                     Root certificate bundle to use to verify client certificates on incoming requests before trusting usernames <span class="keyword">in</span> headers specified by --requestheader-username-headers. WARNING: generally <span class="keyword">do</span> not depend on authorization being already <span class="keyword">done</span> <span class="keyword">for</span> incoming requests.</span><br><span class="line">      --requestheader-extra-headers-prefix strings              List of request header prefixes to inspect. X-Remote-Extra- is suggested. (default [x-remote-extra-])</span><br><span class="line">      --requestheader-group-headers strings                     List of request headers to inspect <span class="keyword">for</span> groups. X-Remote-Group is suggested. (default [x-remote-group])</span><br><span class="line">      --requestheader-username-headers strings                  List of request headers to inspect <span class="keyword">for</span> usernames. X-Remote-User is common. (default [x-remote-user])</span><br><span class="line">      --secure-port int                                         The port on <span class="built_in">which</span> to serve HTTPS with authentication and authorization.If 0, don<span class="string">'t serve HTTPS at all. (default 443)</span></span><br><span class="line"><span class="string">      --skip_headers                                            If true, avoid header prefixes in the log messages</span></span><br><span class="line"><span class="string">      --stderrthreshold severity                                logs at or above this threshold go to stderr</span></span><br><span class="line"><span class="string">      --tls-cert-file string                                    File containing the default x509 Certificate for HTTPS. (CA cert, if any, concatenated after server cert). If HTTPS serving is enabled, and --tls-cert-file and --tls-private-key-file are not provided, a self-signed certificate and key are generated for the public address and saved to the directory specified by --cert-dir.</span></span><br><span class="line"><span class="string">      --tls-cipher-suites strings                               Comma-separated list of cipher suites for the server. If omitted, the default Go cipher suites will be use.  Possible values: TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_RC4_128_SHA,TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_RC4_128_SHA,TLS_RSA_WITH_3DES_EDE_CBC_SHA,TLS_RSA_WITH_AES_128_CBC_SHA,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_RSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_256_CBC_SHA,TLS_RSA_WITH_AES_256_GCM_SHA384,TLS_RSA_WITH_RC4_128_SHA</span></span><br><span class="line"><span class="string">      --tls-min-version string                                  Minimum TLS version supported. Possible values: VersionTLS10, VersionTLS11, VersionTLS12</span></span><br><span class="line"><span class="string">      --tls-private-key-file string                             File containing the default x509 private key matching --tls-cert-file.</span></span><br><span class="line"><span class="string">      --tls-sni-cert-key namedCertKey                           A pair of x509 certificate and private key file paths, optionally suffixed with a list of domain patterns which are fully qualified domain names, possibly with prefixed wildcard segments. If no domain patterns are provided, the names of the certificate are extracted. Non-wildcard matches trump over wildcard matches, explicit domain patterns trump over extracted names. For multiple key/certificate pairs, use the --tls-sni-cert-key multiple times. Examples: "example.crt,example.key" or "foo.crt,foo.key:*.foo.com,foo.com". (default [])</span></span><br><span class="line"><span class="string">  -v, --v Level                                                 number for the log level verbosity</span></span><br><span class="line"><span class="string">      --vmodule moduleSpec                                      comma-separated list of pattern=N settings for file-filtered logging</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;metrics-server这里不详细介绍，可以参考&lt;a href=&quot;https://xxlaila.github.io/2019/09/04/metrics-server安装季/&quot;&gt;metrics-server安装季&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;安装metrics-server&quot;&gt;&lt;a href=&quot;#安装metrics-server&quot; class=&quot;headerlink&quot; title=&quot;安装metrics-server&quot;&gt;&lt;/a&gt;安装metrics-server&lt;/h3&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;这里安装和之前的&lt;strong&gt;metrics-server安装季&lt;/strong&gt;稍微有点不一样，之前集群安装没有使用https证书，后面去各种生成的证书和踩坑，这里是在安装的时候一开始就使用了https全证书,所有稍微有一点区别，这里只列出有区别的地方，其他的完全可以参考&lt;a href=&quot;https://xxlaila.github.io/2019/09/04/metrics-server安装季/&quot;&gt;metrics-server安装季&lt;/a&gt;，这里https证书&lt;strong&gt;不需要&lt;/strong&gt;重新生成；&lt;/p&gt;
    
    </summary>
    
      <category term="kubernetes" scheme="https://xxlaila.github.io/categories/kubernetes/"/>
    
    
      <category term="metrics-server" scheme="https://xxlaila.github.io/tags/metrics-server/"/>
    
  </entry>
  
  <entry>
    <title>k8s v1.14 dashboard</title>
    <link href="https://xxlaila.github.io/2019/09/16/k8s-v1-14-dashboard/"/>
    <id>https://xxlaila.github.io/2019/09/16/k8s-v1-14-dashboard/</id>
    <published>2019-09-16T09:46:10.000Z</published>
    <updated>2019-09-26T03:13:12.863Z</updated>
    
    <content type="html"><![CDATA[<p>kuberntes 自带插件的 manifests yaml 文件使用 gcr.io 的 docker registry，国内被墙，需要手动替换为其它 registry 地址</p><h3 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h3><p>将下载的 kubernetes-server-linux-amd64.tar.gz 解压后，再解压其中的 kubernetes-src.tar.gz 文件。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cd kubernetes</span></span><br><span class="line"><span class="comment"># tar -xzvf kubernetes-src.tar.gz</span></span><br></pre></td></tr></table></figure><p>dashboard 对应的目录是：cluster/addons/dashboard：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cd cluster/addons/dashboard</span></span><br></pre></td></tr></table></figure><p>修改 service 定义，指定端口类型为 NodePort，这样外界可以通过地址 NodeIP:NodePort 访问 dashboard；</p><a id="more"></a><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat dashboard-service.yaml</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: kubernetes-dashboard</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">    kubernetes.io/cluster-service: <span class="string">"true"</span></span><br><span class="line">    addonmanager.kubernetes.io/mode: Reconcile</span><br><span class="line">spec:</span><br><span class="line">  <span class="built_in">type</span>: NodePort <span class="comment"># 增加这一行</span></span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">  ports:</span><br><span class="line">  - port: 443</span><br><span class="line">    targetPort: 8443</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat dashboard-controller.yaml</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">    addonmanager.kubernetes.io/mode: Reconcile</span><br><span class="line">  name: kubernetes-dashboard</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: kubernetes-dashboard</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">    kubernetes.io/cluster-service: <span class="string">"true"</span></span><br><span class="line">    addonmanager.kubernetes.io/mode: Reconcile</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: kubernetes-dashboard</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: kubernetes-dashboard</span><br><span class="line">      annotations:</span><br><span class="line">        scheduler.alpha.kubernetes.io/critical-pod: <span class="string">''</span></span><br><span class="line">        seccomp.security.alpha.kubernetes.io/pod: <span class="string">'docker/default'</span></span><br><span class="line">    spec:</span><br><span class="line">      priorityClassName: system-cluster-critical</span><br><span class="line">      containers:</span><br><span class="line">      - name: kubernetes-dashboard</span><br><span class="line">        image: docker.io/xxlaila/kubernetes-dashboard-amd64:v1.10.0  <span class="comment">#修改这一行</span></span><br><span class="line">        resources:</span><br><span class="line">          limits:</span><br><span class="line">            cpu: 100m</span><br><span class="line">            memory: 300Mi</span><br><span class="line">          requests:</span><br><span class="line">            cpu: 50m</span><br><span class="line">            memory: 100Mi</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 8443</span><br><span class="line">          protocol: TCP</span><br></pre></td></tr></table></figure><h3 id="执行所有定义文件"><a href="#执行所有定义文件" class="headerlink" title="执行所有定义文件"></a>执行所有定义文件</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ls *.yaml</span></span><br><span class="line">dashboard-configmap.yaml  dashboard-controller.yaml  dashboard-rbac.yaml  dashboard-secret.yaml  dashboard-service.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># kubectl apply -f  .</span></span><br></pre></td></tr></table></figure><h3 id="查看分配的-NodePort"><a href="#查看分配的-NodePort" class="headerlink" title="查看分配的 NodePort"></a>查看分配的 NodePort</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl get deployment kubernetes-dashboard  -n kube-system</span></span><br><span class="line">NAME                   READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">kubernetes-dashboard   1/1     1            1           5h10m</span><br><span class="line"></span><br><span class="line"><span class="comment"># kubectl --namespace kube-system get pods -o wide</span></span><br><span class="line">NAME                                    READY   STATUS    RESTARTS   AGE     IP             NODE            NOMINATED NODE   READINESS GATES</span><br><span class="line">coredns-5579b8778b-xw8m9                1/1     Running   1          5h15m   172.30.232.3   172.21.16.204   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kubernetes-dashboard-6cc78dfc99-hb4l5   1/1     Running   0          5h10m   172.30.176.3   172.21.16.240   &lt;none&gt;           &lt;none&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment"># kubectl get services kubernetes-dashboard -n kube-system</span></span><br><span class="line">NAME                   TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)         AGE</span><br><span class="line">kubernetes-dashboard   NodePort   10.254.214.153   &lt;none&gt;        443:32533/TCP   5h10m</span><br></pre></td></tr></table></figure><ul><li>NodePort 32533 映射到 dashboard pod 443 端口；</li></ul><h3 id="查看-dashboard-支持的命令行参数"><a href="#查看-dashboard-支持的命令行参数" class="headerlink" title="查看 dashboard 支持的命令行参数"></a>查看 dashboard 支持的命令行参数</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl exec --namespace kube-system -it kubernetes-dashboard-6cc78dfc99-hb4l5  -- /dashboard --help</span></span><br><span class="line">2019/09/16 09:51:33 Starting overwatch</span><br><span class="line">Usage of /dashboard:</span><br><span class="line">      --alsologtostderr                  <span class="built_in">log</span> to standard error as well as files</span><br><span class="line">      --api-log-level string             Level of API request logging. Should be one of <span class="string">'INFO|NONE|DEBUG'</span>. Default: <span class="string">'INFO'</span>. (default <span class="string">"INFO"</span>)</span><br><span class="line">      --apiserver-host string            The address of the Kubernetes Apiserver to connect to <span class="keyword">in</span> the format of protocol://address:port, e.g., http://localhost:8080. If not specified, the assumption is that the binary runs inside a Kubernetes cluster and <span class="built_in">local</span> discovery is attempted.</span><br><span class="line">      --authentication-mode strings      Enables authentication options that will be reflected on login screen. Supported values: token, basic. Default: token.Note that basic option should only be used <span class="keyword">if</span> apiserver has <span class="string">'--authorization-mode=ABAC'</span> and <span class="string">'--basic-auth-file'</span> flags <span class="built_in">set</span>. (default [token])</span><br><span class="line">      --auto-generate-certificates       When <span class="built_in">set</span> to <span class="literal">true</span>, Dashboard will automatically generate certificates used to serve HTTPS. Default: <span class="literal">false</span>.</span><br><span class="line">      --<span class="built_in">bind</span>-address ip                  The IP address on <span class="built_in">which</span> to serve the --secure-port (<span class="built_in">set</span> to 0.0.0.0 <span class="keyword">for</span> all interfaces). (default 0.0.0.0)</span><br><span class="line">      --default-cert-dir string          Directory path containing <span class="string">'--tls-cert-file'</span> and <span class="string">'--tls-key-file'</span> files. Used also when auto-generating certificates flag is <span class="built_in">set</span>. (default <span class="string">"/certs"</span>)</span><br><span class="line">      --<span class="built_in">disable</span>-settings-authorizer      When enabled, Dashboard settings page will not require user to be logged <span class="keyword">in</span> and authorized to access settings page.</span><br><span class="line">      --<span class="built_in">disable</span>-skip                     When enabled, the skip button on the login page will not be shown. Default: <span class="literal">false</span>.</span><br><span class="line">      --<span class="built_in">enable</span>-insecure-login            When enabled, Dashboard login view will also be shown when Dashboard is not served over HTTPS. Default: <span class="literal">false</span>.</span><br><span class="line">      --heapster-host string             The address of the Heapster Apiserver to connect to <span class="keyword">in</span> the format of protocol://address:port, e.g., http://localhost:8082. If not specified, the assumption is that the binary runs inside a Kubernetes cluster and service proxy will be used.</span><br><span class="line">      --insecure-bind-address ip         The IP address on <span class="built_in">which</span> to serve the --port (<span class="built_in">set</span> to 0.0.0.0 <span class="keyword">for</span> all interfaces). (default 127.0.0.1)</span><br><span class="line">      --insecure-port int                The port to listen to <span class="keyword">for</span> incoming HTTP requests. (default 9090)</span><br><span class="line">      --kubeconfig string                Path to kubeconfig file with authorization and master location information.</span><br><span class="line">      --log_backtrace_at traceLocation   when logging hits line file:N, emit a stack trace (default :0)</span><br><span class="line">      --log_dir string                   If non-empty, write <span class="built_in">log</span> files <span class="keyword">in</span> this directory</span><br><span class="line">      --logtostderr                      <span class="built_in">log</span> to standard error instead of files</span><br><span class="line">      --metric-client-check-period int   Time <span class="keyword">in</span> seconds that defines how often configured metric client health check should be run. Default: 30 seconds. (default 30)</span><br><span class="line">      --port int                         The secure port to listen to <span class="keyword">for</span> incoming HTTPS requests. (default 8443)</span><br><span class="line">      --stderrthreshold severity         logs at or above this threshold go to stderr (default 2)</span><br><span class="line">      --system-banner string             When non-empty displays message to Dashboard users. Accepts simple HTML tags. Default: <span class="string">''</span>.</span><br><span class="line">      --system-banner-severity string    Severity of system banner. Should be one of <span class="string">'INFO|WARNING|ERROR'</span>. Default: <span class="string">'INFO'</span>. (default <span class="string">"INFO"</span>)</span><br><span class="line">      --tls-cert-file string             File containing the default x509 Certificate <span class="keyword">for</span> HTTPS.</span><br><span class="line">      --tls-key-file string              File containing the default x509 private key matching --tls-cert-file.</span><br><span class="line">      --token-ttl int                    Expiration time (<span class="keyword">in</span> seconds) of JWE tokens generated by dashboard. Default: 15 min. 0 - never expires (default 900)</span><br><span class="line">  -v, --v Level                          <span class="built_in">log</span> level <span class="keyword">for</span> V logs</span><br><span class="line">      --vmodule moduleSpec               comma-separated list of pattern=N settings <span class="keyword">for</span> file-filtered logging</span><br><span class="line">pflag: <span class="built_in">help</span> requested</span><br><span class="line"><span class="built_in">command</span> terminated with <span class="built_in">exit</span> code 2</span><br></pre></td></tr></table></figure><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dashboard 的 –authentication-mode 支持 token、basic，默认为 token。如果使用 basic，则 kube-apiserver 必须配置 –authorization-mode=ABAC 和 –basic-auth-file 参数</p><h3 id="访问-dashboard"><a href="#访问-dashboard" class="headerlink" title="访问 dashboard"></a>访问 dashboard</h3><p>使用https协议，在浏览器输入任意node的ip加端口即可访问<br><img src="http://img.xxlaila.cn/1568961339763.jpg" alt="img"></p><h3 id="创建登录-Dashboard-的-token-和-kubeconfig-配置文件"><a href="#创建登录-Dashboard-的-token-和-kubeconfig-配置文件" class="headerlink" title="创建登录 Dashboard 的 token 和 kubeconfig 配置文件"></a>创建登录 Dashboard 的 token 和 kubeconfig 配置文件</h3><p>dashboard 默认只支持 token 认证（不支持 client 证书认证），所以如果使用 Kubeconfig 文件，需要将 token 写入到该文件。</p><h4 id="创建登录-token"><a href="#创建登录-token" class="headerlink" title="创建登录 token"></a>创建登录 token</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl create sa dashboard-admin -n kube-system</span></span><br><span class="line"><span class="comment"># kubectl create clusterrolebinding dashboard-admin --clusterrole=cluster-admin --serviceaccount=kube-system:dashboard-admin</span></span><br><span class="line"><span class="comment"># ADMIN_SECRET=$(kubectl get secrets -n kube-system | grep dashboard-admin | awk '&#123;print $1&#125;')</span></span><br><span class="line"><span class="comment"># DASHBOARD_LOGIN_TOKEN=$(kubectl describe secret -n kube-system $&#123;ADMIN_SECRET&#125; | grep -E '^token' | awk '&#123;print $2&#125;')</span></span><br><span class="line"><span class="comment"># echo $&#123;DASHBOARD_LOGIN_TOKEN&#125;</span></span><br></pre></td></tr></table></figure><p>使用输出的 token 登录 Dashboard。</p><h3 id="创建使用-token-的-KubeConfig-文件"><a href="#创建使用-token-的-KubeConfig-文件" class="headerlink" title="创建使用 token 的 KubeConfig 文件"></a>创建使用 token 的 KubeConfig 文件</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置集群参数</span></span><br><span class="line">kubectl config <span class="built_in">set</span>-cluster kubernetes \</span><br><span class="line">  --certificate-authority=/etc/kubernetes/ssl/ca.pem \</span><br><span class="line">  --embed-certs=<span class="literal">true</span> \</span><br><span class="line">  --server=<span class="variable">$&#123;KUBE_APISERVER&#125;</span> \</span><br><span class="line">  --kubeconfig=dashboard.kubeconfig</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置客户端认证参数，使用上面创建的 Token</span></span><br><span class="line">kubectl config <span class="built_in">set</span>-credentials dashboard_user \</span><br><span class="line">  --token=<span class="variable">$&#123;DASHBOARD_LOGIN_TOKEN&#125;</span> \</span><br><span class="line">  --kubeconfig=dashboard.kubeconfig</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置上下文参数</span></span><br><span class="line">kubectl config <span class="built_in">set</span>-context default \</span><br><span class="line">  --cluster=kubernetes \</span><br><span class="line">  --user=dashboard_user \</span><br><span class="line">  --kubeconfig=dashboard.kubeconfig</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置默认上下文</span></span><br><span class="line">kubectl config use-context default --kubeconfig=dashboard.kubeconfig</span><br></pre></td></tr></table></figure><p>如图:<br><img src="http://img.xxlaila.cn/1568961447890.jpg" alt="img"></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;用生成的 dashboard.kubeconfig 登录 Dashboard。由于k8s 默认的Dashboard 15分钟后就会弹出，又要重新登录和获取token麻烦，可以参考之前的<a href="https://xxlaila.github.io/2019/08/29/k8s配置Dashboard/">k8s配置Dashboard</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;kuberntes 自带插件的 manifests yaml 文件使用 gcr.io 的 docker registry，国内被墙，需要手动替换为其它 registry 地址&lt;/p&gt;
&lt;h3 id=&quot;修改配置文件&quot;&gt;&lt;a href=&quot;#修改配置文件&quot; class=&quot;headerlink&quot; title=&quot;修改配置文件&quot;&gt;&lt;/a&gt;修改配置文件&lt;/h3&gt;&lt;p&gt;将下载的 kubernetes-server-linux-amd64.tar.gz 解压后，再解压其中的 kubernetes-src.tar.gz 文件。&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# cd kubernetes&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# tar -xzvf kubernetes-src.tar.gz&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;p&gt;dashboard 对应的目录是：cluster/addons/dashboard：&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# cd cluster/addons/dashboard&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;p&gt;修改 service 定义，指定端口类型为 NodePort，这样外界可以通过地址 NodeIP:NodePort 访问 dashboard；&lt;/p&gt;
    
    </summary>
    
      <category term="kubernetes" scheme="https://xxlaila.github.io/categories/kubernetes/"/>
    
    
      <category term="v1.14 dashboard" scheme="https://xxlaila.github.io/tags/v1-14-dashboard/"/>
    
  </entry>
  
  <entry>
    <title>k8s v1.14 dns插件</title>
    <link href="https://xxlaila.github.io/2019/09/16/k8s-v1-14-dns%E6%8F%92%E4%BB%B6/"/>
    <id>https://xxlaila.github.io/2019/09/16/k8s-v1-14-dns插件/</id>
    <published>2019-09-16T09:37:06.000Z</published>
    <updated>2019-09-20T05:47:25.878Z</updated>
    
    <content type="html"><![CDATA[<h3 id="部署-coredns-插件"><a href="#部署-coredns-插件" class="headerlink" title="部署 coredns 插件"></a>部署 coredns 插件</h3><p><strong>注意:</strong></p><ul><li>kuberntes 自带插件的 manifests yaml 文件使用 gcr.io 的 docker registry，国内被墙，需要手动替换为其它 registry 地址;</li></ul><h3 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h3><p>将下载的 kubernetes-server-linux-amd64.tar.gz 解压后，再解压其中的 kubernetes-src.tar.gz 文件。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cd kubernetes</span></span><br><span class="line"><span class="comment"># tar -xzvf kubernetes-src.tar.gz</span></span><br></pre></td></tr></table></figure><a id="more"></a><ul><li>coredns 目录是 cluster/addons/dns<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cd cluster/addons/dns/coredns</span></span><br><span class="line"><span class="comment"># cp coredns.yaml.base coredns.yaml</span></span><br><span class="line"><span class="comment"># sed -i -e "s/__PILLAR__DNS__DOMAIN__/cluster.local/" -e "s/__PILLAR__DNS__SERVER__/10.254.0.2/" coredns.yaml</span></span><br><span class="line"><span class="comment"># sed -i "s/k8s.gcr.io/coredns/" coredns.yaml</span></span><br><span class="line"><span class="comment"># kubectl create -f coredns.yaml</span></span><br></pre></td></tr></table></figure></li></ul><h3 id="检查-coredns-功能"><a href="#检查-coredns-功能" class="headerlink" title="检查 coredns 功能"></a>检查 coredns 功能</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl get all -n kube-system</span></span><br><span class="line">NAME                                        READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod/coredns-5579b8778b-xw8m9                1/1     Running   1          5h7m</span><br><span class="line"></span><br><span class="line">NAME                           TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                  AGE</span><br><span class="line">service/kube-dns               ClusterIP   10.254.0.2       &lt;none&gt;        53/UDP,53/TCP,9153/TCP   5h7m</span><br><span class="line"></span><br><span class="line">NAME                                   READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">deployment.apps/coredns                1/1     1            1           5h7m</span><br><span class="line"></span><br><span class="line">NAME                                              DESIRED   CURRENT   READY   AGE</span><br><span class="line">replicaset.apps/coredns-5579b8778b                1         1         1       5h7m</span><br></pre></td></tr></table></figure><h3 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl get pods</span></span><br><span class="line">NAME             READY   STATUS    RESTARTS   AGE</span><br><span class="line">nginx-ds-9fb46   1/1     Running   0          5h14m</span><br><span class="line">nginx-ds-bgfzt   1/1     Running   0          5h14m</span><br><span class="line">nginx-ds-t22wj   1/1     Running   0          5h14m</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl -it exec nginx-ds-9fb46 bash</span></span><br><span class="line">root@nginx-ds-9fb46:/<span class="comment"># cat /etc/resolv.conf</span></span><br><span class="line">nameserver 10.254.0.2</span><br><span class="line">search default.svc.cluster.local svc.cluster.local cluster.local openstacklocal novalocal</span><br><span class="line">options ndots:5</span><br><span class="line"></span><br><span class="line">root@nginx-ds-9fb46:/<span class="comment"># ping www.baidu.com</span></span><br><span class="line">PING www.wshifen.com (104.193.88.77): 48 data bytes</span><br><span class="line">56 bytes from 104.193.88.77: icmp_seq=0 ttl=45 time=191.953 ms</span><br><span class="line">56 bytes from 104.193.88.77: icmp_seq=1 ttl=45 time=191.680 ms</span><br><span class="line">^C--- www.wshifen.com ping statistics ---</span><br><span class="line">2 packets transmitted, 2 packets received, 0% packet loss</span><br><span class="line">round-trip min/avg/max/stddev = 191.680/191.817/191.953/0.137 ms</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">root@nginx-ds-9fb46:/<span class="comment"># ping kube-dns.kube-system.svc</span></span><br><span class="line">PING kube-dns.kube-system.svc.cluster.local (10.254.0.2): 48 data bytes</span><br><span class="line">56 bytes from 10.254.0.2: icmp_seq=0 ttl=64 time=0.120 ms</span><br><span class="line">56 bytes from 10.254.0.2: icmp_seq=1 ttl=64 time=0.116 ms</span><br><span class="line">^C--- kube-dns.kube-system.svc.cluster.local ping statistics ---</span><br><span class="line">2 packets transmitted, 2 packets received, 0% packet loss</span><br><span class="line">round-trip min/avg/max/stddev = 0.116/0.118/0.120/0.000 ms</span><br><span class="line"></span><br><span class="line">root@nginx-ds-9fb46:/<span class="comment"># ping kube-dns.kube-system.svc.cluster.local</span></span><br><span class="line">PING kube-dns.kube-system.svc.cluster.local (10.254.0.2): 48 data bytes</span><br><span class="line">56 bytes from 10.254.0.2: icmp_seq=0 ttl=64 time=0.079 ms</span><br><span class="line">56 bytes from 10.254.0.2: icmp_seq=1 ttl=64 time=0.152 ms</span><br><span class="line">^C--- kube-dns.kube-system.svc.cluster.local ping statistics ---</span><br><span class="line">2 packets transmitted, 2 packets received, 0% packet loss</span><br><span class="line">round-trip min/avg/max/stddev = 0.079/0.115/0.152/0.037 ms</span><br><span class="line"></span><br><span class="line">root@nginx-ds-9fb46:/<span class="comment"># ping kube-dns.kube-system.svc.cluster.local.</span></span><br><span class="line">PING kube-dns.kube-system.svc.cluster.local (10.254.0.2): 48 data bytes</span><br><span class="line">56 bytes from 10.254.0.2: icmp_seq=0 ttl=64 time=0.080 ms</span><br><span class="line">^C--- kube-dns.kube-system.svc.cluster.local ping statistics ---</span><br><span class="line">1 packets transmitted, 1 packets received, 0% packet loss</span><br><span class="line">round-trip min/avg/max/stddev = 0.080/0.080/0.080/0.000 ms</span><br><span class="line">`</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;部署-coredns-插件&quot;&gt;&lt;a href=&quot;#部署-coredns-插件&quot; class=&quot;headerlink&quot; title=&quot;部署 coredns 插件&quot;&gt;&lt;/a&gt;部署 coredns 插件&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;注意:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;kuberntes 自带插件的 manifests yaml 文件使用 gcr.io 的 docker registry，国内被墙，需要手动替换为其它 registry 地址;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;修改配置文件&quot;&gt;&lt;a href=&quot;#修改配置文件&quot; class=&quot;headerlink&quot; title=&quot;修改配置文件&quot;&gt;&lt;/a&gt;修改配置文件&lt;/h3&gt;&lt;p&gt;将下载的 kubernetes-server-linux-amd64.tar.gz 解压后，再解压其中的 kubernetes-src.tar.gz 文件。&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# cd kubernetes&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# tar -xzvf kubernetes-src.tar.gz&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="kubernetes" scheme="https://xxlaila.github.io/categories/kubernetes/"/>
    
    
      <category term="coredns" scheme="https://xxlaila.github.io/tags/coredns/"/>
    
  </entry>
  
  <entry>
    <title>k8s v1.14集群验证</title>
    <link href="https://xxlaila.github.io/2019/09/16/k8s-v1-14%E9%9B%86%E7%BE%A4%E9%AA%8C%E8%AF%81/"/>
    <id>https://xxlaila.github.io/2019/09/16/k8s-v1-14集群验证/</id>
    <published>2019-09-16T09:21:22.000Z</published>
    <updated>2019-09-20T05:47:25.896Z</updated>
    
    <content type="html"><![CDATA[<h3 id="验证集群功能"><a href="#验证集群功能" class="headerlink" title="验证集群功能"></a>验证集群功能</h3><h3 id="检查节点状态"><a href="#检查节点状态" class="headerlink" title="检查节点状态"></a>检查节点状态</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl get nodes</span></span><br><span class="line">NAME            STATUS   ROLES    AGE     VERSION</span><br><span class="line">172.21.16.204   Ready    &lt;none&gt;   5h50m   v1.14.6</span><br><span class="line">172.21.16.240   Ready    &lt;none&gt;   5h48m   v1.14.6</span><br><span class="line">172.21.16.87    Ready    &lt;none&gt;   5h45m   v1.14.6</span><br></pre></td></tr></table></figure><p>都为 Ready 时正常。</p><a id="more"></a><h3 id="创建测试文件"><a href="#创建测试文件" class="headerlink" title="创建测试文件"></a>创建测试文件</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat nginx-ds.yml </span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-ds</span><br><span class="line">  labels:</span><br><span class="line">    app: nginx-ds</span><br><span class="line">spec:</span><br><span class="line">  <span class="built_in">type</span>: NodePort</span><br><span class="line">  selector:</span><br><span class="line">    app: nginx-ds</span><br><span class="line">  ports:</span><br><span class="line">  - name: http</span><br><span class="line">    port: 80</span><br><span class="line">    targetPort: 80</span><br><span class="line">---</span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: DaemonSet</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-ds</span><br><span class="line">  labels:</span><br><span class="line">    addonmanager.kubernetes.io/mode: Reconcile</span><br><span class="line">spec:</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx-ds</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: my-nginx</span><br><span class="line">        image: nginx:1.7.9</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br><span class="line"></span><br><span class="line"><span class="comment"># kubectl create -f nginx-ds.yml</span></span><br></pre></td></tr></table></figure><h3 id="检查各节点的-Pod-IP-连通性"><a href="#检查各节点的-Pod-IP-连通性" class="headerlink" title="检查各节点的 Pod IP 连通性"></a>检查各节点的 Pod IP 连通性</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl get pods  -o wide|grep nginx-ds</span></span><br><span class="line">nginx-ds-9fb46   1/1     Running   0          5h2m   172.30.232.2   172.21.16.204   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">nginx-ds-bgfzt   1/1     Running   0          5h2m   172.30.128.2   172.21.16.87    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">nginx-ds-t22wj   1/1     Running   0          5h2m   172.30.176.2   172.21.16.240   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure><h3 id="检查服务-IP-和端口可达性"><a href="#检查服务-IP-和端口可达性" class="headerlink" title="检查服务 IP 和端口可达性"></a>检查服务 IP 和端口可达性</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl get svc |grep nginx-ds</span></span><br><span class="line">nginx-ds     NodePort    10.254.232.104   &lt;none&gt;        80:30349/TCP   5h2m</span><br></pre></td></tr></table></figure><p>在浏览器在30349进行访问可以看到neinx的欢迎界面</p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;验证集群功能&quot;&gt;&lt;a href=&quot;#验证集群功能&quot; class=&quot;headerlink&quot; title=&quot;验证集群功能&quot;&gt;&lt;/a&gt;验证集群功能&lt;/h3&gt;&lt;h3 id=&quot;检查节点状态&quot;&gt;&lt;a href=&quot;#检查节点状态&quot; class=&quot;headerlink&quot; title=&quot;检查节点状态&quot;&gt;&lt;/a&gt;检查节点状态&lt;/h3&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# kubectl get nodes&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;NAME            STATUS   ROLES    AGE     VERSION&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;172.21.16.204   Ready    &amp;lt;none&amp;gt;   5h50m   v1.14.6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;172.21.16.240   Ready    &amp;lt;none&amp;gt;   5h48m   v1.14.6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;172.21.16.87    Ready    &amp;lt;none&amp;gt;   5h45m   v1.14.6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;p&gt;都为 Ready 时正常。&lt;/p&gt;
    
    </summary>
    
      <category term="kubernetes" scheme="https://xxlaila.github.io/categories/kubernetes/"/>
    
    
      <category term="v1.14" scheme="https://xxlaila.github.io/tags/v1-14/"/>
    
  </entry>
  
  <entry>
    <title>kubernetes-v1.14 node安装</title>
    <link href="https://xxlaila.github.io/2019/09/16/kubernetes-v1-14-node%E5%AE%89%E8%A3%85/"/>
    <id>https://xxlaila.github.io/2019/09/16/kubernetes-v1-14-node安装/</id>
    <published>2019-09-16T07:42:55.000Z</published>
    <updated>2019-09-26T03:13:12.804Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1、安装docker"><a href="#1、安装docker" class="headerlink" title="1、安装docker"></a>1、安装docker</h3><h4 id="1-1、增加docker-源"><a href="#1-1、增加docker-源" class="headerlink" title="1.1、增加docker 源"></a>1.1、增加docker 源</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yum-config-manager \</span><br><span class="line">  --add-repo \</span><br><span class="line">  https://download.docker.com/linux/centos/docker-ce.repo</span><br></pre></td></tr></table></figure><h4 id="1-2、安装docker"><a href="#1-2、安装docker" class="headerlink" title="1.2、安装docker"></a>1.2、安装docker</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#  yum -y install docker-ce</span></span><br></pre></td></tr></table></figure><a id="more"></a><h4 id="1-3、修改docker-systemd-unit-文件"><a href="#1-3、修改docker-systemd-unit-文件" class="headerlink" title="1.3、修改docker systemd unit 文件"></a>1.3、修改docker systemd unit 文件</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat /usr/lib/systemd/system/docker.service |egrep -Ev "^$|^#"</span></span><br><span class="line">[Unit]</span><br><span class="line">Description=Docker Application Container Engine</span><br><span class="line">Documentation=https://docs.docker.com</span><br><span class="line">BindsTo=containerd.service</span><br><span class="line">After=network-online.target firewalld.service containerd.service</span><br><span class="line">Wants=network-online.target</span><br><span class="line">Requires=docker.socket</span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line">EnvironmentFile=-/run/flannel/docker</span><br><span class="line">ExecStart=/usr/bin/dockerd <span class="variable">$DOCKER_NETWORK_OPTIONS</span></span><br><span class="line">ExecReload=/bin/<span class="built_in">kill</span> -s HUP <span class="variable">$MAINPID</span></span><br><span class="line">TimeoutSec=0</span><br><span class="line">RestartSec=2</span><br><span class="line">Restart=always</span><br><span class="line">StartLimitBurst=3</span><br><span class="line">StartLimitInterval=60s</span><br><span class="line">LimitNOFILE=infinity</span><br><span class="line">LimitNPROC=infinity</span><br><span class="line">LimitCORE=infinity</span><br><span class="line">TasksMax=infinity</span><br><span class="line">Delegate=yes</span><br><span class="line">KillMode=process</span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure><ul><li>dockerd 运行时会调用其它 docker 命令，如 docker-proxy，所以需要将 docker 命令所在的目录加到 PATH 环境变量中；</li><li>flanneld 启动时将网络配置写入 /run/flannel/docker 文件中，dockerd 启动前读取该文件中的环境变量 DOCKER_NETWORK_OPTIONS ，然后设置 docker0 网桥网段；</li><li>如果指定了多个 EnvironmentFile 选项，则必须将 /run/flannel/docker 放在最后(确保 docker0 使用 flanneld 生成的 bip 参数)；</li><li>docker 需要以 root 用于运行；</li></ul><h4 id="1-4、启动-docker-服务"><a href="#1-4、启动-docker-服务" class="headerlink" title="1.4、启动 docker 服务"></a>1.4、启动 docker 服务</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># systemctl daemon-reload &amp;&amp; systemctl enable docker &amp;&amp; systemctl restart docker &amp;&amp; systemctl status docker</span></span><br></pre></td></tr></table></figure><h4 id="1-5、检查-docker0-网桥"><a href="#1-5、检查-docker0-网桥" class="headerlink" title="1.5、检查 docker0 网桥"></a>1.5、检查 docker0 网桥</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># /usr/sbin/ip addr show flannel.1 &amp;&amp; /usr/sbin/ip addr show docker0</span></span><br><span class="line">3: flannel.1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UNKNOWN </span><br><span class="line">    link/ether 8a:be:12:b9:ab:b8 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 172.30.128.0/32 scope global flannel.1</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">4: docker0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP </span><br><span class="line">    link/ether 02:42:eb:ec:ae:94 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 172.30.128.1/21 brd 172.30.135.255 scope global docker0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure><h4 id="1-5、查看-docker-的状态信息"><a href="#1-5、查看-docker-的状态信息" class="headerlink" title="1.5、查看 docker 的状态信息"></a>1.5、查看 docker 的状态信息</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ps -elfH|grep docker</span></span><br><span class="line">0 S root      1436   975  0  80   0 - 28167 -      10:54 pts/0    00:00:00                 grep --color=auto docker</span><br><span class="line">4 S root      1265     1  1  80   0 - 122095 futex_ 10:54 ?       00:00:00   /usr/bin/dockerd --bip=172.30.112.1/21 --ip-masq=<span class="literal">false</span> --mtu=1450</span><br><span class="line"></span><br><span class="line"><span class="comment"># docker info</span></span><br><span class="line">vClient:</span><br><span class="line"> Debug Mode: <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">Server:</span><br><span class="line"> Containers: 0</span><br><span class="line">  Running: 0</span><br><span class="line">  Paused: 0</span><br><span class="line">  Stopped: 0</span><br><span class="line"> Images: 0</span><br><span class="line"> Server Version: 18.09.6</span><br><span class="line"> Storage Driver: overlay2</span><br><span class="line">  Backing Filesystem: xfs</span><br><span class="line">  Supports d_type: <span class="literal">true</span></span><br><span class="line">  Native Overlay Diff: <span class="literal">true</span></span><br><span class="line"> Logging Driver: json-file</span><br><span class="line"> Cgroup Driver: cgroupfs</span><br><span class="line"> Plugins:</span><br><span class="line">  Volume: <span class="built_in">local</span></span><br><span class="line">  Network: bridge host macvlan null overlay</span><br><span class="line">  Log: awslogs fluentd gcplogs gelf journald json-file <span class="built_in">local</span> logentries splunk syslog</span><br><span class="line"> Swarm: inactive</span><br><span class="line"> Runtimes: runc</span><br><span class="line"> Default Runtime: runc</span><br><span class="line"> Init Binary: docker-init</span><br><span class="line"> containerd version: 894b81a4b802e4eb2a91d1ce216b8817763c29fb</span><br><span class="line"> runc version: 425e105d5a03fabd737a126ad93d62a9eeede87f</span><br><span class="line"> init version: fec3683</span><br><span class="line"> Security Options:</span><br><span class="line">  seccomp</span><br><span class="line">   Profile: default</span><br><span class="line"> Kernel Version: 4.4.193-1.el7.elrepo.x86_64</span><br><span class="line"> Operating System: CentOS Linux 7 (Core)</span><br><span class="line"> OSType: linux</span><br><span class="line"> Architecture: x86_64</span><br><span class="line"> CPUs: 4</span><br><span class="line"> Total Memory: 7.796GiB</span><br><span class="line"> Name: k8s-node-2.kxl</span><br><span class="line"> ID: GJEA:U6PT:NMHM:KWD2:DOIJ:U6XW:6N3U:4QZN:F5PT:CQXH:MZKU:VATL</span><br><span class="line"> Docker Root Dir: /var/lib/docker</span><br><span class="line"> Debug Mode: <span class="literal">false</span></span><br><span class="line"> Registry: https://index.docker.io/v1/</span><br><span class="line"> Labels:</span><br><span class="line"> Experimental: <span class="literal">false</span></span><br><span class="line"> Insecure Registries:</span><br><span class="line">  127.0.0.0/8</span><br><span class="line"> Live Restore Enabled: <span class="literal">false</span></span><br><span class="line"> Product License: Community Engine</span><br></pre></td></tr></table></figure><h3 id="2、部署-kubelet-组件"><a href="#2、部署-kubelet-组件" class="headerlink" title="2、部署 kubelet 组件"></a>2、部署 kubelet 组件</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;kubelet 运行在每个 worker 节点上，接收 kube-apiserver 发送的请求，管理 Pod 容器，执行交互式命令，如 exec、run、logs 等。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;kubelet 启动时自动向 kube-apiserver 注册节点信息，内置的 cadvisor 统计和监控节点的资源使用情况。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;为确保安全，部署时关闭了 kubelet 的非安全 http 端口，对请求进行认证和授权，拒绝未授权的访问(如 apiserver、heapster 的请求)。</p><h4 id="2-1、创建-kubelet-bootstrap-kubeconfig-文件"><a href="#2-1、创建-kubelet-bootstrap-kubeconfig-文件" class="headerlink" title="2.1、创建 kubelet bootstrap kubeconfig 文件"></a>2.1、创建 kubelet bootstrap kubeconfig 文件</h4><p>NODE_NAMES 里面的值是node的主机名</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># NODE_NAMES=(node-01 node-02 node-03)</span></span><br><span class="line"><span class="keyword">for</span> node_name <span class="keyword">in</span> <span class="variable">$&#123;NODE_NAMES[@]&#125;</span></span><br><span class="line">  <span class="keyword">do</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"&gt;&gt;&gt; <span class="variable">$&#123;node_name&#125;</span>"</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建 token</span></span><br><span class="line">    <span class="built_in">export</span> BOOTSTRAP_TOKEN=$(kubeadm token create \</span><br><span class="line">      --description kubelet-bootstrap-token \</span><br><span class="line">      --groups system:bootstrappers:<span class="variable">$&#123;node_name&#125;</span> \</span><br><span class="line">      --kubeconfig ~/.kube/config)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置集群参数</span></span><br><span class="line">    kubectl config <span class="built_in">set</span>-cluster kubernetes \</span><br><span class="line">      --certificate-authority=/etc/kubernetes/ssl/ca.pem \</span><br><span class="line">      --embed-certs=<span class="literal">true</span> \</span><br><span class="line">      --server=<span class="variable">$&#123;KUBE_APISERVER&#125;</span> \</span><br><span class="line">      --kubeconfig=kubelet-bootstrap-<span class="variable">$&#123;node_name&#125;</span>.kubeconfig</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置客户端认证参数</span></span><br><span class="line">    kubectl config <span class="built_in">set</span>-credentials kubelet-bootstrap \</span><br><span class="line">      --token=<span class="variable">$&#123;BOOTSTRAP_TOKEN&#125;</span> \</span><br><span class="line">      --kubeconfig=kubelet-bootstrap-<span class="variable">$&#123;node_name&#125;</span>.kubeconfig</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置上下文参数</span></span><br><span class="line">    kubectl config <span class="built_in">set</span>-context default \</span><br><span class="line">      --cluster=kubernetes \</span><br><span class="line">      --user=kubelet-bootstrap \</span><br><span class="line">      --kubeconfig=kubelet-bootstrap-<span class="variable">$&#123;node_name&#125;</span>.kubeconfig</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置默认上下文</span></span><br><span class="line">    kubectl config use-context default --kubeconfig=kubelet-bootstrap-<span class="variable">$&#123;node_name&#125;</span>.kubeconfig</span><br><span class="line">  <span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># for node_name in $&#123;NODE_NAMES[@]&#125;</span></span><br><span class="line">  <span class="keyword">do</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"&gt;&gt;&gt; <span class="variable">$&#123;node_name&#125;</span>"</span></span><br><span class="line">    scp kubelet-bootstrap-<span class="variable">$&#123;node_name&#125;</span>.kubeconfig root@<span class="variable">$&#123;node_name&#125;</span>:/etc/kubernetes/kubelet-bootstrap.kubeconfig</span><br><span class="line">  <span class="keyword">done</span></span><br></pre></td></tr></table></figure><ul><li><p>向 kubeconfig 写入的是 token，bootstrap 结束后 kube-controller-manager 为 kubelet 创建 client 和 server 证书；</p></li><li><p>查看 kubeadm 为各节点创建的 token:<br>master 节点查看</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubeadm token list --kubeconfig ~/.kube/config</span></span><br><span class="line">TOKEN                     TTL       EXPIRES                     USAGES                   DESCRIPTION               EXTRA GROUPS</span><br><span class="line">016e9x.306t91l832suzg8i   19h       2019-09-17T11:29:43+08:00   authentication,signing   kubelet-bootstrap-token   system:bootstrappers:node-03</span><br><span class="line">4l4tcx.juy6qs9rmrnfpbig   19h       2019-09-17T11:29:43+08:00   authentication,signing   kubelet-bootstrap-token   system:bootstrappers:node-01</span><br><span class="line">64pk36.vbhvbmtojpskyclt   19h       2019-09-17T11:29:43+08:00   authentication,signing   kubelet-bootstrap-token   system:bootstrappers:node-02</span><br></pre></td></tr></table></figure><ul><li>token 有效期为 1 天，超期后将不能再被用来 boostrap kubelet，且会被 kube-controller-manager 的 tokencleaner 清理；</li><li>kube-apiserver 接收 kubelet 的 bootstrap token 后，将请求的 user 设置为 system:bootstrap:<token id>，group 设置为 system:bootstrappers，后续将为这个 group 设置 ClusterRoleBinding；</token></li></ul></li><li><p>查看各 token 关联的 Secret：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl get secrets  -n kube-system|grep bootstrap-token</span></span><br><span class="line">bootstrap-token-016e9x                           bootstrap.kubernetes.io/token         7      4h25m</span><br><span class="line">bootstrap-token-4l4tcx                           bootstrap.kubernetes.io/token         7      4h25m</span><br><span class="line">bootstrap-token-64pk36                           bootstrap.kubernetes.io/token         7      4h25m</span><br></pre></td></tr></table></figure></li></ul><h4 id="2-2、创建和分发-kubelet-参数配置文件"><a href="#2-2、创建和分发-kubelet-参数配置文件" class="headerlink" title="2.2、创建和分发 kubelet 参数配置文件"></a>2.2、创建和分发 kubelet 参数配置文件</h4><p>从 v1.10 开始，部分 kubelet 参数需在配置文件中配置，kubelet –help 会提示：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DEPRECATED: This parameter should be <span class="built_in">set</span> via the config file specified by the Kubelet<span class="string">'s --config flag</span></span><br></pre></td></tr></table></figure><ul><li><p>创建 kubelet 参数配置文件模板</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat /etc/kubernetes/kubelet-config.yaml</span></span><br><span class="line">kind: KubeletConfiguration</span><br><span class="line">apiVersion: kubelet.config.k8s.io/v1beta1</span><br><span class="line">address: <span class="string">"0.0.0.0"</span></span><br><span class="line">staticPodPath: <span class="string">""</span></span><br><span class="line">syncFrequency: 1m</span><br><span class="line">fileCheckFrequency: 20s</span><br><span class="line">httpCheckFrequency: 20s</span><br><span class="line">staticPodURL: <span class="string">""</span></span><br><span class="line">port: 10250</span><br><span class="line">readOnlyPort: 0</span><br><span class="line">rotateCertificates: <span class="literal">true</span></span><br><span class="line">serverTLSBootstrap: <span class="literal">true</span></span><br><span class="line">authentication:</span><br><span class="line">  anonymous:</span><br><span class="line">    enabled: <span class="literal">false</span></span><br><span class="line">  webhook:</span><br><span class="line">    enabled: <span class="literal">true</span></span><br><span class="line">  x509:</span><br><span class="line">    clientCAFile: <span class="string">"/etc/kubernetes/ssl/ca.pem"</span></span><br><span class="line">authorization:</span><br><span class="line">  mode: Webhook</span><br><span class="line">registryPullQPS: 0</span><br><span class="line">registryBurst: 20</span><br><span class="line">eventRecordQPS: 0</span><br><span class="line">eventBurst: 20</span><br><span class="line">enableDebuggingHandlers: <span class="literal">true</span></span><br><span class="line">enableContentionProfiling: <span class="literal">true</span></span><br><span class="line">healthzPort: 10248</span><br><span class="line">healthzBindAddress: <span class="string">"172.21.16.87"</span> <span class="comment"># node节点ip</span></span><br><span class="line">clusterDomain: <span class="string">"cluster.local"</span></span><br><span class="line">clusterDNS:</span><br><span class="line">  - <span class="string">"10.254.0.2"</span></span><br><span class="line">nodeStatusUpdateFrequency: 10s</span><br><span class="line">nodeStatusReportFrequency: 1m</span><br><span class="line">imageMinimumGCAge: 2m</span><br><span class="line">imageGCHighThresholdPercent: 85</span><br><span class="line">imageGCLowThresholdPercent: 80</span><br><span class="line">volumeStatsAggPeriod: 1m</span><br><span class="line">kubeletCgroups: <span class="string">""</span></span><br><span class="line">systemCgroups: <span class="string">""</span></span><br><span class="line">cgroupRoot: <span class="string">""</span></span><br><span class="line">cgroupsPerQOS: <span class="literal">true</span></span><br><span class="line">cgroupDriver: cgroupfs</span><br><span class="line">runtimeRequestTimeout: 10m</span><br><span class="line">hairpinMode: promiscuous-bridge</span><br><span class="line">maxPods: 100</span><br><span class="line">podCIDR: <span class="string">"172.30.0.0/16"</span></span><br><span class="line">podPidsLimit: -1</span><br><span class="line">resolvConf: /etc/resolv.conf</span><br><span class="line">maxOpenFiles: 1000000</span><br><span class="line">kubeAPIQPS: 1000</span><br><span class="line">kubeAPIBurst: 2000</span><br><span class="line">serializeImagePulls: <span class="literal">false</span></span><br><span class="line">evictionHard:</span><br><span class="line">  memory.available:  <span class="string">"100Mi"</span></span><br><span class="line">nodefs.available:  <span class="string">"10%"</span></span><br><span class="line">nodefs.inodesFree: <span class="string">"5%"</span></span><br><span class="line">imagefs.available: <span class="string">"15%"</span></span><br><span class="line">evictionSoft: &#123;&#125;</span><br><span class="line">enableControllerAttachDetach: <span class="literal">true</span></span><br><span class="line">failSwapOn: <span class="literal">true</span></span><br><span class="line">containerLogMaxSize: 20Mi</span><br><span class="line">containerLogMaxFiles: 10</span><br><span class="line">systemReserved: &#123;&#125;</span><br><span class="line">kubeReserved: &#123;&#125;</span><br><span class="line">systemReservedCgroup: <span class="string">""</span></span><br><span class="line">kubeReservedCgroup: <span class="string">""</span></span><br><span class="line">enforceNodeAllocatable: [<span class="string">"pods"</span>]</span><br></pre></td></tr></table></figure><ul><li>address：kubelet 安全端口（https，10250）监听的地址，不能为 127.0.0.1，否则 kube-apiserver、heapster 等不能调用 kubelet 的 API；</li><li>readOnlyPort=0：关闭只读端口(默认 10255)，等效为未指定；</li><li>authentication.anonymous.enabled：设置为 false，不允许匿名�访问 10250 端口；</li><li>authentication.x509.clientCAFile：指定签名客户端证书的 CA 证书，开启 HTTP 证书认证；</li><li>authentication.webhook.enabled=true：开启 HTTPs bearer token 认证；</li><li>对于未通过 x509 证书和 webhook 认证的请求(kube-apiserver 或其他客户端)，将被拒绝，提示 Unauthorized；</li><li>authroization.mode=Webhook：kubelet 使用 SubjectAccessReview API 查询 kube-apiserver 某 user、group 是否具有操作资源的权限(RBAC)；</li><li>featureGates.RotateKubeletClientCertificate、featureGates.RotateKubeletServerCertificate：自动 rotate 证书，证书的有效期取决于 kube-controller-manager 的 –experimental-cluster-signing-duration 参数；</li><li>需要 root 账户运行；</li></ul></li></ul><h4 id="2-3、创建kubelet-systemd-unit-文件"><a href="#2-3、创建kubelet-systemd-unit-文件" class="headerlink" title="2.3、创建kubelet systemd unit 文件"></a>2.3、创建kubelet systemd unit 文件</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat /usr/lib/systemd/system/kubelet.service </span></span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Kubelet</span><br><span class="line">Documentation=https://github.com/GoogleCloudPlatform/kubernetes</span><br><span class="line">After=docker.service</span><br><span class="line">Requires=docker.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">WorkingDirectory=/var/<span class="built_in">log</span>/k8s/kubelet</span><br><span class="line">ExecStart=/usr/bin/kubelet \</span><br><span class="line">  --allow-privileged=<span class="literal">true</span> \</span><br><span class="line">  --bootstrap-kubeconfig=/etc/kubernetes/kubelet-bootstrap.kubeconfig \</span><br><span class="line">  --cert-dir=/etc/kubernetes/ssl \</span><br><span class="line">  --cni-conf-dir=/etc/cni/net.d \</span><br><span class="line">  --container-runtime=docker \</span><br><span class="line">  --container-runtime-endpoint=unix:///var/run/dockershim.sock \</span><br><span class="line">  --root-dir=/var/lib/kubelet \</span><br><span class="line">  --kubeconfig=/etc/kubernetes/kubelet.kubeconfig \</span><br><span class="line">  --config=/etc/kubernetes/kubelet-config.yaml \</span><br><span class="line">  --hostname-override=172.21.16.87 \ <span class="comment"># node 节点ip</span></span><br><span class="line">  --pod-infra-container-image=registry.cn-beijing.aliyuncs.com/images_k8s/pause-amd64:3.1 \</span><br><span class="line">  --image-pull-progress-deadline=15m \</span><br><span class="line">  --volume-plugin-dir=/var/lib/kubelet/kubelet-plugins/volume/<span class="built_in">exec</span>/ \</span><br><span class="line">  --logtostderr=<span class="literal">true</span> \</span><br><span class="line">  --v=2</span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=5</span><br><span class="line">StartLimitInterval=0</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure><ul><li>如果设置了 –hostname-override 选项，则 kube-proxy 也需要设置该选项，否则会出现找不到 Node 的情况；</li><li>–bootstrap-kubeconfig：指向 bootstrap kubeconfig 文件，kubelet 使用该文件中的用户名和 token 向 kube-apiserver 发送 TLS Bootstrapping 请求；</li><li>K8S approve kubelet 的 csr 请求后，在 –cert-dir 目录创建证书和私钥文件，然后写入 –kubeconfig 文件；</li><li>–pod-infra-container-image 不使用 redhat 的 pod-infrastructure:latest 镜像，它不能回收容器的僵尸；</li></ul><h4 id="2-4、Bootstrap-Token-Auth-和授予权限"><a href="#2-4、Bootstrap-Token-Auth-和授予权限" class="headerlink" title="2.4、Bootstrap Token Auth 和授予权限"></a>2.4、Bootstrap Token Auth 和授予权限</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;kubelet 启动时查找 –kubeletconfig 参数对应的文件是否存在，如果不存在则使用 –bootstrap-kubeconfig 指定的 kubeconfig 文件向 kube-apiserver 发送证书签名请求 (CSR)。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;kube-apiserver 收到 CSR 请求后，对其中的 Token 进行认证，认证通过后将请求的 user 设置为 system:bootstrap:<token id>，group 设置为 system:bootstrappers，这一过程称为 Bootstrap Token Auth。</token></p><p>默认情况下，这个 user 和 group 没有创建 CSR 的权限，kubelet 启动失败，错误日志如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Sep 16 11:39:43 node-02 kubelet[20385]: E0916 11:39:43.858672   20385 reflector.go:126] k8s.io/client-go/informers/factory.go:133: Failed to list *v1beta1.RuntimeClass: Unauthorized</span><br><span class="line">Sep 16 11:39:43 node-02 kubelet[20385]: E0916 11:39:43.860429   20385 reflector.go:126] k8s.io/client-go/informers/factory.go:133: Failed to list *v1beta1.CSIDriver: Unauthorized</span><br><span class="line">Sep 16 11:39:43 node-02 kubelet[20385]: E0916 11:39:43.903098   20385 kubelet.go:2244] node <span class="string">"172.21.16.240"</span> not found</span><br><span class="line">Sep 16 11:39:43 node-02 kubelet[20385]: E0916 11:39:43.985568   20385 reflector.go:126] k8s.io/kubernetes/pkg/kubelet/kubelet.go:442: Failed to list *v1.Service: Unauthorized</span><br><span class="line">Sep 16 11:39:43 node-02 kubelet[20385]: E0916 11:39:43.986781   20385 reflector.go:126] k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:47: Failed to list *v1.Pod: Unauthorized</span><br><span class="line">Sep 16 11:39:43 node-02 kubelet[20385]: E0916 11:39:43.987454   20385 reflector.go:126] k8s.io/kubernetes/pkg/kubelet/kubelet.go:451: Failed to list *v1.Node: Unauthorized</span><br></pre></td></tr></table></figure><p>解决办法是：创建一个 clusterrolebinding，将 group system:bootstrappers 和 clusterrole system:node-bootstrapper 绑定：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl create clusterrolebinding kubelet-bootstrap --clusterrole=system:node-bootstrapper --group=system:bootstrappers</span></span><br></pre></td></tr></table></figure><h4 id="2-5、启动-kubelet-服务"><a href="#2-5、启动-kubelet-服务" class="headerlink" title="2.5、启动 kubelet 服务"></a>2.5、启动 kubelet 服务</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># mkdir -p /var/log/k8s/kubelet</span></span><br><span class="line"><span class="comment"># systemctl daemon-reload &amp;&amp; systemctl enable kubelet &amp;&amp; systemctl restart kubelet &amp;&amp; systemctl status kubelet</span></span><br></pre></td></tr></table></figure><ul><li>启动服务前必须先创建工作目录；</li><li>关闭 swap 分区，否则 kubelet 会启动失败；</li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;kubelet 启动后使用 –bootstrap-kubeconfig 向 kube-apiserver 发送 CSR 请求，当这个 CSR 被 approve 后，kube-controller-manager 为 kubelet 创建 TLS 客户端证书、私钥和 –kubeletconfig 文件。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>注意</strong>：kube-controller-manager 需要配置 –cluster-signing-cert-file 和 –cluster-signing-key-file 参数，才会为 TLS Bootstrap 创建证书和私钥。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl get csr</span></span><br><span class="line">NAME        AGE     REQUESTOR                 CONDITION</span><br><span class="line">csr-bwcbm   82s     system:bootstrap:016e9x   Pending</span><br><span class="line">csr-gqdhf   105s    system:bootstrap:64pk36   Pending</span><br><span class="line">csr-q995g   6m57s   system:bootstrap:4l4tcx   Pending</span><br><span class="line">csr-xx45v   7m33s   system:bootstrap:4l4tcx   Pending</span><br><span class="line"></span><br><span class="line"><span class="comment"># kubectl get nodes</span></span><br><span class="line">No resources found.</span><br></pre></td></tr></table></figure><h4 id="2-6、自动-approve-CSR-请求"><a href="#2-6、自动-approve-CSR-请求" class="headerlink" title="2.6、自动 approve CSR 请求"></a>2.6、自动 approve CSR 请求</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat /etc/kubernetes/csr-crb.yaml</span></span><br><span class="line"><span class="comment"># Approve all CSRs for the group "system:bootstrappers"</span></span><br><span class="line"> kind: ClusterRoleBinding</span><br><span class="line"> apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line"> metadata:</span><br><span class="line">   name: auto-approve-csrs-for-group</span><br><span class="line"> subjects:</span><br><span class="line"> - kind: Group</span><br><span class="line">   name: system:bootstrappers</span><br><span class="line">   apiGroup: rbac.authorization.k8s.io</span><br><span class="line"> roleRef:</span><br><span class="line">   kind: ClusterRole</span><br><span class="line">   name: system:certificates.k8s.io:certificatesigningrequests:nodeclient</span><br><span class="line">   apiGroup: rbac.authorization.k8s.io</span><br><span class="line">---</span><br><span class="line"> <span class="comment"># To let a node of the group "system:nodes" renew its own credentials</span></span><br><span class="line"> kind: ClusterRoleBinding</span><br><span class="line"> apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line"> metadata:</span><br><span class="line">   name: node-client-cert-renewal</span><br><span class="line"> subjects:</span><br><span class="line"> - kind: Group</span><br><span class="line">   name: system:nodes</span><br><span class="line">   apiGroup: rbac.authorization.k8s.io</span><br><span class="line"> roleRef:</span><br><span class="line">   kind: ClusterRole</span><br><span class="line">   name: system:certificates.k8s.io:certificatesigningrequests:selfnodeclient</span><br><span class="line">   apiGroup: rbac.authorization.k8s.io</span><br><span class="line">---</span><br><span class="line"><span class="comment"># A ClusterRole which instructs the CSR approver to approve a node requesting a</span></span><br><span class="line"><span class="comment"># serving cert matching its client cert.</span></span><br><span class="line">kind: ClusterRole</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: approve-node-server-renewal-csr</span><br><span class="line">rules:</span><br><span class="line">- apiGroups: [<span class="string">"certificates.k8s.io"</span>]</span><br><span class="line">  resources: [<span class="string">"certificatesigningrequests/selfnodeserver"</span>]</span><br><span class="line">  verbs: [<span class="string">"create"</span>]</span><br><span class="line">---</span><br><span class="line"> <span class="comment"># To let a node of the group "system:nodes" renew its own server credentials</span></span><br><span class="line"> kind: ClusterRoleBinding</span><br><span class="line"> apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line"> metadata:</span><br><span class="line">   name: node-server-cert-renewal</span><br><span class="line"> subjects:</span><br><span class="line"> - kind: Group</span><br><span class="line">   name: system:nodes</span><br><span class="line">   apiGroup: rbac.authorization.k8s.io</span><br><span class="line"> roleRef:</span><br><span class="line">   kind: ClusterRole</span><br><span class="line">   name: approve-node-server-renewal-csr</span><br><span class="line">   apiGroup: rbac.authorization.k8s.io</span><br></pre></td></tr></table></figure><ul><li>auto-approve-csrs-for-group：自动 approve node 的第一次 CSR； 注意第一次 CSR 时，请求的 Group 为 system:bootstrappers；</li><li>node-client-cert-renewal：自动 approve node 后续过期的 client 证书，自动生成的证书 Group 为 system:nodes;</li><li>node-server-cert-renewal：自动 approve node 后续过期的 server 证书，自动生成的证书 Group 为 system:nodes;</li></ul><h4 id="2-6、等查看-kubelet-的情况"><a href="#2-6、等查看-kubelet-的情况" class="headerlink" title="2.6、等查看 kubelet 的情况"></a>2.6、等查看 kubelet 的情况</h4><p>待一段时间(1-10 分钟)，三个节点的 CSR 都被自动 approved：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl get csr</span></span><br><span class="line">NAME        AGE     REQUESTOR                   CONDITION</span><br><span class="line">csr-2t4bj   2m58s   system:node:172.21.16.240   Pending</span><br><span class="line">csr-2z2mq   4m14s   system:node:172.21.16.204   Pending</span><br><span class="line">csr-bwcbm   6m6s    system:bootstrap:016e9x     Approved,Issued</span><br><span class="line">csr-gqdhf   6m29s   system:bootstrap:64pk36     Approved,Issued</span><br><span class="line">csr-q995g   11m     system:bootstrap:4l4tcx     Approved,Issued</span><br><span class="line">csr-xx45v   12m     system:bootstrap:4l4tcx     Pending</span><br></pre></td></tr></table></figure><ul><li>所有节点均 ready：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl get nodes</span></span><br><span class="line">NAME            STATUS   ROLES    AGE     VERSION</span><br><span class="line">172.21.16.204   Ready    &lt;none&gt;   4m17s   v1.14.6</span><br><span class="line">172.21.16.240   Ready    &lt;none&gt;   3m2s    v1.14.6</span><br><span class="line">172.21.16.87    Ready    &lt;none&gt;   3s      v1.14.6</span><br></pre></td></tr></table></figure></li></ul><p>kube-controller-manager 为各 node 生成了 kubeconfig 文件和公私钥：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ls -l /etc/kubernetes/kubelet.kubeconfig</span></span><br><span class="line">-rw------- 1 root root 2311 Sep 16 11:31 /etc/kubernetes/kubelet.kubeconfig</span><br><span class="line"></span><br><span class="line"><span class="comment"># ls -l /etc/kubernetes/ssl/|grep kubelet</span></span><br><span class="line">-rw------- 1 root root 1281 Sep 16 11:43 kubelet-client-2019-09-16-11-43-20.pem</span><br><span class="line">lrwxrwxrwx 1 root root   58 Sep 16 11:43 kubelet-client-current.pem -&gt; /etc/kubernetes/ssl/kubelet-client-2019-09-16-11-43-20.pem</span><br></pre></td></tr></table></figure><p>没有自动生成 kubelet server 证书；</p><h4 id="2-8、手动-approve-server-cert-csr"><a href="#2-8、手动-approve-server-cert-csr" class="headerlink" title="2.8、手动 approve server cert csr"></a>2.8、手动 approve server cert csr</h4><p>基于<a href="https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet-tls-bootstrapping/#kubelet-configuratio" target="_blank" rel="noopener">安全性考虑</a>，CSR approving controllers 不会自动 approve kubelet server 证书签名请求，需要手动 approve：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl get csr</span></span><br><span class="line">NAME        AGE     REQUESTOR                   CONDITION</span><br><span class="line">csr-2t4bj   3m5s    system:node:172.21.16.240   Pending</span><br><span class="line">csr-2z2mq   4m21s   system:node:172.21.16.204   Pending</span><br><span class="line">csr-bwcbm   6m13s   system:bootstrap:016e9x     Approved,Issued</span><br><span class="line">csr-gqdhf   6m36s   system:bootstrap:64pk36     Approved,Issued</span><br><span class="line">csr-gtkrt   7s      system:node:172.21.16.87    Pending</span><br><span class="line">csr-q995g   11m     system:bootstrap:4l4tcx     Approved,Issued</span><br><span class="line">csr-xx45v   12m     system:bootstrap:4l4tcx     Pending</span><br><span class="line"></span><br><span class="line"><span class="comment"># kubectl certificate approve csr-2t4bj</span></span><br><span class="line">certificatesigningrequest.certificates.k8s.io/csr-2t4bj approved</span><br><span class="line"></span><br><span class="line"><span class="comment"># kubectl certificate approve csr-2z2mq </span></span><br><span class="line">certificatesigningrequest.certificates.k8s.io/csr-2z2mq approved</span><br><span class="line"></span><br><span class="line"><span class="comment"># kubectl certificate approve csr-gtkrt</span></span><br><span class="line">certificatesigningrequest.certificates.k8s.io/csr-gtkrt approved</span><br><span class="line"></span><br><span class="line"><span class="comment"># ls -l /etc/kubernetes/ssl/|grep kubelet</span></span><br><span class="line">-rw------- 1 root root 1281 Sep 16 11:43 kubelet-client-2019-09-16-11-43-20.pem</span><br><span class="line">lrwxrwxrwx 1 root root   58 Sep 16 11:43 kubelet-client-current.pem -&gt; /etc/kubernetes/ssl/kubelet-client-2019-09-16-11-43-20.pem</span><br><span class="line">-rw------- 1 root root 1305 Sep 16 11:44 kubelet-server-2019-09-16-11-44-12.pem</span><br><span class="line">lrwxrwxrwx 1 root root   58 Sep 16 11:44 kubelet-server-current.pem -&gt; /etc/kubernetes/ssl/kubelet-server-2019-09-16-11-44-12.pem</span><br></pre></td></tr></table></figure><h4 id="2-9、kubelet-提供的-API-接口"><a href="#2-9、kubelet-提供的-API-接口" class="headerlink" title="2.9、kubelet 提供的 API 接口"></a>2.9、kubelet 提供的 API 接口</h4><p>kubelet 启动后监听多个端口，用于接收 kube-apiserver 或其它客户端发送的请求：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># netstat -lnpt|grep kubelet</span></span><br><span class="line">tcp        0      0 127.0.0.1:43042         0.0.0.0:*               LISTEN      22726/kubelet       </span><br><span class="line">tcp        0      0 172.21.16.87:10248      0.0.0.0:*               LISTEN      22726/kubelet       </span><br><span class="line">tcp6       0      0 :::10250                :::*                    LISTEN      22726/kubelet</span><br></pre></td></tr></table></figure><ul><li>10248: healthz http 服务；</li><li>10250: https 服务，访问该端口时需要认证和授权（即使访问 /healthz 也需要）；</li><li>未开启只读端口 10255；</li><li>从 K8S v1.10 开始，去除了 –cadvisor-port 参数（默认 4194 端口），不支持访问 cAdvisor UI &amp; API。</li></ul><p>由于关闭了匿名认证，同时开启了 webhook 授权，所有访问 10250 端口 https API 的请求都需要被认证和授权。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;预定义的 ClusterRole system:kubelet-api-admin 授予访问 kubelet 所有 API 的权限(kube-apiserver 使用的 kubernetes 证书 User 授予了该权限)：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl describe clusterrole system:kubelet-api-admin</span></span><br><span class="line">Name:         system:kubelet-api-admin</span><br><span class="line">Labels:       kubernetes.io/bootstrapping=rbac-defaults</span><br><span class="line">Annotations:  rbac.authorization.kubernetes.io/autoupdate: <span class="literal">true</span></span><br><span class="line">PolicyRule:</span><br><span class="line">  Resources      Non-Resource URLs  Resource Names  Verbs</span><br><span class="line">  ---------      -----------------  --------------  -----</span><br><span class="line">  nodes/<span class="built_in">log</span>      []                 []              [*]</span><br><span class="line">  nodes/metrics  []                 []              [*]</span><br><span class="line">  nodes/proxy    []                 []              [*]</span><br><span class="line">  nodes/spec     []                 []              [*]</span><br><span class="line">  nodes/stats    []                 []              [*]</span><br><span class="line">  nodes          []                 []              [get list watch proxy]</span><br></pre></td></tr></table></figure><h4 id="2-10、kubelet-api-认证和授权"><a href="#2-10、kubelet-api-认证和授权" class="headerlink" title="2.10、kubelet api 认证和授权"></a>2.10、kubelet api 认证和授权</h4><p>kubelet 配置了如下认证参数:</p><ul><li>authentication.anonymous.enabled：设置为 false，不允许匿名访问 10250 端口；</li><li>authentication.x509.clientCAFile：指定签名客户端证书的 CA 证书，开启 HTTPs 证书认证；</li><li>authentication.webhook.enabled=true：开启 HTTPs bearer token 认证；</li></ul><p>同时配置了如下授权参数:</p><ul><li>authroization.mode=Webhook：开启 RBAC 授权</li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;kubelet 收到请求后，使用 clientCAFile 对证书签名进行认证，或者查询 bearer token 是否有效。如果两者都没通过，则拒绝请求，提示 Unauthorized：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># curl -s --cacert /etc/kubernetes/ssl/ca.pem https://172.21.16.87:10250/metrics</span></span><br><span class="line">Unauthorized</span><br><span class="line"></span><br><span class="line"><span class="comment"># curl -s --cacert /etc/kubernetes/ssl/ca.pem -H "Authorization: Bearer 123456"  https://172.21.16.87:10250/metrics</span></span><br><span class="line">Unauthorized</span><br></pre></td></tr></table></figure><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过认证后，kubelet 使用 SubjectAccessReview API 向 kube-apiserver 发送请求，查询证书或 token 对应的 user、group 是否有操作资源的权限(RBAC)；</p><h4 id="2-11、证书认证和授权"><a href="#2-11、证书认证和授权" class="headerlink" title="2.11、证书认证和授权"></a>2.11、证书认证和授权</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 权限不足的证书；</span></span><br><span class="line"><span class="comment"># curl -s --cacert /etc/kubernetes/ssl/ca.pem --cert /etc/kubernetes/ssl/kube-controller-manager.pem --key /etc/kubernetes/ssl/kube-controller-manager-key.pem https://172.21.16.87:10250/metrics</span></span><br><span class="line">Forbidden (user=system:kube-controller-manager, verb=get, resource=nodes, subresource=metrics)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用部署 kubectl 命令行工具时创建的、具有最高权限的 admin 证书；</span></span><br><span class="line"><span class="comment"># curl -s --cacert /etc/kubernetes/ssl/ca.pem --cert /etc/kubernetes/ssl/admin.pem --key /etc/kubernetes/ssl/admin-key.pem https://172.21.16.87:10250/metrics</span></span><br><span class="line"><span class="comment"># HELP apiserver_audit_event_total Counter of audit events generated and sent to the audit backend.</span></span><br><span class="line"><span class="comment"># TYPE apiserver_audit_event_total counter</span></span><br><span class="line">apiserver_audit_event_total 0</span><br><span class="line"><span class="comment"># HELP apiserver_audit_requests_rejected_total Counter of apiserver requests rejected due to an error in audit logging backend.</span></span><br><span class="line"><span class="comment"># TYPE apiserver_audit_requests_rejected_total counter</span></span><br><span class="line">apiserver_audit_requests_rejected_total 0</span><br><span class="line"><span class="comment"># HELP apiserver_client_certificate_expiration_seconds Distribution of the remaining lifetime on the certificate used to authenticate a request.</span></span><br><span class="line"><span class="comment"># TYPE apiserver_client_certificate_expiration_seconds histogram</span></span><br><span class="line">apiserver_client_certificate_expiration_seconds_bucket&#123;le=<span class="string">"0"</span>&#125; 0</span><br><span class="line">apiserver_client_certificate_expiration_seconds_bucket&#123;le=<span class="string">"1800"</span>&#125; 0</span><br></pre></td></tr></table></figure><ul><li>–cacert、–cert、–key 的参数值必须是文件路径，如上面的 ./admin.pem 不能省略 ./，否则返回 401 Unauthorized；</li></ul><h4 id="2-12、bear-token-认证和授权"><a href="#2-12、bear-token-认证和授权" class="headerlink" title="2.12、bear token 认证和授权"></a>2.12、bear token 认证和授权</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;创建一个 ServiceAccount，将它和 ClusterRole system:kubelet-api-admin 绑定，从而具有调用 kubelet API 的权限：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl create sa kubelet-api-test</span></span><br><span class="line"><span class="comment"># kubectl create clusterrolebinding kubelet-api-test --clusterrole=system:kubelet-api-admin --serviceaccount=default:kubelet-api-test</span></span><br><span class="line"><span class="comment"># SECRET=$(kubectl get secrets | grep kubelet-api-test | awk '&#123;print $1&#125;')</span></span><br><span class="line"><span class="comment"># TOKEN=$(kubectl describe secret $&#123;SECRET&#125; | grep -E '^token' | awk '&#123;print $2&#125;')</span></span><br><span class="line"><span class="comment"># echo $&#123;TOKEN&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># curl -s --cacert /etc/kubernetes/ssl/ca.pem -H "Authorization: Bearer $&#123;TOKEN&#125;" https://172.21.16.87:10250/metrics|head</span></span><br></pre></td></tr></table></figure><h3 id="3、cadvisor-和-metrics"><a href="#3、cadvisor-和-metrics" class="headerlink" title="3、cadvisor 和 metrics"></a>3、cadvisor 和 metrics</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;cadvisor 是内嵌在 kubelet 二进制中的，统计所在节点各容器的资源(CPU、内存、磁盘、网卡)使用情况的服务。<br>浏览器访问 <a href="https://172.21.16.87:10250/metrics" target="_blank" rel="noopener">https://172.21.16.87:10250/metrics</a> 和 <a href="https://172.21.16.87:10250/metrics/cadvisor" target="_blank" rel="noopener">https://172.21.16.87:10250/metrics/cadvisor</a> 分别返回 kubelet 和 cadvisor 的 metrics。<br><img src="http://img.xxlaila.cn/1568624798589.jpg" alt="img"></p><p><strong>注意:</strong></p><ul><li>kubelet.config.json 设置 authentication.anonymous.enabled 为 false，不允许匿名证书访问 10250 的 https 服务；</li><li>参考<a href="https://xxlaila.github.io/2019/09/04/kubelet提供api请求接口/">kubelet提供api请求接口</a>，创建和导入相关证书，然后访问上面的 10250 端口；</li></ul><h4 id="3-1、获取-kubelet-的配置"><a href="#3-1、获取-kubelet-的配置" class="headerlink" title="3.1、获取 kubelet 的配置"></a>3.1、获取 kubelet 的配置</h4><p>从 kube-apiserver 获取各节点 kubelet 的配置：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用部署 kubectl 命令行工具时创建的、具有最高权限的 admin 证书；</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># curl -sSL --cacert /etc/kubernetes/ssl/ca.pem --cert /etc/kubernetes/ssl/admin.pem --key /etc/kubernetes/ssl/admin-key.pem $&#123;KUBE_APISERVER&#125;/api/v1/nodes/172.21.16.87/proxy/configz | jq  '.kubeletconfig|.kind="KubeletConfiguration"|.apiVersion="kubelet.config.k8s.io/v1beta1"'</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"syncFrequency"</span>: <span class="string">"1m0s"</span>,</span><br><span class="line">  <span class="string">"fileCheckFrequency"</span>: <span class="string">"20s"</span>,</span><br><span class="line">  <span class="string">"httpCheckFrequency"</span>: <span class="string">"20s"</span>,</span><br><span class="line">  <span class="string">"address"</span>: <span class="string">"0.0.0.0"</span>,</span><br><span class="line">  <span class="string">"port"</span>: 10250,</span><br><span class="line">  <span class="string">"rotateCertificates"</span>: <span class="literal">true</span>,</span><br><span class="line">  <span class="string">"serverTLSBootstrap"</span>: <span class="literal">true</span>,</span><br><span class="line">  <span class="string">"authentication"</span>: &#123;</span><br><span class="line">    <span class="string">"x509"</span>: &#123;</span><br><span class="line">      <span class="string">"clientCAFile"</span>: <span class="string">"/etc/kubernetes/ssl/ca.pem"</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">"webhook"</span>: &#123;</span><br><span class="line">      <span class="string">"enabled"</span>: <span class="literal">true</span>,</span><br><span class="line">      <span class="string">"cacheTTL"</span>: <span class="string">"2m0s"</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">"anonymous"</span>: &#123;</span><br><span class="line">      <span class="string">"enabled"</span>: <span class="literal">false</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="string">"authorization"</span>: &#123;</span><br><span class="line">    <span class="string">"mode"</span>: <span class="string">"Webhook"</span>,</span><br><span class="line">    <span class="string">"webhook"</span>: &#123;</span><br><span class="line">      <span class="string">"cacheAuthorizedTTL"</span>: <span class="string">"5m0s"</span>,</span><br><span class="line">      <span class="string">"cacheUnauthorizedTTL"</span>: <span class="string">"30s"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="string">"registryPullQPS"</span>: 0,</span><br><span class="line">  <span class="string">"registryBurst"</span>: 20,</span><br><span class="line">  <span class="string">"eventRecordQPS"</span>: 0,</span><br><span class="line">  <span class="string">"eventBurst"</span>: 20,</span><br><span class="line">  <span class="string">"enableDebuggingHandlers"</span>: <span class="literal">true</span>,</span><br><span class="line">  <span class="string">"enableContentionProfiling"</span>: <span class="literal">true</span>,</span><br><span class="line">  <span class="string">"healthzPort"</span>: 10248,</span><br><span class="line">  <span class="string">"healthzBindAddress"</span>: <span class="string">"172.21.16.87"</span>,</span><br><span class="line">  <span class="string">"oomScoreAdj"</span>: -999,</span><br><span class="line">  <span class="string">"clusterDomain"</span>: <span class="string">"cluster.local"</span>,</span><br><span class="line">  <span class="string">"clusterDNS"</span>: [</span><br><span class="line">    <span class="string">"10.254.0.2"</span></span><br><span class="line">  ],</span><br><span class="line">  <span class="string">"streamingConnectionIdleTimeout"</span>: <span class="string">"4h0m0s"</span>,</span><br><span class="line">  <span class="string">"nodeStatusUpdateFrequency"</span>: <span class="string">"10s"</span>,</span><br><span class="line">  <span class="string">"nodeStatusReportFrequency"</span>: <span class="string">"1m0s"</span>,</span><br><span class="line">  <span class="string">"nodeLeaseDurationSeconds"</span>: 40,</span><br><span class="line">  <span class="string">"imageMinimumGCAge"</span>: <span class="string">"2m0s"</span>,</span><br><span class="line">  <span class="string">"imageGCHighThresholdPercent"</span>: 85,</span><br><span class="line">  <span class="string">"imageGCLowThresholdPercent"</span>: 80,</span><br><span class="line">  <span class="string">"volumeStatsAggPeriod"</span>: <span class="string">"1m0s"</span>,</span><br><span class="line">  <span class="string">"cgroupsPerQOS"</span>: <span class="literal">true</span>,</span><br><span class="line">  <span class="string">"cgroupDriver"</span>: <span class="string">"cgroupfs"</span>,</span><br><span class="line">  <span class="string">"cpuManagerPolicy"</span>: <span class="string">"none"</span>,</span><br><span class="line">  <span class="string">"cpuManagerReconcilePeriod"</span>: <span class="string">"10s"</span>,</span><br><span class="line">  <span class="string">"runtimeRequestTimeout"</span>: <span class="string">"10m0s"</span>,</span><br><span class="line">  <span class="string">"hairpinMode"</span>: <span class="string">"promiscuous-bridge"</span>,</span><br><span class="line">  <span class="string">"maxPods"</span>: 100,</span><br><span class="line">  <span class="string">"podCIDR"</span>: <span class="string">"172.30.0.0/16"</span>,</span><br><span class="line">  <span class="string">"podPidsLimit"</span>: -1,</span><br><span class="line">  <span class="string">"resolvConf"</span>: <span class="string">"/etc/resolv.conf"</span>,</span><br><span class="line">  <span class="string">"cpuCFSQuota"</span>: <span class="literal">true</span>,</span><br><span class="line">  <span class="string">"cpuCFSQuotaPeriod"</span>: <span class="string">"100ms"</span>,</span><br><span class="line">  <span class="string">"maxOpenFiles"</span>: 1000000,</span><br><span class="line">  <span class="string">"contentType"</span>: <span class="string">"application/vnd.kubernetes.protobuf"</span>,</span><br><span class="line">  <span class="string">"kubeAPIQPS"</span>: 1000,</span><br><span class="line">  <span class="string">"kubeAPIBurst"</span>: 2000,</span><br><span class="line">  <span class="string">"serializeImagePulls"</span>: <span class="literal">false</span>,</span><br><span class="line">  <span class="string">"evictionHard"</span>: &#123;</span><br><span class="line">    <span class="string">"memory.available"</span>: <span class="string">"100Mi"</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="string">"evictionPressureTransitionPeriod"</span>: <span class="string">"5m0s"</span>,</span><br><span class="line">  <span class="string">"enableControllerAttachDetach"</span>: <span class="literal">true</span>,</span><br><span class="line">  <span class="string">"makeIPTablesUtilChains"</span>: <span class="literal">true</span>,</span><br><span class="line">  <span class="string">"iptablesMasqueradeBit"</span>: 14,</span><br><span class="line">  <span class="string">"iptablesDropBit"</span>: 15,</span><br><span class="line">  <span class="string">"failSwapOn"</span>: <span class="literal">true</span>,</span><br><span class="line">  <span class="string">"containerLogMaxSize"</span>: <span class="string">"20Mi"</span>,</span><br><span class="line">  <span class="string">"containerLogMaxFiles"</span>: 10,</span><br><span class="line">  <span class="string">"configMapAndSecretChangeDetectionStrategy"</span>: <span class="string">"Watch"</span>,</span><br><span class="line">  <span class="string">"enforceNodeAllocatable"</span>: [</span><br><span class="line">    <span class="string">"pods"</span></span><br><span class="line">  ],</span><br><span class="line">  <span class="string">"kind"</span>: <span class="string">"KubeletConfiguration"</span>,</span><br><span class="line">  <span class="string">"apiVersion"</span>: <span class="string">"kubelet.config.k8s.io/v1beta1"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="4、部署-kube-proxy-组件"><a href="#4、部署-kube-proxy-组件" class="headerlink" title="4、部署 kube-proxy 组件"></a>4、部署 kube-proxy 组件</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;kube-proxy 运行在所有 worker 节点上，它监听 apiserver 中 service 和 endpoint 的变化情况，创建路由规则以提供服务 IP 和负载均衡功能。</p><h4 id="4-1、创建-kube-proxy-证书"><a href="#4-1、创建-kube-proxy-证书" class="headerlink" title="4.1、创建 kube-proxy 证书"></a>4.1、创建 kube-proxy 证书</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kube-proxy-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"CN"</span>: <span class="string">"system:kube-proxy"</span>,</span><br><span class="line">  <span class="string">"key"</span>: &#123;</span><br><span class="line">    <span class="string">"algo"</span>: <span class="string">"rsa"</span>,</span><br><span class="line">    <span class="string">"size"</span>: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="string">"names"</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="string">"C"</span>: <span class="string">"CN"</span>,</span><br><span class="line">      <span class="string">"ST"</span>: <span class="string">"BeiJing"</span>,</span><br><span class="line">      <span class="string">"L"</span>: <span class="string">"BeiJing"</span>,</span><br><span class="line">      <span class="string">"O"</span>: <span class="string">"k8s"</span>,</span><br><span class="line">      <span class="string">"OU"</span>: <span class="string">"4Paradigm"</span></span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><ul><li><p>CN：指定该证书的 User 为 system:kube-proxy；</p></li><li><p>预定义的 RoleBinding system:node-proxier 将User system:kube-proxy 与 Role system:node-proxier 绑定，该 Role 授予了调用 kube-apiserver Proxy 相关 API 的权限；</p></li><li><p>该证书只会被 kube-proxy 当做 client 证书使用，所以 hosts 字段为空；</p></li><li><p>生成证书和私钥</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes  kube-proxy-csr.json | cfssljson -bare kube-proxy</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ls kube-proxy*.pem</span></span><br><span class="line">kube-proxy-key.pem  kube-proxy.pem</span><br></pre></td></tr></table></figure></li></ul><h4 id="4-2、创建和分发-kubeconfig-文件"><a href="#4-2、创建和分发-kubeconfig-文件" class="headerlink" title="4.2、创建和分发 kubeconfig 文件"></a>4.2、创建和分发 kubeconfig 文件</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl config set-cluster kubernetes \</span></span><br><span class="line">  --certificate-authority=ca.pem \</span><br><span class="line">  --embed-certs=<span class="literal">true</span> \</span><br><span class="line">  --server=<span class="variable">$&#123;KUBE_APISERVER&#125;</span> \</span><br><span class="line">  --kubeconfig=kube-proxy.kubeconfig</span><br><span class="line"></span><br><span class="line"><span class="comment"># kubectl config set-credentials kube-proxy \</span></span><br><span class="line">  --client-certificate=kube-proxy.pem \</span><br><span class="line">  --client-key=kube-proxy-key.pem \</span><br><span class="line">  --embed-certs=<span class="literal">true</span> \</span><br><span class="line">  --kubeconfig=kube-proxy.kubeconfig</span><br><span class="line"></span><br><span class="line"><span class="comment"># kubectl config set-context default \</span></span><br><span class="line">  --cluster=kubernetes \</span><br><span class="line">  --user=kube-proxy \</span><br><span class="line">  --kubeconfig=kube-proxy.kubeconfig</span><br><span class="line"></span><br><span class="line"><span class="comment"># kubectl config use-context default --kubeconfig=kube-proxy.kubeconfig</span></span><br></pre></td></tr></table></figure><ul><li>–embed-certs=true：将 ca.pem 和 admin.pem 证书内容嵌入到生成的 kubectl-proxy.kubeconfig 文件中(不加时，写入的是证书文件路径)</li></ul><h4 id="4-3、创建-kube-proxy-配置文件"><a href="#4-3、创建-kube-proxy-配置文件" class="headerlink" title="4.3、创建 kube-proxy 配置文件"></a>4.3、创建 kube-proxy 配置文件</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat /etc/kubernetes/kube-proxy-config.yaml</span></span><br><span class="line">kind: KubeProxyConfiguration</span><br><span class="line">apiVersion: kubeproxy.config.k8s.io/v1alpha1</span><br><span class="line">clientConnection:</span><br><span class="line">  burst: 200</span><br><span class="line">  kubeconfig: <span class="string">"/etc/kubernetes/kube-proxy.kubeconfig"</span></span><br><span class="line">  qps: 100</span><br><span class="line">bindAddress: 0.0.0.0</span><br><span class="line">healthzBindAddress: 172.21.16.87:10256 <span class="comment">#node</span></span><br><span class="line">metricsBindAddress: 172.21.16.87:10249 <span class="comment">#node</span></span><br><span class="line">enableProfiling: <span class="literal">true</span></span><br><span class="line">clusterCIDR: 172.30.0.0/16</span><br><span class="line">hostnameOverride: 172.21.16.87 <span class="comment">#node </span></span><br><span class="line">mode: <span class="string">"ipvs"</span></span><br><span class="line">portRange: <span class="string">""</span></span><br><span class="line">kubeProxyIPTablesConfiguration:</span><br><span class="line">  masqueradeAll: <span class="literal">false</span></span><br><span class="line">kubeProxyIPVSConfiguration:</span><br><span class="line">  scheduler: rr</span><br><span class="line">  excludeCIDRs: []</span><br></pre></td></tr></table></figure><ul><li>bindAddress: 监听地址；</li><li>clientConnection.kubeconfig: 连接 apiserver 的 kubeconfig 文件；</li><li>clusterCIDR: kube-proxy 根据 –cluster-cidr 判断集群内部和外部流量，指定 –cluster-cidr 或 –masquerade-all 选项后 kube-proxy 才会对访问 Service IP 的请求做 SNAT；</li><li>hostnameOverride: 参数值必须与 kubelet 的值一致，否则 kube-proxy 启动后会找不到该 Node，从而不会创建任何 ipvs 规则；</li><li>mode: 使用 ipvs 模式；</li></ul><h4 id="4-4、创建kube-proxy-systemd-unit-文件"><a href="#4-4、创建kube-proxy-systemd-unit-文件" class="headerlink" title="4.4、创建kube-proxy systemd unit 文件"></a>4.4、创建kube-proxy systemd unit 文件</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat /usr/lib/systemd/system/kube-proxy.service </span></span><br><span class="line">[Service]</span><br><span class="line">WorkingDirectory=/var/<span class="built_in">log</span>/k8s/kube-proxy</span><br><span class="line">ExecStart=/usr/bin/kube-proxy \</span><br><span class="line">  --config=/etc/kubernetes/kube-proxy-config.yaml \</span><br><span class="line">  --logtostderr=<span class="literal">true</span> \</span><br><span class="line">  --v=2</span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=5</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure><h4 id="4-5、启动-kube-proxy-服务"><a href="#4-5、启动-kube-proxy-服务" class="headerlink" title="4.5、启动 kube-proxy 服务"></a>4.5、启动 kube-proxy 服务</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># mkdir -p /var/log/k8s/kube-proxy</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># systemctl daemon-reload &amp;&amp; systemctl enable kube-proxy &amp;&amp; systemctl restart kube-proxy &amp;&amp; systemctl status kube-proxy</span></span><br></pre></td></tr></table></figure><h4 id="4-5、检查"><a href="#4-5、检查" class="headerlink" title="4.5、检查"></a>4.5、检查</h4><ul><li><p>查看监听端口</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># netstat -lnpt|grep kube-prox</span></span><br><span class="line">tcp        0      0 172.21.16.87:10256      0.0.0.0:*               LISTEN      27423/kube-proxy    </span><br><span class="line">tcp        0      0 172.21.16.87:10249      0.0.0.0:*               LISTEN      27423/kube-proxy</span><br></pre></td></tr></table></figure></li><li><p>查看 ipvs 路由规则</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ipvsadm -ln</span></span><br><span class="line">IP Virtual Server version 1.2.1 (size=4096)</span><br><span class="line">Prot LocalAddress:Port Scheduler Flags</span><br><span class="line">  -&gt; RemoteAddress:Port           Forward Weight ActiveConn InActConn</span><br><span class="line">TCP  10.254.0.1:443 rr</span><br><span class="line">  -&gt; 172.21.17.30:6443            Masq    1      0          0         </span><br><span class="line">  -&gt; 172.21.17.31:6443            Masq    1      0          0 </span><br><span class="line">  -&gt; 172.21.16.110:6443           Masq    1      0          0</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;1、安装docker&quot;&gt;&lt;a href=&quot;#1、安装docker&quot; class=&quot;headerlink&quot; title=&quot;1、安装docker&quot;&gt;&lt;/a&gt;1、安装docker&lt;/h3&gt;&lt;h4 id=&quot;1-1、增加docker-源&quot;&gt;&lt;a href=&quot;#1-1、增加docker-源&quot; class=&quot;headerlink&quot; title=&quot;1.1、增加docker 源&quot;&gt;&lt;/a&gt;1.1、增加docker 源&lt;/h4&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;yum-config-manager \&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  --add-repo \&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  https://download.docker.com/linux/centos/docker-ce.repo&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;h4 id=&quot;1-2、安装docker&quot;&gt;&lt;a href=&quot;#1-2、安装docker&quot; class=&quot;headerlink&quot; title=&quot;1.2、安装docker&quot;&gt;&lt;/a&gt;1.2、安装docker&lt;/h4&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;#  yum -y install docker-ce&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="kubernetes" scheme="https://xxlaila.github.io/categories/kubernetes/"/>
    
    
      <category term="v1.14 node安装" scheme="https://xxlaila.github.io/tags/v1-14-node%E5%AE%89%E8%A3%85/"/>
    
  </entry>
  
</feed>
