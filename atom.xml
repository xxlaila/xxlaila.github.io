<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>懒羊羊</title>
  
  <subtitle>我是不会和普通的羊一般见识的。</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.xxlaila.cn/"/>
  <updated>2020-02-25T07:37:44.448Z</updated>
  <id>https://www.xxlaila.cn/</id>
  
  <author>
    <name>xxlaila</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Elasticsearch集群规划</title>
    <link href="https://www.xxlaila.cn/2020/02/20/Elasticsearch%E9%9B%86%E7%BE%A4%E8%A7%84%E5%88%92/"/>
    <id>https://www.xxlaila.cn/2020/02/20/Elasticsearch集群规划/</id>
    <published>2020-02-20T07:38:04.000Z</published>
    <updated>2020-02-25T07:37:44.448Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Feb 25 2020 15:38:05 GMT+0800 (China Standard Time) --><h3 id="集群规划"><a href="#集群规划" class="headerlink" title="集群规划"></a>集群规划</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在Elasticsearch集群规划中，如何规划集群，合理的规划集群可以防止Elasticsearch出现脑裂，<a id="more"></a><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;为避免Elasticsearch集群出现脑裂，Elasticsearch的的config目录下elasticsearch.yml文件中配置避免脑裂的参数，常见的参数是<code>discovery.zen.minimum_master_nodes</code>,该参数决定主节点选择工程中至少需要有多少个master节点，默认配置1。基本的参数原则是N/2+1，如在一个3个节点的集群中，<code>discovery.zen.minimum_master_nodes</code>应该设置为2。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果在2个集群节点中，如果吧<code>discovery.zen.minimum_master_nodes</code>设置为2，当两个节点通信失败时，节点1会失去它的主状态，同时节点2也不会被选举为主节点。这种情况下可以配置另外一个参数来防止脑裂，<code>discovery.zen.ping.timeout</code>，默认值时3秒，用该参数来决定节点之间通信的等待时间。如在网络较差的环境里面可以调大该值。但该参数是适用于高网络延迟的情况。建议配置至少3节点的集群。</p><h3 id="分布式集群"><a href="#分布式集群" class="headerlink" title="分布式集群"></a>分布式集群</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Elasticsearch集群中的节点一般分为3中角色，如何区别这种角色，取决于在搭建分布式集群以前需要在配置文件中指定节点角色。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;节点简介</p><ul><li>master 节点: master节点主要负责元数据的处理；比如索引的新增、删除、分片分配等，每当元数据有更新时，master节点负责同步到其他节点上。</li><li>data 节点: data节点上保存了数据分片，负责数据相关的操作，如分片的增删改查以及搜索和整个操作。</li><li>client 节点: client节点起到路由请求作用，可以看作为负载均衡，适用于高并发访问的业务场景。</li></ul><h4 id="列子"><a href="#列子" class="headerlink" title="列子"></a>列子</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3台Elasticsearch服务器(172.21.1.10，172.21.1.11，172.21.1.12)，为避免脑裂，3台机器master节点为2（172.21.1.10，172.21.1.11），同时也为data节点。172.21.1.12为client节点，三个ip对应hostname为：node-10，node-11，node-12。</p><ul><li>172.21.1.10 节点<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">cluster.name: test1</span><br><span class="line">node.name: node-10</span><br><span class="line">network.host: 0.0.0.0</span><br><span class="line">http.port: 9200</span><br><span class="line">node.master: <span class="literal">true</span></span><br><span class="line">node.data: <span class="literal">true</span></span><br><span class="line">discovery.zen.minimum_master_nodes: 2</span><br><span class="line">path.data: /var/lib/elasticsearch</span><br><span class="line">path.logs: /var/<span class="built_in">log</span>/elasticsearch</span><br><span class="line">discovery.zen.ping.unicast.hosts: [<span class="string">"172.21.1.10"</span>, <span class="string">"172.21.1.11"</span>]</span><br><span class="line">http.cors.enable: <span class="literal">true</span></span><br><span class="line">http:cors.allow-origin: <span class="string">"*"</span></span><br></pre></td></tr></table></figure></li></ul><p>注释:</p><ul><li>http.cors.enable: true,http:cors.allow-origin: “*”: 该两个参数为如果要使用head来进行监控Elasticsearch集群，需要配置此参数。<a href="https://github.com/mobz/elasticsearch-head" target="_blank" rel="noopener">elasticsearch-head</a></li></ul><ul><li><p>172.21.1.11 节点</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">cluster.name: test1</span><br><span class="line">node.name: node-11</span><br><span class="line">network.host: 0.0.0.0</span><br><span class="line">http.port: 9200</span><br><span class="line">node.master: <span class="literal">true</span></span><br><span class="line">node.data: <span class="literal">true</span></span><br><span class="line">discovery.zen.minimum_master_nodes: 2</span><br><span class="line">path.data: /var/lib/elasticsearch</span><br><span class="line">path.logs: /var/<span class="built_in">log</span>/elasticsearch</span><br><span class="line">discovery.zen.ping.unicast.hosts: [<span class="string">"172.21.1.10"</span>, <span class="string">"172.21.1.11"</span>]</span><br><span class="line">http.cors.enable: <span class="literal">true</span></span><br><span class="line">http:cors.allow-origin: <span class="string">"*"</span></span><br></pre></td></tr></table></figure></li><li><p>172.21.1.12 节点</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">cluster.name: test1</span><br><span class="line">node.name: node-12</span><br><span class="line">network.host: 0.0.0.0</span><br><span class="line">http.port: 9200</span><br><span class="line">node.master: <span class="literal">false</span></span><br><span class="line">node.data: talse</span><br><span class="line">discovery.zen.minimum_master_nodes: 2</span><br><span class="line">path.data: /var/lib/elasticsearch</span><br><span class="line">path.logs: /var/<span class="built_in">log</span>/elasticsearch</span><br><span class="line">discovery.zen.ping.unicast.hosts: [<span class="string">"172.21.1.10"</span>, <span class="string">"172.21.1.11"</span>]</span><br><span class="line">http.cors.enable: <span class="literal">true</span></span><br><span class="line">http:cors.allow-origin: <span class="string">"*"</span></span><br></pre></td></tr></table></figure></li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;启动各节点进行head验证</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Elasticsearch集群监控查看<a href="http://www.xxlaila.cn/2019/10/17/elasticserch%E6%97%A5%E5%B8%B8%E7%BB%B4%E6%8A%A4/">elasticserch日常维护</a>，监控插件可以参考<a href="http://www.xxlaila.cn/2019/11/19/logstash%E7%9B%91%E6%8E%A7/">logstash监控</a>末尾。</p><h3 id="Elasticsearch集群api"><a href="#Elasticsearch集群api" class="headerlink" title="Elasticsearch集群api"></a>Elasticsearch集群api</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;利用Elasticsearch 集群健康api查看当前集群的健康信息</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">curl http: //127.0.0.1:9200/_cluster/health</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"cluster_name"</span>: <span class="string">"test1"</span>,</span><br><span class="line">  <span class="string">"status"</span>: <span class="string">"green"</span>,</span><br><span class="line">  <span class="string">"timed_out"</span>: <span class="literal">false</span>,</span><br><span class="line">  <span class="string">"number_of_nodes"</span>: 3,</span><br><span class="line">  <span class="string">"number_of_data_nodes"</span>: 3,</span><br><span class="line">  <span class="string">"active_primary_shards"</span>: 162,</span><br><span class="line">  <span class="string">"active_shards"</span>: 324,</span><br><span class="line">  <span class="string">"relocating_shards"</span>: 0,</span><br><span class="line">  <span class="string">"initializing_shards"</span>: 0,</span><br><span class="line">  <span class="string">"unassigned_shards"</span>: 0,</span><br><span class="line">  <span class="string">"delayed_unassigned_shards"</span>: 0,</span><br><span class="line">  <span class="string">"number_of_pending_tasks"</span>: 0,</span><br><span class="line">  <span class="string">"number_of_in_flight_fetch"</span>: 0,</span><br><span class="line">  <span class="string">"task_max_waiting_in_queue_millis"</span>: 0,</span><br><span class="line">  <span class="string">"active_shards_percent_as_number"</span>: 100.0</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="参数解释"><a href="#参数解释" class="headerlink" title="参数解释"></a>参数解释</h4><ul><li>cluster_name: 集群名称</li><li>status: 集群健康状态；green为所有的主分片和从分片都可以用，yellow所有主分片可用，但存在不可用的从分片，red存在不可用的主分片</li><li>timed_out: 是否超时</li><li>number_of_nodes: 节点数，包括master和data。</li><li>number_of_data_nodes: data节点数</li><li>active_primary_shards: 活动的主分片</li><li>active_shards: 所有活动分片数，包括主分片和副本</li><li>relocating_shards: 正在发生迁移的分片</li><li>initializing_shards: 正在初始化的分片</li><li>unassigned_shards: 没有被分配的分片</li><li>delayed_unassigned_shards: 延迟未被分配的分片</li><li>number_of_pending_tasks: master节点任务队列中的任务数</li><li>number_of_in_flight_fetch: 正在进行迁移的分片数</li><li>task_max_waiting_in_queue_millis: 队列中任务的最大等待时间</li><li>active_shards_percent_as_number: 活动分片的百分比</li></ul><h3 id="Elasticsearch容量评估"><a href="#Elasticsearch容量评估" class="headerlink" title="Elasticsearch容量评估"></a>Elasticsearch容量评估</h3><h4 id="存储容量评估"><a href="#存储容量评估" class="headerlink" title="存储容量评估"></a>存储容量评估</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Elasticsearch服务存储空间大小影响因素如下：</p><ul><li>副本数量：副本有利于增加数据的可靠性，但同时会增加存储成本。默认和建议的副本数量为 1。</li><li>索引开销：除原始数据外，ES 需要存储索引等数据，一般情况下数据膨胀为10% (_all等未计算)。</li><li>内部任务开销：ES 自身会占用约 20% 的磁盘空间用于段合并、日志等，因此要预留20%的此部分空间。</li><li>操作系统预留：操作系统也会占用5%的磁盘空间，用于关键流程处理、防止磁盘碎片化问题等。</li><li>安全阈值。通常至少预留15%的安全阈值。</li></ul><p>ES的实际空间可通过下面公式估算:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">实际空间 = 源数据 * (1 + 副本数量) * (1 + 索引开销) / （1-操作系统预留）/(1 - 内部任务开销) </span><br><span class="line">        = 源数据 * (1 + 副本数量) * 1.45</span><br><span class="line">        = 源数据 *2.9</span><br></pre></td></tr></table></figure><blockquote><ul><li>对于_all这项参数，如果不需要在业务上使用，通常建议您禁止或者有选择性地添加。</li><li>如果您需要开启_all参数的索引，磁盘容量的开销也会随之增大。建议在上述评估的基础上，增加空间至原来的1.5倍。<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">磁盘总大小 = 源数据 * (1 + 副本数) * 1.7 * (1 + 0.5) </span><br><span class="line">= 源数据 * 5.1</span><br></pre></td></tr></table></figure></li></ul></blockquote><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;为了保证服务能稳定运行，建议在上述评估的基础上至少预留50%的存储空间，因此建议申请的存储容量为：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">存储容量 = 源数据 * (1 + 副本数量) * 1.45 * （1 + 0.5）</span><br><span class="line">        = 源数据 * 4.35</span><br></pre></td></tr></table></figure><h4 id="服务配置评估"><a href="#服务配置评估" class="headerlink" title="服务配置评估"></a>服务配置评估</h4><ul><li>建议您至少选择 3 个节点，保证集群具有较高的节点故障容错能力。</li><li>如有非常大的存储容量需求，建议主机配置规格更高，有助于提升集群性能和稳定性。</li><li>可以通过观察 CPU 使用率、集群查询QPS、集群写入QPS等监控指标，判断配置是否足够</li></ul><h4 id="分片数量评估"><a href="#分片数量评估" class="headerlink" title="分片数量评估"></a>分片数量评估</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;shard大小和数量是影响ES集群稳定性和性能的重要因素之一。ES集群中任何一个索引都需要有一个合理的shard规划（默认为5个）。索引分片的数量会影响集群稳定性和性能，且通常确定后无法轻松更改，需要提前规划：</p><ul><li>建议单个分片大小在小规格节点下不超过30GB，在高规格节点下不超过50GB。分片过大会导致ES故障的恢复速度慢，分片过小会导致内存不足等问题。</li><li>分片数量要尽量匹配节点数，分片数可以等于节点数，也可以是节点数的整数倍，方便分片在所有数据节点均匀分布。</li><li>对于日志分析或者超大索引场景，建议单个shard大小不要超过100GB。</li><li>单个节点上同一索引的shard个数不要超5个。</li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;利用ansible来安装<a href="https://github.com/xxlaila/ansible" target="_blank" rel="noopener">Elasticsearch</a>集群，</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue Feb 25 2020 15:38:05 GMT+0800 (China Standard Time) --&gt;&lt;h3 id=&quot;集群规划&quot;&gt;&lt;a href=&quot;#集群规划&quot; class=&quot;headerlink&quot; title=&quot;集群规划&quot;&gt;&lt;/a&gt;集群规划&lt;/h3&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;在Elasticsearch集群规划中，如何规划集群，合理的规划集群可以防止Elasticsearch出现脑裂，
    
    </summary>
    
      <category term="elasticsearch" scheme="https://www.xxlaila.cn/categories/elasticsearch/"/>
    
    
      <category term="elasticsearch" scheme="https://www.xxlaila.cn/tags/elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>traefik支持socketio会话</title>
    <link href="https://www.xxlaila.cn/2020/02/17/traefik%E6%94%AF%E6%8C%81socketio%E4%BC%9A%E8%AF%9D/"/>
    <id>https://www.xxlaila.cn/2020/02/17/traefik支持socketio会话/</id>
    <published>2020-02-17T10:48:57.000Z</published>
    <updated>2020-02-17T11:09:56.889Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Thu Feb 20 2020 16:22:06 GMT+0800 (China Standard Time) --><h3 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;公司业务出现使用一个使用websocket的会话需求，和常见的web聊天工具一样，如网页QQ。<a id="more"></a>但是在研发在开发的时候没有做session会话的粘制，于是乎就是能在运维层面进行设置。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>socket.io</code>单节点模式是很容易部署的，但是往往在生产环境一个节点不能满足业务需求，况且还要保证节点挂掉的情况仍能正常提供服务，所以多节点模式就成为了生成环境的一种必须的部署模式。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;将介绍如何在kubernetes 集群上部署多节点的socket.io服务，并使用traeifk 2.1 版本如何进行访问</p><h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在普通环境下，我们配置websocket会话使用nginx很简单，配置一个ip_hash，其他的和普通的location配置差不多，但在kubernetes集群下，生产环境一般部署多个POD 来提供服务，而socket.io服务并不是单纯的无状态应用，只需要将POD 部署成多个就可以正常提供服务了，因为其底层需要建立很多连接来保持长连接，但是这样的话上一个请求可能会被路由到一个POD，下一个请求则很有可能会被路由到另外一个POD 中去了，这样就会出现错误。<br><img src="https://img.xxlaila.cn/1581937028934.jpg" alt="img"></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;上图中可以看出是有的请求找不到对应的Session ID，也证明了上面提到的引起错误的原因。</p><h3 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从<a href="https://socket.io/docs/using-multiple-nodes/" target="_blank" rel="noopener">socket.io 官方文档</a>中可以看到对于多节点的介绍，其中通过Nginx的ip_hash 配置用得比较多，同一个ip 访问的请求通过hash 计算过后会被路由到相同的后端程序去，这样就不会出现上面的问题了。我们这里是部署在kubernetes集群上面的，通过traefik ingress来连接外部和集群内部间的请求的，所以这里中间就省略了Nginx这一层，当然你也可以多加上这一层，但是这样显然从架构上就冗余了，而且还有更好的解决方案的：sessionAffinity（也称会话亲和力）</p><blockquote><p>什么是sessionAffinity？ sessionAffinity是一个功能，将来自同一个客户端的请求总是被路由回服务器集群中的同一台服务器的能力。</p></blockquote><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在kubernetes中启用sessionAffinity很简单，只需要简单的Service中配置即可：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service.spec.sessionAffinity = <span class="string">"ClientIP"</span></span><br></pre></td></tr></table></figure><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;默认情况下sessionAffinity=None，会随机选择一个后端进行路由转发的，设置成ClientIP后就和上面的ip_hash功能一样了，由于我们使用的是traefik ingress，这里还需要在Service中添加一个traefik的annotation：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: socket-demo</span><br><span class="line">  namespace: kube-apps</span><br><span class="line">  annotations:</span><br><span class="line">    traefik.backend.loadbalancer.stickiness: <span class="string">"true"</span></span><br><span class="line">    traefik.backend.loadbalancer.stickiness.cookieName: <span class="string">"socket"</span></span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: socket-demo</span><br><span class="line">spec:</span><br><span class="line">  sessionAffinity: <span class="string">"ClientIP"</span></span><br><span class="line">  ports:</span><br><span class="line">    - name: socketio</span><br><span class="line">      port: 80</span><br><span class="line">      protocol: TCP</span><br><span class="line">      targetPort: 3000</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: socket-demo</span><br></pre></td></tr></table></figure><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在traefik 的路径下面建立一个socket.toml文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[http]</span><br><span class="line">  [http.routers]</span><br><span class="line">    [http.routers.socketio]</span><br><span class="line">      namespace = <span class="string">"kube-ops"</span></span><br><span class="line">      entryPoints = [<span class="string">"web"</span>]</span><br><span class="line">      service = <span class="string">"socket-demo"</span></span><br><span class="line">      rule = <span class="string">"Host(`socket-demo.xxlaila.cn`)"</span></span><br><span class="line">  [http.services]</span><br><span class="line">    [http.services.socket-demo]</span><br><span class="line">      [http.services.socket-demo.loadBalancer]</span><br><span class="line">      passHostHeader = <span class="literal">true</span></span><br><span class="line">      [[http.services.socket-demo.loadBalancer.servers]]</span><br><span class="line">        url = <span class="string">"http://socket-demo.kube-ops.svc.cluster.local:80"</span></span><br></pre></td></tr></table></figure><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;完成以后可以执行测试，打印出来的hostname是一样的，因为使用的所有的访问都来自一个ip地址。</p><p>部署在kubernetes集群上的yaml文件如下:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: socket-demo</span><br><span class="line">  namespace: kube-apps</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: socket-demo</span><br><span class="line">spec:</span><br><span class="line">  replicas: 3</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: socket-demo</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - image: cnych/socketdemo:k8s</span><br><span class="line">          imagePullPolicy: Always</span><br><span class="line">          name: socketdemo</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 3000</span><br><span class="line">              protocol: TCP</span><br><span class="line">          resources:</span><br><span class="line">            limits:</span><br><span class="line">              cpu: 100m</span><br><span class="line">              memory: 100Mi</span><br><span class="line">            requests:</span><br><span class="line">              cpu: 50m</span><br><span class="line">              memory: 50Mi</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: socket-demo</span><br><span class="line">  namespace: kube-apps</span><br><span class="line">  annotations:</span><br><span class="line">    traefik.backend.loadbalancer.stickiness: <span class="string">"true"</span></span><br><span class="line">    traefik.backend.loadbalancer.stickiness.cookieName: <span class="string">"socket"</span></span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: socket-demo</span><br><span class="line">spec:</span><br><span class="line">  sessionAffinity: None</span><br><span class="line">  ports:</span><br><span class="line">    - name: socketio</span><br><span class="line">      port: 80</span><br><span class="line">      protocol: TCP</span><br><span class="line">      targetPort: 3000</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: socket-demo</span><br></pre></td></tr></table></figure><blockquote><p>参考文献:<br><a href="https://www.qikqiak.com/post/socketio-multiple-nodes-in-kubernetes/" target="_blank" rel="noopener">https://www.qikqiak.com/post/socketio-multiple-nodes-in-kubernetes/</a><br><a href="https://docs.traefik.cn/toml#configuration-backends" target="_blank" rel="noopener">https://docs.traefik.cn/toml#configuration-backends</a></p></blockquote><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Thu Feb 20 2020 16:22:06 GMT+0800 (China Standard Time) --&gt;&lt;h3 id=&quot;场景&quot;&gt;&lt;a href=&quot;#场景&quot; class=&quot;headerlink&quot; title=&quot;场景&quot;&gt;&lt;/a&gt;场景&lt;/h3&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;公司业务出现使用一个使用websocket的会话需求，和常见的web聊天工具一样，如网页QQ。
    
    </summary>
    
      <category term="traefik" scheme="https://www.xxlaila.cn/categories/traefik/"/>
    
    
      <category term="socketio" scheme="https://www.xxlaila.cn/tags/socketio/"/>
    
  </entry>
  
  <entry>
    <title>白话Kubernetes基础概念</title>
    <link href="https://www.xxlaila.cn/2020/02/17/%E7%99%BD%E8%AF%9DKubernetes%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/"/>
    <id>https://www.xxlaila.cn/2020/02/17/白话Kubernetes基础概念/</id>
    <published>2020-02-17T07:58:00.000Z</published>
    <updated>2020-02-17T08:02:20.106Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Thu Feb 20 2020 16:22:06 GMT+0800 (China Standard Time) --><h2 id="Kubernetes-简介"><a href="#Kubernetes-简介" class="headerlink" title="Kubernetes 简介"></a>Kubernetes 简介</h2><p>微服务框架的流行，使得服务越来越精细化，服务也变的越来越多，对于发布和管理而言产生了巨大的挑战，而 <code>Docker</code> 的诞生，给与微服务的资源治理和控制提供了很好的基础。<a id="more"></a>容器化可以解决各个不同语言环境部署、移植性高、跨平台部署等。但是 <code>Docker</code> 对于容器服务的编排没有那么方便，因为 <code>Docker</code> 这方面不足，而诞生 <code>Kubernetes</code>，<code>Kubernetes</code> 是一个可移植的、可扩展的开源平台，用于管理容器化的工作负载和服务，可促进声明式配置和自动化。</p><h2 id="使用-Kubernetes-带来那些方便"><a href="#使用-Kubernetes-带来那些方便" class="headerlink" title="使用 Kubernetes 带来那些方便"></a>使用 Kubernetes 带来那些方便</h2><ul><li>快速部署应用</li><li>很容易实现 水平伸缩 或 垂直伸缩</li><li>无缝发布新的应用版本</li><li>资源使用最大化</li><li>应用停止自动重启</li></ul><h2 id="Kubernetes-特点"><a href="#Kubernetes-特点" class="headerlink" title="Kubernetes 特点"></a>Kubernetes 特点</h2><ul><li>可移植：支持公有云、私有云、混合云、多重云（multi-cloud）</li><li>可扩展：模块化、插件化、可挂载、可组合</li><li>自动化：自动部署、自动重启、自动复制、自动伸缩/扩展</li></ul><h2 id="为什么需要-Kubernetes，它能做什么"><a href="#为什么需要-Kubernetes，它能做什么" class="headerlink" title="为什么需要 Kubernetes，它能做什么?"></a>为什么需要 Kubernetes，它能做什么?</h2><p>容器是打包和运行应用程序的好方式。在生产环境中，您需要管理运行应用程序的容器，并确保不会停机。例如，如果一个容器发生故障，则需要启动另一个容器。如果系统处理此行为，会不会更容易？</p><p>这就是 Kubernetes 的救援方法！Kubernetes 为您提供了一个可弹性运行分布式系统的框架。Kubernetes 会满足您的扩展要求、故障转移、部署模式等。</p><p>Kubernetes 为您提供：</p><ul><li><p><code>服务发现和负载均衡</code>：Kubernetes 可以使用 DNS 名称或自己的 IP 地址公开容器，如果到容器的流量很大，Kubernetes 可以负载均衡并分配网络流量，从而使部署稳定。</p></li><li><p><code>存储编排</code>：Kubernetes 允许您自动挂载您选择的存储系统，例如本地存储、公共云提供商等。</p></li><li><p><code>自动部署和回滚</code>：您可以使用 Kubernetes 描述已部署容器的所需状态，它可以以受控的速率将实际状态更改为所需状态。例如，您可以自动化 Kubernetes 来为您的部署创建新容器，删除现有容器并将它们的所有资源用于新容器。</p></li><li><p><code>容器资源配额</code>：Kubernetes 允许您指定每个容器所需 CPU 和内存（RAM）。当容器指定了资源请求时，Kubernetes 可以做出更好的决策来管理容器的资源。</p></li><li><p><code>自我修复</code>：Kubernetes 重新启动失败的容器、替换容器、杀死不响应用户定义的运行状况检查的容器，并且在准备好服务之前不将其通告给客户端。</p></li><li><p><code>密钥与配置管理</code>：Kubernetes 允许您存储和管理敏感信息，例如密码、OAuth 令牌和 ssh 密钥。您可以在不重建容器镜像的情况下部署和更新密钥和应用程序配置，也无需在堆栈配置中暴露密钥。</p></li><li><p><code>配置文件</code>：Kubernetes 可以通过 ConfigMap 来存储配置。</p></li></ul><h2 id="Kubernetes-基础资源定义和理解"><a href="#Kubernetes-基础资源定义和理解" class="headerlink" title="Kubernetes 基础资源定义和理解"></a>Kubernetes 基础资源定义和理解</h2><p>一切皆为资源，一切即可描述，一切皆可管理。</p><h3 id="NameSpaces"><a href="#NameSpaces" class="headerlink" title="NameSpaces"></a>NameSpaces</h3><p>命名空间，在一个 Kubernetes 集群中可以使用namespace创建多个“虚拟集群”，这些namespace之间可以完全隔离，也可以通过某种方式，让一个namespace中的service可以访问到其他的namespace中的服务。</p><h3 id="Deployment"><a href="#Deployment" class="headerlink" title="Deployment"></a>Deployment</h3><p>Deployment 为 Pod 和 ReplicaSet 提供了一个声明式定义(declarative)方法，用来替代以前的 <code>ReplicationController</code> 来方便的管理应用。典型的应用场景包括：</p><ul><li>定义Deployment来创建Pod和ReplicaSet</li><li>滚动升级和回滚应用</li><li>扩容和缩容</li><li>暂停和继续Deployment</li></ul><h3 id="Service"><a href="#Service" class="headerlink" title="Service"></a>Service</h3><p>Kubernetes Service 定义了这样一种抽象：一个 Pod 的逻辑分组，一种可以访问它们的策略 —— 通常称为<code>微服务</code>。 这一组 Pod 能够被 Service 访问到，通常是通过 Label Selector实现的。</p><h3 id="Ingress"><a href="#Ingress" class="headerlink" title="Ingress"></a>Ingress</h3><p>Ingress 是从 Kubernetes集群外部访问集群内部服务的入口。比如官方维护的 <code>Ingress Nginx</code>。<code>ingress traefik</code>、<code>ingress haproxy</code>等。</p><h3 id="Pod"><a href="#Pod" class="headerlink" title="Pod"></a>Pod</h3><p>Pod 是 kubernetes 中你可以创建和部署的最小也是最简的单位。Pod代表着集群中运行的进程。</p><p>Pod中封装着应用的容器（有的情况下是好几个容器），存储、独立的网络IP，管理容器如何运行的策略选项。Pod代表着部署的一个单位：kubernetes中应用的一个实例，可能由一个或者多个容器组合在一起共享资源。</p><h3 id="ConfigMap"><a href="#ConfigMap" class="headerlink" title="ConfigMap"></a>ConfigMap</h3><p>ConfigMap API 资源用来保存 key-value pair配置数据，这个数据可以在pods里使用，或者被用来为像controller一样的系统组件存储配置数据。虽然 ConfigMap 跟 Secrets 类似，但是ConfigMap更方便的处理不含敏感信息的字符串。 注意：ConfigMaps不是属性配置文件的替代品。ConfigMaps只是作为多个properties文件的引用。你可以把它理解为Linux系统中的/etc目录，专门用来存储配置文件的目录。</p><h3 id="Secret"><a href="#Secret" class="headerlink" title="Secret"></a>Secret</h3><p>Secret 解决了密码、token、密钥等敏感数据的配置问题，而不需要把这些敏感数据暴露到镜像或者Pod Spec中。Secret 可以以Volume或者环境变量的方式使用。</p><p>Secret有三种类型：</p><ul><li><code>Service Account</code> ：用来访问Kubernetes API，由Kubernetes自动创建，并且会自动挂载到Pod的/run/secrets/kubernetes.io/serviceaccount目录中；</li><li><code>Opaque</code> ：base64编码格式的Secret，用来存储密码、密钥等；</li><li><code>kubernetes.io/dockerconfigjson</code> ：用来存储私有docker registry的认证信息。</li></ul><h3 id="PV-和-PVC"><a href="#PV-和-PVC" class="headerlink" title="PV 和 PVC"></a>PV 和 PVC</h3><p>用于数据持续存储，Pod中，容器销毁，所有数据都会被销毁，如果需要保留数据，这里就需要用到 PV存储卷，PVC存储卷申明。</p><p>PVC 常用于 Deployment 做数据持久存储。实现持久化存储还需要理解 Volume 概念。</p><h3 id="Volume"><a href="#Volume" class="headerlink" title="Volume"></a>Volume</h3><p>容器磁盘上的文件的生命周期是短暂的，这就使得在容器中运行重要应用时会出现一些问题。首先，当容器崩溃时，kubelet 会重启它，但是容器中的文件将丢失——容器以干净的状态（镜像最初的状态）重新启动。其次，在 Pod 中同时运行多个容器时，这些容器之间通常需要共享文件。Kubernetes 中的 Volume 抽象就很好的解决了这些问题。</p><h3 id="Labels-和-Selectors"><a href="#Labels-和-Selectors" class="headerlink" title="Labels 和 Selectors"></a>Labels 和 Selectors</h3><p><code>标签</code> 和 <code>选择器</code>。作用用于给每个容器打标签，然后各个控制器通过 Selector 匹配容器，并管理。比如 Deployment 或 Service 都是通过这种方式匹配相应的 Pod。</p><h2 id="自述"><a href="#自述" class="headerlink" title="自述"></a>自述</h2><p>以上只是介绍 Kubernetes 几种常用的资源概念和作用，具体介绍可以查阅<a href="https://kubernetes.io/docs/home/" target="_blank" rel="noopener">Kubernetes 官方文档</a>。</p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul><li><a href="https://kubernetes.io/docs/home/" target="_blank" rel="noopener">https://kubernetes.io/docs/home/</a></li><li><a href="https://jimmysong.io/kubernetes-handbook" target="_blank" rel="noopener">https://jimmysong.io/kubernetes-handbook</a></li><li><a href="https://www.jianshu.com/p/b5b9041e8d7b" target="_blank" rel="noopener">https://www.jianshu.com/p/b5b9041e8d7b</a></li></ul><blockquote><ul><li>来源: 微信群分享</li><li>原文: <a href="https://www.yp14.cn/2020/01/04/%E7%99%BD%E8%AF%9D-Kubernetes-%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/" target="_blank" rel="noopener">yp14</a></li><li>版本: 本文版权归原作者所有</li></ul></blockquote><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Thu Feb 20 2020 16:22:06 GMT+0800 (China Standard Time) --&gt;&lt;h2 id=&quot;Kubernetes-简介&quot;&gt;&lt;a href=&quot;#Kubernetes-简介&quot; class=&quot;headerlink&quot; title=&quot;Kubernetes 简介&quot;&gt;&lt;/a&gt;Kubernetes 简介&lt;/h2&gt;&lt;p&gt;微服务框架的流行，使得服务越来越精细化，服务也变的越来越多，对于发布和管理而言产生了巨大的挑战，而 &lt;code&gt;Docker&lt;/code&gt; 的诞生，给与微服务的资源治理和控制提供了很好的基础。
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>如何实现应用在Kubernetes上的优雅落地</title>
    <link href="https://www.xxlaila.cn/2020/02/17/%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E5%BA%94%E7%94%A8%E5%9C%A8Kubernetes%E4%B8%8A%E7%9A%84%E4%BC%98%E9%9B%85%E8%90%BD%E5%9C%B0/"/>
    <id>https://www.xxlaila.cn/2020/02/17/如何实现应用在Kubernetes上的优雅落地/</id>
    <published>2020-02-17T07:31:30.000Z</published>
    <updated>2020-02-17T08:08:03.761Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Thu Feb 20 2020 16:22:07 GMT+0800 (China Standard Time) --><h3 id="Kubernetes-热度"><a href="#Kubernetes-热度" class="headerlink" title="Kubernetes 热度"></a>Kubernetes 热度</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;国内外对 Kubernetes 这波潮流的追捧，包括各大云厂商：蚂蚁金服、京东、美团、滴滴等各大公司都把 Kubernetes 作为自己的基础设施的重心。<a id="more"></a>“一万个人眼中就有一万个哈姆雷特”，虽说 Kubernetes 是容器管理领域的事实标准，但实际上在不同背景的企业 Kubernetes 的落地方式上是存在差异的。大致可分为三类：</p><ul><li>一类是完全在 Kubernetes 之上（Above）以其原生方式部署和应用，这类用户大部分是一些初创企业，没有过多的技术栈负担，并且主要集中在使用公有云的 Kubernetes 方案和服务；</li><li>一类是基于 Kubernetes（On）构建的容器管理平台，复用了 Kubernetes 的一些概念但是并没有把应用的管理交给 Kubernetes 来管理，保持着旧的服务治理方式。这类企业发展时间比较久，技术负担比较重，无法立即切换到云原生的服务治理方式，一时无法抛弃多年的技术积累，这类用户主要集中在一些中型或大型的私有云的 Kubernetes 使用场景；</li><li>另一类是基于 Kubernetes 的设计理念（In）通过自定义应用负载来解决和适应本地化的应用管理需求，将本地化的负载和管理融入到原生的 Kubernetes 架构中。这也是目前应用管理的一个趋势，既能吃到云原生和社区 Kubernetes 的红利，又能更好地将多年的技术积累发展演进融入其中，这是一种拥抱云原生的一种绝佳的道路。</li></ul><h3 id="基础”斧”：Above-Kubernetes"><a href="#基础”斧”：Above-Kubernetes" class="headerlink" title="基础”斧”：Above Kubernetes"></a>基础”斧”：Above Kubernetes</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果现在让你选择一个容器管理平台，相信应该没人会错过 Kubernetes。尤其对于没有任何技术负担的用户，选择 Kubernetes 无疑是最明智的一个选择。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Above Kubernetes，这种落地方式很好理解，就是你把原生的、标准的、无任何接触和侵入改动的社区版本的 Kubernetes 拿来，直接部署运行起来即可。完全在 Kubernetes 之上构建自己的应用，通过标准的 Kubernetes API 来访问集群。你可以完全跟着社区升级演进你的 Kubernetes，保持与社区同步，完全借助于社区的力量维护你的 Kubernetes。这种落地方式无疑是最理想的，你不必考虑与社区和业界的主流脱离，同时也降低了管理和运维的成本。<br><img src="https://img.xxlaila.cn/640.webp" alt="img"></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如上图，你可以安装标准的主流的云原生体系来落地 Kubernetes，可以拥抱社区的一整套完整的架构方案，并且足以满足你的需求。</p><h3 id="高阶”斧”：On-Kubernetes"><a href="#高阶”斧”：On-Kubernetes" class="headerlink" title="高阶”斧”：On Kubernetes"></a>高阶”斧”：On Kubernetes</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;能够使用原生的 Kubernetes 集群诚然非常好，但是有些场景并不一定走得通。大家都知道，Kubernetes 的概念和设计其实是很超前的。谷歌的软件开发和应用部署理念虽然好，但业界大部分的企业还是陈旧的技术理念和更复杂的场景。对于一些有技术积淀的企业用户而言，想要一下子抛弃当前的应用管理和部署方式改为原生的 Kubernetes 的应用部署和管理方式，确实有些吃不消。那对于这些用户而言，肯定不能看着别人吃肉自己啃窝窝头。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;On Kubernetes 的落地形态其实是一种妥协和中间过程，一方面很难一下子抛弃已有的基础设施，例如：服务治理、监控、网络拓扑等等。只能在原生的 Kubernetes 基础上做一些本地化改造使得 Kubernetes 能够满足当前的应用管理方式，例如：抛弃 Kube-Proxy 使用扁平化的内网环境、通过富容器的方式包装一些监控和代理组件等等。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这种落地方式一方面能够做少量改动就吃到这波技术红利，一方面可以探索属于自己的云原生的道路。内部技术栈也可以朝着云原生的方向发展演进，不至于在这波潮流中落后太多，而且可以根据自己的场景做定制化的 Kubernetes 开发，甚至比社区的 Kubernetes 走的更远或者解决一些社区没有解决的问题。有得必有失，虽然可以在借助于 Kubernetes 的设计理念和管理能力，但是同时由于本地化的改造不能完全与社区版本的 Kubernetes 兼容。升级就会比较麻烦，每次升级不得不重新打 Patch，还会出现同时维护多个 Kubernetes 版本的窘境。这无疑会给开发和运维带来很多麻烦，所以这也不是一般的小公司能够走得通的道路。需要一定的研发和技术能力，比较典型的是美团点评的 HULK 2.0、京东的 JDOS 2.0 以及阿里巴巴的 Sigma。<br><img src="https://img.xxlaila.cn/641.webp" alt="img"></p><center>美团点评 HULK 2.0</center><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在这种高阶的玩法中，没有标准的套路，只有符合自己的方案。例如：美团点评结合自己已有的设施在 Kubernetes 以上构建了 HULK 2.0 系统，在存储、网络、负载生命周期管理以及应用监控等方面做了本地化改造，但是仍然保持对 Kubernetes API 的完全兼容。你可以根据自有的基础设施，例如存储、监控、链路追踪、服务发布以及网络等等一系列组件融合，甚至根据业务场景和自身需求对 Kubernetes 做深度的定制化，例如：网易云基于 Kubernetes 的深度定制化实践。</p><h3 id="绝杀”斧”：In-Kubernetes"><a href="#绝杀”斧”：In-Kubernetes" class="headerlink" title="绝杀”斧”：In Kubernetes"></a>绝杀”斧”：In Kubernetes</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;云原生这一说法在技术圈已经广为流传，甚至一些同学并不理解什么是云原生，但都知道要朝着云原生的方向发展演进。不管怎样，对于用户而言改变以往虚拟机的部署和管理方式以及服务的治理策略是必要的。不得不说，All in Kubernetes 是一个趋势，CRD 自 Kubernetes 1.7 版本产生到上周发布的 1.16 版本的 GA，也就是说我们完全有了可以在生产环境扩展 Kubernetes 的能力。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;大家如果深入了解 Kubernetes 会发现，Kubernetes 本身就是一个平台。Kubernetes 除了提供了很多的功能，例如：它可以简化应用程序的工作流、加快开发速度、用户可以使用 Label 以自己的方式组织管理资源。还可以使用 Annotation 来自定义资源的描述信息，比如：为管理工具提供状态检查等。此外，Kubernetes 控制器也是构建在跟开发人员和用户使用的相同的 API 之上。用户还可以编写自己的控制器和调度器，也可以通过各种插件机制扩展系统的功能。这就是说，我们完全可以在 Kubernetes 里面通过扩展 API 和负载类型完成任何形式和类型的应用负载和管理方法。即使你有复杂的技术栈不可摆脱或者说有复杂的工作流，没问题，你可以根据自己的需要在资源和应用生命周期注入任何外部依赖和逻辑。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这种落地方式其实是借助于 Kubernetes 提供的扩展机制，完全将本地化、复杂化的逻辑转化为 Kubernetes 的设计和管理理念。不仅仅是使用 Kubernetes，而是融入和弱化原生 Kubernetes，最终每个用户都有着自己的一套独一无二的 Kubernetes。你中有我，我中有你。此外，它仍然完全和原生的 Kubernetes 兼容，可以优雅地升级和合并社区的 Patch 等等。比较有代表性的是阿里开源的 Openkruise 项目。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;用户使用 Kubernetes 核心是对工作负载的管理，其实选择 On Kubernetes 的一个很大原因是用户当前的工作负载管理方式与 Kubernetes 的已有工作负载类型不能很好地匹配。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;CRD 和 Operator 很好地解决了这个问题，让用户可以定制自己的负载。OpenKruise 项目就是这样一个典型的例子， 它是一组控制器，可扩展和补充 Kubernetes 核心控制器的工作负载管理。例如：它提供三种工作负载控制器：</p><ul><li><p>高级 StatefulSet：默认 StatefulSet 的增强版本，具有额外的功能，例如 inplace-update，pasue 和 MaxUnavailable。<br><img src="https://img.xxlaila.cn/642.webp" alt="img"></p></li><li><p>BroadcastJob：在集群中的所有节点上运行 Pod 以完成的作业。<br><img src="https://img.xxlaila.cn/643.webp" alt="img"></p></li><li><p>SidecarSet：一个控制器，它根据选择器将边车容器注入 Pod 规范，并且能够升级边车容器。<br><img src="https://img.xxlaila.cn/644.webp" alt="img"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;理想的情况下，任何负载都可以做到 All in Kubernetes。甚至 Kubernetes 本身的负载管理，即 Kube-on-Kube。以及对于有状态服务的管理，例如：MySQL 集群 Operator 等等，你可以在 operatorhub 找到一些非常经典的例子。<br><img src="https://img.xxlaila.cn/645.webp" alt="img"></p></li></ul><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;虽说不同的落地方式互有差异，但其实都是不同背景下的最好选择，它们都可以做到完全兼容 Kubernetes 的 API，脱离了问题本身，都不能说哪种方式最好。</p><ul><li><p>Above Kubernetes：如果你是一家初创公司，只想使用 Kubernetes 满足正常的容器管理或者服务部署，没有什么负担，同时人力也不足，没有能力自己维护 Kubernetes</p></li><li><p>On Kubernetes：如果你是一家中型甚至大型公司，有着大量的技术积累和设施，并且有能力和人力改造和开发 Kubernetes 或者原生的 Kubernetes 并不能满足你的需求</p></li><li><p>In Kubernetes：你不满足于单纯使用 Kubernetes 或者说原生的 Kubernetes 不能满足你的需求，你可以从 Above Kubernetes 转变而来；当然，如果痛定思痛，或者想彻底地改造当前的基础设施和应用管理方式，想更加靠近云原生的道路或者想要升级陈旧的机器部署和交付模式，你可以从 On Kubernetes 转变而来，最终 All in Kubernetes！</p></li></ul><blockquote><ul><li>来源：知乎</li><li>原文：<a href="https://url.cn/5lyaniK" target="_blank" rel="noopener">https://url.cn/5lyaniK</a></li><li>版权：本文版权归原作者所有</li></ul></blockquote><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Thu Feb 20 2020 16:22:07 GMT+0800 (China Standard Time) --&gt;&lt;h3 id=&quot;Kubernetes-热度&quot;&gt;&lt;a href=&quot;#Kubernetes-热度&quot; class=&quot;headerlink&quot; title=&quot;Kubernetes 热度&quot;&gt;&lt;/a&gt;Kubernetes 热度&lt;/h3&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;国内外对 Kubernetes 这波潮流的追捧，包括各大云厂商：蚂蚁金服、京东、美团、滴滴等各大公司都把 Kubernetes 作为自己的基础设施的重心。
    
    </summary>
    
    
      <category term="kubernetes" scheme="https://www.xxlaila.cn/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>traefik2.0-动态配置</title>
    <link href="https://www.xxlaila.cn/2020/01/13/traefik2-0-%E5%8A%A8%E6%80%81%E9%85%8D%E7%BD%AE/"/>
    <id>https://www.xxlaila.cn/2020/01/13/traefik2-0-动态配置/</id>
    <published>2020-01-13T09:39:36.000Z</published>
    <updated>2020-01-20T03:51:50.649Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Thu Feb 20 2020 16:22:06 GMT+0800 (China Standard Time) --><h3 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;之前在traefik部署的时候做了traefik 2.0 的动态安装和动态配置加载<a id="more"></a>，本次来结合实际的场景进行配置测试，测试主要几个功能: 灰度发布、流量复制、ssl证书加载、tcp配置、中间件。<a href="https://www.xxlaila.cn/2020/01/09/traefik%E7%81%B0%E5%BA%A6%E5%8F%91%E5%B8%83/">yaml配置参考</a>，本次主要是以toml格式进行配置文件的配置加载</p><h4 id="灰度发布"><a href="#灰度发布" class="headerlink" title="灰度发布"></a>灰度发布</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;灰度发布参部分考traefik2.0部署<a href="https://www.xxlaila.cn/2020/01/08/traefik2-0%E9%83%A8%E7%BD%B2/">动态配置加载</a>，最后部分。也可以按照下列写法，效果一致。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat &gt;canary.toml &lt;&lt;EOF</span></span><br><span class="line">[http]</span><br><span class="line">  [http.routers]</span><br><span class="line">    [http.routers.Router-canary]</span><br><span class="line">      namespace = <span class="string">"default"</span></span><br><span class="line">      entryPoints = [<span class="string">"web"</span>]</span><br><span class="line">      service = <span class="string">"nginx-canary"</span></span><br><span class="line">      rule = <span class="string">"Host(`wrr.xxlaila.cn`)"</span></span><br><span class="line"></span><br><span class="line">  [http.services]</span><br><span class="line">    [http.services.nginx-canary]</span><br><span class="line">      [http.services.nginx-canary.weighted]</span><br><span class="line">        [[http.services.nginx-canary.weighted.services]]</span><br><span class="line">          name = <span class="string">"appv1"</span></span><br><span class="line">          weight = 3</span><br><span class="line">        [[http.services.nginx-canary.weighted.services]]</span><br><span class="line">          name = <span class="string">"appv2"</span></span><br><span class="line">          weight = 2</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p><img src="https://img.xxlaila.cn/1579491439096.jpg" alt="img"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这里的name指的是服务的名称，在浏览器打开进行测试，然后观察日志。</p><h4 id="流量复制"><a href="#流量复制" class="headerlink" title="流量复制"></a>流量复制</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;流量复制<a href="https://www.xxlaila.cn/2020/01/09/traefik%E7%81%B0%E5%BA%A6%E5%8F%91%E5%B8%83/">yaml格式参考</a>，在node节点的conf目录下面新建一个mirr.toml文件。</p><ul><li>mirr.toml<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat &gt; mirr.toml&lt;&lt;EOF</span></span><br><span class="line">[http]</span><br><span class="line">  [http.routers]</span><br><span class="line">    [http.routers.Router-nginx]</span><br><span class="line">      namespace = <span class="string">"default"</span></span><br><span class="line">      entryPoints = [<span class="string">"web"</span>]</span><br><span class="line">      service = <span class="string">"nginx-mirr"</span></span><br><span class="line">      rule = <span class="string">"Host(`mirror.xxlaila.cn`)"</span></span><br><span class="line"></span><br><span class="line">  [http.services]</span><br><span class="line">    [http.services.nginx-mirr]</span><br><span class="line">      [http.services.nginx-mirr.mirroring]</span><br><span class="line">        service = <span class="string">"app"</span></span><br><span class="line">        [[http.services.nginx-mirr.mirroring.mirrors]]</span><br><span class="line">          name = <span class="string">"appv1-nginx"</span></span><br><span class="line"></span><br><span class="line">        [[http.services.nginx-mirr.mirroring.mirrors]]</span><br><span class="line">          name = <span class="string">"appv2-nginx"</span></span><br><span class="line">          percent = 50</span><br><span class="line"></span><br><span class="line">    [http.services.appv1-nginx]</span><br><span class="line">      [http.services.appv1-nginx.loadBalancer]</span><br><span class="line">        [[http.services.appv1-nginx.loadBalancer.servers]]</span><br><span class="line">          url = <span class="string">"http://appv1/"</span></span><br><span class="line"></span><br><span class="line">    [http.services.appv2-nginx]</span><br><span class="line">      [http.services.appv2-nginx.loadBalancer]</span><br><span class="line">        [[http.services.appv2-nginx.loadBalancer.servers]]</span><br><span class="line">          url = <span class="string">"http://appv2/"</span></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>url=http://appv1 和 url=http://appv2</code>可以以完成的域名写入<code>http://appv1.default.svc.cluster.local:80/</code>，保存退出以后可以在traefik 的dashboard界面看到，在浏览器输入域名进行访问测试<br><img src="https://img.xxlaila.cn/1579171592771.jpg" alt="img"><br><img src="https://img.xxlaila.cn/1579171717285.jpg" alt="img"><br><img src="https://img.xxlaila.cn/1579171755921.jpg" alt="img"></p><h3 id="ssl证书加载"><a href="#ssl证书加载" class="headerlink" title="ssl证书加载"></a>ssl证书加载</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;新起一个ssl.toml的文件用于证书的加载，吧配置文件进行分开，利于维护和错误时影响范围缩小。拷贝证书到node节点/opt/traefik/certs。</p><h4 id="单证书加载"><a href="#单证书加载" class="headerlink" title="单证书加载"></a>单证书加载</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat &gt;ssl.toml &lt;&lt;EOF</span></span><br><span class="line">[tls]</span><br><span class="line"></span><br><span class="line">  [[tls.certificates]]</span><br><span class="line">    certFile = <span class="string">"/config/certs/xxlaila.cn.crt"</span></span><br><span class="line">    keyFile = <span class="string">"/config/certs/xxlaila.cn.key"</span></span><br><span class="line">    stores = [<span class="string">"default"</span>]</span><br><span class="line"></span><br><span class="line">  [tls.stores]</span><br><span class="line">    [tls.stores.default]</span><br><span class="line">      [tls.stores.default.defaultCertificate]</span><br><span class="line">        certFile = <span class="string">"/config/certs/xxlaila.cn.crt"</span></span><br><span class="line">        keyFile = <span class="string">"/config/certs/xxlaila.cn.key"</span></span><br><span class="line"></span><br><span class="line">  [tls.options]</span><br><span class="line">    [tls.options.default]</span><br><span class="line">      minVersion = <span class="string">"VersionTLS12"</span></span><br><span class="line">    [tls.options.mintls13]</span><br><span class="line">      minVersion = <span class="string">"VersionTLS13"</span></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h4 id="多证书加载"><a href="#多证书加载" class="headerlink" title="多证书加载"></a>多证书加载</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat &gt;ssl.toml &lt;&lt;EOF</span></span><br><span class="line">[tls]</span><br><span class="line"></span><br><span class="line">  [[tls.certificates]]</span><br><span class="line">    certFile = <span class="string">"/config/certs/test.xxlaila.cn.crt"</span></span><br><span class="line">    keyFile = <span class="string">"/config/certs/test.xxlaila.cn.key"</span></span><br><span class="line">    stores = [<span class="string">"default"</span>]</span><br><span class="line">  [[tls.certificates]]</span><br><span class="line">    certFile = <span class="string">"/config/certs/dev.xxlaila.cn.crt"</span></span><br><span class="line">    keyFile = <span class="string">"/config/certs/dev.xxlaila.cn.key"</span></span><br><span class="line">    stores = [<span class="string">"kxldev"</span>]</span><br><span class="line"></span><br><span class="line">  [tls.stores]</span><br><span class="line">    [tls.stores.default]</span><br><span class="line">      [tls.stores.default.defaultCertificate]</span><br><span class="line">        certFile = <span class="string">"/config/certs/test.xxlaila.cn.crt"</span></span><br><span class="line">        keyFile = <span class="string">"/config/certs/test.xxlaila.cn.key"</span></span><br><span class="line">    [tls.stores.kxldev]</span><br><span class="line">      [tls.stores.kxldev.defaultCertificate]</span><br><span class="line">        certFile = <span class="string">"/config/certs/dev.xxlaila.cn.crt"</span></span><br><span class="line">        keyFile = <span class="string">"/config/certs/dev.xxlaila.cn.key"</span></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">  [tls.options]</span><br><span class="line">    [tls.options.default]</span><br><span class="line">      minVersion = <span class="string">"VersionTLS12"</span></span><br><span class="line">    [tls.options.mintls13]</span><br><span class="line">      minVersion = <span class="string">"VersionTLS13"</span></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这里遇到一个问题，自己生成的证书，没办法加载，但是公司购买的证书，可以自动识别，不知道为啥。<a href="https://godoc.org/crypto/tls#pkg-constants" target="_blank" rel="noopener">cipherSuites</a>。</p><h3 id="tcp配置"><a href="#tcp配置" class="headerlink" title="tcp配置"></a>tcp配置</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于tcp 的路由是基于sni，之前参考一些文档，说的是traefik 2.0 版本的sni需要tls证书，但在2.1试用的时候，没有使用证书，而且支持域名。<a href="https://www.xxlaila.cn/2020/01/09/traefik%E7%81%B0%E5%BA%A6%E5%8F%91%E5%B8%83/">参考tcp支持</a>，下面是测试代理redis服务和mongo数据库服务。</p><h4 id="redis-服务"><a href="#redis-服务" class="headerlink" title="redis 服务"></a>redis 服务</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat &gt;redis_tcp.toml &lt;&lt;EOF</span></span><br><span class="line">[tcp]</span><br><span class="line">  [tcp.routers]</span><br><span class="line">    [tcp.routers.redis]</span><br><span class="line">      namespace = <span class="string">"kube-ops"</span></span><br><span class="line">      entryPoints = [<span class="string">"redis"</span>]</span><br><span class="line">      service = <span class="string">"redis"</span></span><br><span class="line">      rule = <span class="string">"HostSNI(`*`)"</span></span><br><span class="line"></span><br><span class="line">  [tcp.services]</span><br><span class="line">    [tcp.services.redis.loadBalancer]</span><br><span class="line">      [[tcp.services.redis.loadBalancer.servers]]</span><br><span class="line">        address = <span class="string">"redis.kube-ops.svc.cluster.local:6379"</span></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h4 id="mongo服务"><a href="#mongo服务" class="headerlink" title="mongo服务"></a>mongo服务</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat &gt;mongo_tcp.toml&lt;&lt;EOF</span></span><br><span class="line">[tcp]</span><br><span class="line">  [tcp.routers]</span><br><span class="line">    [tcp.routers.mongo]</span><br><span class="line">      namespace = <span class="string">"default"</span></span><br><span class="line">      entryPoints = [<span class="string">"mongo"</span>]</span><br><span class="line">      service = <span class="string">"mongo"</span></span><br><span class="line">      rule = <span class="string">"HostSNI(`*`)"</span></span><br><span class="line"></span><br><span class="line">  [tcp.services]</span><br><span class="line">    [tcp.services.mongo.loadBalancer]</span><br><span class="line">      [[tcp.services.mongo.loadBalancer.servers]]</span><br><span class="line">        address = <span class="string">"mongo.default.svc.cluster.local:27017"</span></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>测试效果<br><img src="https://img.xxlaila.cn/1579059828086.jpg" alt="img"><br><img src="https://img.xxlaila.cn/1579059869663.jpg" alt="img"><br><img src="https://img.xxlaila.cn/1578990332568.jpg" alt="img"><br><img src="https://img.xxlaila.cn/1579059922027.jpg" alt="img"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;但是在写toml文件的时候，在<code>HostSNI</code>这里的时候不能使用域名，只能使用*来代替，因为这里需要tls的支持。在<code>address</code>这个参数配置项目的时候可以使用一个完整的域<br>名，该域名是k8s默认的域名，及时服务被重新部署以后，也不会影响地址的链接。只要service保持不变。</p><h3 id="http"><a href="#http" class="headerlink" title="http"></a>http</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;配置一个<code>ll.xxlaila.cn</code>域名代理到后段appv2的服务去。然后配置了一个ip的白名单。强制跳转到https。这里需要用到中间件<code>Middlewares</code>，https强制跳转和ip白名单可以参考下面的中间件。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat &gt;http_nginx.toml&lt;&lt;EOF</span></span><br><span class="line">[http]</span><br><span class="line">  [http.routers]</span><br><span class="line">    [http.routers.app]</span><br><span class="line">      namespace = <span class="string">"default"</span></span><br><span class="line">      entryPoints = [<span class="string">"web"</span>]</span><br><span class="line">      service = <span class="string">"appv2"</span></span><br><span class="line">      rule = <span class="string">"Host(`ll.xxlaila.cn`)"</span></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>service</code>参数可以是服务名称，直接引用服务名也可以进行访问。在servers项的url里面会直接应用appv2服务的域名路径。<br><img src="https://img.xxlaila.cn/1579231822303.jpg" alt="img"></p><h4 id="跳转https和白名单"><a href="#跳转https和白名单" class="headerlink" title="跳转https和白名单"></a>跳转https和白名单</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这里http强制跳转到https，加载白名单，这两种配置是写在<code>Middlewares</code>里面。让其他的来进行加载，<code>Middlewares</code>的写法参考下面章节。而ssl证书文件参考文档上面的ssl章节。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat &gt;http_nginx.toml&lt;&lt;EOF</span></span><br><span class="line">[http]</span><br><span class="line">  [http.routers]</span><br><span class="line">    [http.routers.Router0001]</span><br><span class="line">      namespace = <span class="string">"default"</span></span><br><span class="line">      entryPoints = [<span class="string">"web"</span>, <span class="string">"websecure"</span>]</span><br><span class="line">      service = <span class="string">"appv2-zxc"</span></span><br><span class="line">      rule = <span class="string">"Host(`ll.xxlaila.cn`)"</span></span><br><span class="line">      middlewares = [<span class="string">"test-ipwhitelist"</span>, <span class="string">"test-redirectscheme"</span>]</span><br><span class="line">      priority = 42</span><br><span class="line">      [http.routers.Router0001.tls]</span><br><span class="line"></span><br><span class="line">  [http.services]</span><br><span class="line">    [http.services.appv2-zxc]</span><br><span class="line">      [http.services.appv2-zxc.loadBalancer]</span><br><span class="line">      passHostHeader = <span class="literal">true</span></span><br><span class="line">      [[http.services.appv2-zxc.loadBalancer.servers]]</span><br><span class="line">        url = <span class="string">"http://appv2.default.svc.cluster.local:80"</span></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p><img src="https://img.xxlaila.cn/1579251114979.jpg" alt="img"><br><img src="https://img.xxlaila.cn/1579251505095.jpg" alt="img"><br><img src="https://img.xxlaila.cn/1579251546993.jpg" alt="img"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由于自己生成的证书不能识别加载，故而使用了公司的证书，加载时可以正常的。以下是两个环境的配置文件，里面包含了ip白名单，https跳转，页面打开认证，header的加载。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat &gt;dev_nginx.toml&lt;&lt;EOF</span></span><br><span class="line">[http]</span><br><span class="line">  [http.routers]</span><br><span class="line">    [http.routers.Router0001]</span><br><span class="line">      namespace = <span class="string">"default"</span></span><br><span class="line">      entryPoints = [<span class="string">"web"</span>, <span class="string">"websecure"</span>]</span><br><span class="line">      service = <span class="string">"appv2-zxc"</span></span><br><span class="line">      rule = <span class="string">"Host(`ll.dev.xxlaila`)"</span></span><br><span class="line">      middlewares = [<span class="string">"test-ipwhitelist"</span>, <span class="string">"test-redirectscheme"</span>, <span class="string">"test-auth"</span>, <span class="string">"testHeader"</span>]</span><br><span class="line">      priority = 42</span><br><span class="line">      [http.routers.Router0001.tls]</span><br><span class="line">        options = <span class="string">"default"</span></span><br><span class="line"></span><br><span class="line">  [http.services]</span><br><span class="line">    [http.services.appv2-zxc]</span><br><span class="line">      [http.services.appv2-zxc.loadBalancer]</span><br><span class="line">      passHostHeader = <span class="literal">true</span></span><br><span class="line">      [[http.services.appv2-zxc.loadBalancer.servers]]</span><br><span class="line">        url = <span class="string">"http://appv2.default.svc.cluster.local:80"</span></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat &gt;test_nginx.toml&lt;&lt;EOF</span></span><br><span class="line">[http]</span><br><span class="line">  [http.routers]</span><br><span class="line">    [http.routers.Router00010]</span><br><span class="line">      namespace = <span class="string">"default"</span></span><br><span class="line">      entryPoints = [<span class="string">"web"</span>, <span class="string">"websecure"</span>]</span><br><span class="line">      service = <span class="string">"appv1-zxc"</span></span><br><span class="line">      rule = <span class="string">"Host(`ll.test.xxlaila.cn`)"</span></span><br><span class="line">      middlewares = [<span class="string">"test-ipwhitelist"</span>, <span class="string">"test-redirectscheme"</span>, <span class="string">"test-auth"</span>, <span class="string">"testHeader"</span>]</span><br><span class="line">      priority = 42</span><br><span class="line">      [http.routers.Router00010.tls]</span><br><span class="line">        options = <span class="string">"default"</span></span><br><span class="line"></span><br><span class="line">  [http.services]</span><br><span class="line">    [http.services.appv1-zxc]</span><br><span class="line">      [http.services.appv1-zxc.loadBalancer]</span><br><span class="line">      passHostHeader = <span class="literal">true</span></span><br><span class="line">      [[http.services.appv1-zxc.loadBalancer.servers]]</span><br><span class="line">        url = <span class="string">"http://appv1.default.svc.cluster.local:80"</span></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="中间件"><a href="#中间件" class="headerlink" title="中间件"></a>中间件</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Middlewares针对每一个 router 开启和调整相关特性，Middlewares 是在请求实际转发到服务之前对其进行操作的组件，如果不满足要求的条件，甚至可以决定不转发请求。<br><strong>Traefik附带了一下功能</strong>:</p><ul><li>AddPrefix(给请求添加一个前缀路径)</li><li>BasicAuth</li><li>DigestAuth</li><li>ForwardAuth(委托第三方服务身份验证)</li><li>Buffering</li><li>Chain (定义可重用的Middleware集和)</li><li>CircuitBreaker (断路器，避免调用压垮服务)</li><li>Compress</li><li>Errors(提供自定义的错误页面)</li><li>Headers(头部请求)</li><li>IpWhitelist(白名单)</li><li>MaxConn(限制连接到服务的并发连接数)</li><li>PassTLSClientCert</li><li>RateLimit(在给定时间段内限制对服务的请求数量)</li><li>RedirectRegex</li><li>RedirectScheme</li><li>ReplacePath(在转发到服务之前更新请求路径)</li><li>ReplacePathRegex</li><li>Retry</li><li>StripPrefix</li><li>StripPrefixRegex<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;利用Middlewares来实现前端白名单请求。http强制跳转到https。白名单，页面打开认证，header。<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat &gt;middlewares.toml &lt;&lt;EOF</span></span><br><span class="line">[http.middlewares]</span><br><span class="line">  [http.middlewares.test-ipwhitelist.ipWhiteList]</span><br><span class="line">    sourceRange = [<span class="string">"172.20.20.0/20"</span>, <span class="string">"172.21.21.0/20"</span>, <span class="string">"172.20.16.22"</span>]</span><br><span class="line"></span><br><span class="line">  [http.middlewares.test-redirectscheme.redirectScheme]</span><br><span class="line">    scheme = <span class="string">"https"</span></span><br><span class="line">    permanent = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">  [http.middlewares.test-auth.basicAuth]</span><br><span class="line">    headerField = <span class="string">"X-WebAuth-User"</span></span><br><span class="line">    removeHeader = <span class="literal">true</span></span><br><span class="line">    users = [</span><br><span class="line">      <span class="string">"test:<span class="variable">$apr1</span><span class="variable">$H6uskkkW</span><span class="variable">$IgXLP6ewTrSuBkTrqE8wj</span>/"</span>, </span><br><span class="line">      <span class="string">"test2:<span class="variable">$apr1</span><span class="variable">$d9hr9HBB</span><span class="variable">$4HxwgUir3HP4EsggP</span>/QNo0"</span>,</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">  [http.middlewares.testHeader.headers]</span><br><span class="line">    frameDeny = <span class="literal">true</span></span><br><span class="line">    sslRedirect = <span class="literal">true</span></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></li></ul><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Thu Feb 20 2020 16:22:06 GMT+0800 (China Standard Time) --&gt;&lt;h3 id=&quot;实战&quot;&gt;&lt;a href=&quot;#实战&quot; class=&quot;headerlink&quot; title=&quot;实战&quot;&gt;&lt;/a&gt;实战&lt;/h3&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;之前在traefik部署的时候做了traefik 2.0 的动态安装和动态配置加载
    
    </summary>
    
      <category term="Ingress" scheme="https://www.xxlaila.cn/categories/Ingress/"/>
    
    
      <category term="traefik" scheme="https://www.xxlaila.cn/tags/traefik/"/>
    
  </entry>
  
  <entry>
    <title>traefik 2.0 灰度发布</title>
    <link href="https://www.xxlaila.cn/2020/01/09/traefik%E7%81%B0%E5%BA%A6%E5%8F%91%E5%B8%83/"/>
    <id>https://www.xxlaila.cn/2020/01/09/traefik灰度发布/</id>
    <published>2020-01-09T08:52:01.000Z</published>
    <updated>2020-01-19T01:16:12.020Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Thu Feb 20 2020 16:22:06 GMT+0800 (China Standard Time) --><h3 id="灰度发布"><a href="#灰度发布" class="headerlink" title="灰度发布"></a>灰度发布</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Traefik2.0 的一个更强大的功能就是灰度发布，灰度发布我们有时候也会称为金丝雀发布（Canary），主要就是让一部分测试的服务也参与到线上去，经过测试观察看是否符号上线要求。<a id="more"></a></p><h3 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这里部署两个nginx服务，通过 Traefik 来控制流量，将3/5的流量到v1 版本，2/5的流量到v2版本。需要利用Traefik2.0中提供的带权重的轮询(WRR)来实现该功能。</p><h4 id="nginx资源部署"><a href="#nginx资源部署" class="headerlink" title="nginx资源部署"></a>nginx资源部署</h4><ul><li><p>nginx-appv1.yaml</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat &gt;nginx-appv1.yaml &lt;&lt;EOF</span></span><br><span class="line">---</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: appv1</span><br><span class="line">  namespace: default</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: appv1</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        use: <span class="built_in">test</span></span><br><span class="line">        app: appv1</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: nginx</span><br><span class="line">        image: nginx</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        lifecycle:</span><br><span class="line">          postStart:</span><br><span class="line">            <span class="built_in">exec</span>:</span><br><span class="line">              <span class="built_in">command</span>:  [<span class="string">"/bin/sh"</span>, <span class="string">"-c"</span>, <span class="string">"echo Hello v1 &gt; /usr/share/nginx/html/index.html"</span>]</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br><span class="line">          name: portv1</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: appv1</span><br><span class="line">  namespace: default</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    app: appv1</span><br><span class="line">  ports:</span><br><span class="line">  - name: http</span><br><span class="line">    port: 80</span><br><span class="line">    targetPort: portv1</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></li><li><p>nginx-appv2.yaml</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat &gt; nginx-appv2.yaml &lt;&lt;EOF</span></span><br><span class="line">---</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: appv2</span><br><span class="line">  namespace: default</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: appv2</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        use: <span class="built_in">test</span></span><br><span class="line">        app: appv2</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: nginx</span><br><span class="line">        image: nginx</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        lifecycle:</span><br><span class="line">          postStart:</span><br><span class="line">            <span class="built_in">exec</span>:</span><br><span class="line">              <span class="built_in">command</span>:  [<span class="string">"/bin/sh"</span>, <span class="string">"-c"</span>, <span class="string">"echo Hello v2 &gt; /usr/share/nginx/html/index.html"</span>]</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br><span class="line">          name: portv2</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: appv2</span><br><span class="line">  namespace: default</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    app: appv2</span><br><span class="line">  ports:</span><br><span class="line">  - name: http</span><br><span class="line">    port: 80</span><br><span class="line">    targetPort: portv2</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></li></ul><h4 id="执行创建"><a href="#执行创建" class="headerlink" title="执行创建"></a>执行创建</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl apply -f ./</span></span><br><span class="line"><span class="comment"># kubectl get pods -l use=test</span></span><br><span class="line">NAME                     READY   STATUS    RESTARTS   AGE</span><br><span class="line">appv1-6f88c7b898-qx2pc   2/2     Running   0          23h</span><br><span class="line">appv2-558fdbbdb7-6gd8l   2/2     Running   0          23h</span><br></pre></td></tr></table></figure><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;前面在安装traefik的时候在crd里面定义了一个TraefikService的crd资源，直接利用这个对象来配置 WRR。</p><h4 id="新建资源清单"><a href="#新建资源清单" class="headerlink" title="新建资源清单"></a>新建资源清单</h4><ul><li><p>nginx-wrr.yaml</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat &gt;nginx-wrr.yaml&lt;&lt;EOF</span></span><br><span class="line">---</span><br><span class="line">apiVersion: traefik.containo.us/v1alpha1</span><br><span class="line">kind: TraefikService</span><br><span class="line">metadata:</span><br><span class="line">  name: app-wrr</span><br><span class="line">spec:</span><br><span class="line">  weighted:</span><br><span class="line">    services:</span><br><span class="line">      - name: appv1</span><br><span class="line">        weight: 3</span><br><span class="line">        port: 80</span><br><span class="line">        kind: Service</span><br><span class="line">      - name: appv2</span><br><span class="line">        weight: 2</span><br><span class="line">        port: 80</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></li><li><p>nginx-ingressroute.yaml<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;为灰度发布的服务创建一个 IngressRoute 资源对象。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat &gt;nginx-ingressroute.yaml&lt;&lt;EOF</span></span><br><span class="line">apiVersion: traefik.containo.us/v1alpha1</span><br><span class="line">kind: IngressRoute</span><br><span class="line">metadata:</span><br><span class="line">  name: wrringressroute</span><br><span class="line">  namespace: default</span><br><span class="line">spec:</span><br><span class="line">  entryPoints:</span><br><span class="line">    - web</span><br><span class="line">  routes:</span><br><span class="line">  - match: Host(`nginx.xxlaila.cn`)</span><br><span class="line">    kind: Rule</span><br><span class="line">    services:</span><br><span class="line">    - name: app-wrr</span><br><span class="line">      kind: TraefikService</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></li></ul><p><strong>注</strong>:</p><ul><li>weight: 3: 定义权重</li><li>kind: Service: 可选，默认就是 Service</li></ul><ul><li>执行创建<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl apply -f nginx-wrr.yam</span></span><br><span class="line"><span class="comment"># kubectl apply -f nginx-ingressroute.yaml</span></span><br></pre></td></tr></table></figure></li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在浏览器访问<code>nginx.xxlaila.cn</code>，这里联系访问了5次，有三次请求到appv1，两次请求到appv2。符合3:2权重配置。</p><figure class="highlight vala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># kubectl logs -f appv1-6f88c7b898-qx2pc nginx</span></span><br></pre></td></tr></table></figure><p><img src="https://img.xxlaila.cn/1578562105802.jpg" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl logs -f appv2-558fdbbdb7-6gd8l nginx</span></span><br></pre></td></tr></table></figure><p><img src="https://img.xxlaila.cn/1578562349387.jpg" alt="img"></p><h3 id="流量复制"><a href="#流量复制" class="headerlink" title="流量复制"></a>流量复制</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Traefik 2.0 还引入了流量镜像服务，是一种可以将流入流量复制并同时将其发送给其他服务的方法，镜像服务可以获得给定百分比的请求同时也会忽略这部分请求的响应。在traefik 2.0 中只能通过 FileProvider 进行配置，在 2.1 版本中可以通过 TraefikService 资源对象来进行配置。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;修改前面的nginx-appv2.yaml 为v1版本。创建一个 IngressRoute 对象，将服务v1的流量复制50%到服务v2。</p><ul><li>mirror-ingress-route.yaml<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat &gt; mirror-ingress-route.yaml&lt;&lt;EOF</span></span><br><span class="line">apiVersion: traefik.containo.us/v1alpha1</span><br><span class="line">kind: TraefikService</span><br><span class="line">metadata:</span><br><span class="line">  name: app-mirror</span><br><span class="line">spec:</span><br><span class="line">  mirroring:</span><br><span class="line">    name: appv1</span><br><span class="line">    port: 80</span><br><span class="line">    mirrors:</span><br><span class="line">    - name: appv2</span><br><span class="line">      percent: 50</span><br><span class="line">      port: 80</span><br><span class="line">---</span><br><span class="line">apiVersion: traefik.containo.us/v1alpha1</span><br><span class="line">kind: IngressRoute</span><br><span class="line">metadata:</span><br><span class="line">  name: mirror-ingress-route</span><br><span class="line">  namespace: default</span><br><span class="line">spec:</span><br><span class="line">  entryPoints:</span><br><span class="line">  - web</span><br><span class="line">  routes:   </span><br><span class="line">  - match: Host(`mirror.xxlaila.cn`)</span><br><span class="line">    kind: Rule</span><br><span class="line">    services:</span><br><span class="line">    - name: app-mirror</span><br><span class="line">      kind: TraefikService</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="comment"># kubectl apply -f mirror-ingress-route.yaml</span></span><br><span class="line">ingressroute.traefik.containo.us/mirror-ingress-route created</span><br><span class="line">traefikservice.traefik.containo.us/mirroring-example created</span><br></pre></td></tr></table></figure></li></ul><p><strong>注</strong>:</p><ul><li>mirroring.appv1: 发送 100% 的请求到 K8S 的 Service “v1”</li><li>mirrors.appv2: 然后复制 50% 的请求到 v2</li><li>kind: TraefikService: 使用声明的 TraefikService 服务，而不是 K8S 的 Service</li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在浏览器进行测试访问<code>mirror.xxlaila.cn</code>，进行6次访问，会有一半的请求会路由到appv2上来</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl logs -f appv1-6f88c7b898-qx2pc nginx</span></span><br></pre></td></tr></table></figure><p><img src="https://img.xxlaila.cn/1578563771830.jpg" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl logs -f appv2-558fdbbdb7-6gd8l nginx</span></span><br></pre></td></tr></table></figure><p><img src="https://img.xxlaila.cn/1578563835542.jpg" alt="img"></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在安装traefik的时候引用了tracing.zipkin，当在浏览器访问的时候，可以在tracing的界面观察请求的路径<br><img src="https://img.xxlaila.cn/1578620392679.jpg" alt="img"></p><h3 id="TCP"><a href="#TCP" class="headerlink" title="TCP"></a>TCP</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Traefik2.0 已经支持了TCP服务的，这里以redis、mongodb为例来测试Traefik是如何支持TCP服务。</p><h4 id="redis-服务"><a href="#redis-服务" class="headerlink" title="redis 服务"></a>redis 服务</h4><ul><li>redis.yaml<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat &gt; redis.yaml&lt;&lt;EOF</span></span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: redis</span><br><span class="line">spec:</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: redis</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: redis</span><br><span class="line">        image: redis:4</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 6379</span><br><span class="line">          protocol: TCP</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: redis</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - port: 6379</span><br><span class="line">    targetPort: 6379</span><br><span class="line">  selector:</span><br><span class="line">    app: redis</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="comment"># kubectl apply -f redis.yaml</span></span><br></pre></td></tr></table></figure></li></ul><h5 id="部署mongo服务"><a href="#部署mongo服务" class="headerlink" title="部署mongo服务"></a>部署mongo服务</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat &gt;mongo.yaml &lt;&lt;EOF</span></span><br><span class="line">---</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: mongo</span><br><span class="line">  labels:</span><br><span class="line">    app: mongo</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: mongo</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: mongo</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: mongo</span><br><span class="line">        image: mongo:4.0</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 27017</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: mongo</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    app: mongo</span><br><span class="line">  ports:</span><br><span class="line">  - port: 27017</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="comment"># kubectl apply -f mongo.yaml</span></span><br></pre></td></tr></table></figure><h4 id="暴露-TCP-服务"><a href="#暴露-TCP-服务" class="headerlink" title="暴露 TCP 服务"></a>暴露 TCP 服务</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由于 Traefik 中使用 TCP 路由配置需要 SNI，而 SNI 又是依赖 TLS 的，所以我们需要配置证书才行，但是如果没有证书的话，我们可以使用通配符 * 进行配置，我们这里创建一个 IngressRouteTCP 类型的 CRD 对象。在之前安装的时候crd文件里面已经加入了对应的crd资源。我在使用traefik 2.1版本的时候写入域名是可以成功的。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat redis-ingressroute-tcp.yaml </span></span><br><span class="line">apiVersion: traefik.containo.us/v1alpha1</span><br><span class="line">kind: IngressRouteTCP</span><br><span class="line">metadata:</span><br><span class="line">  name: redis-traefik-tcp</span><br><span class="line">  namespace: kube-ops</span><br><span class="line">spec:</span><br><span class="line">  entryPoints:</span><br><span class="line">    - redis</span><br><span class="line">  routes:</span><br><span class="line">  - match: HostSNI(`redis.ops.xxlaila.cn`)</span><br><span class="line">    services:</span><br><span class="line">    - name: redis</span><br><span class="line">      port: 6379</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="comment"># kubectl apply -f redis-ingressroute-tcp.yaml</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat &gt;mongo-ingressroute-tcp.yaml &lt;&lt;EOF</span></span><br><span class="line">apiVersion: traefik.containo.us/v1alpha1</span><br><span class="line">kind: IngressRouteTCP</span><br><span class="line">metadata:</span><br><span class="line">  name: mongo-traefik-tcp</span><br><span class="line">  namespace: default</span><br><span class="line">spec:</span><br><span class="line">  entryPoints:</span><br><span class="line">    - mongo</span><br><span class="line">  routes:</span><br><span class="line">  - match: HostSNI(`mongo.ops.xxlaila.cn`)</span><br><span class="line">    services:</span><br><span class="line">    - name: mongo</span><br><span class="line">      port: 27017</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="comment"># kubectl apply -f &gt;mongo-ingressroute-tcp.yaml</span></span><br></pre></td></tr></table></figure><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;要注意的是这里的entryPoints部分，是根据我们启动的 Traefik 的静态配置中的 entryPoints 来决定的，比如我们可以自己添加一个用于 Redis 的专门的入口点，在安装的时候已经添加。</p><p><img src="https://img.xxlaila.cn/1578564549279.jpg" alt="img"><br><img src="https://img.xxlaila.cn/1578564836153.jpg" alt="img"><br><img src="https://img.xxlaila.cn/1579059922027.jpg" alt="img"></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Thu Feb 20 2020 16:22:06 GMT+0800 (China Standard Time) --&gt;&lt;h3 id=&quot;灰度发布&quot;&gt;&lt;a href=&quot;#灰度发布&quot; class=&quot;headerlink&quot; title=&quot;灰度发布&quot;&gt;&lt;/a&gt;灰度发布&lt;/h3&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Traefik2.0 的一个更强大的功能就是灰度发布，灰度发布我们有时候也会称为金丝雀发布（Canary），主要就是让一部分测试的服务也参与到线上去，经过测试观察看是否符号上线要求。
    
    </summary>
    
      <category term="Ingress" scheme="https://www.xxlaila.cn/categories/Ingress/"/>
    
    
      <category term="traefik" scheme="https://www.xxlaila.cn/tags/traefik/"/>
    
  </entry>
  
  <entry>
    <title>traefik 2.0部署</title>
    <link href="https://www.xxlaila.cn/2020/01/08/traefik2-0%E9%83%A8%E7%BD%B2/"/>
    <id>https://www.xxlaila.cn/2020/01/08/traefik2-0部署/</id>
    <published>2020-01-08T09:52:01.000Z</published>
    <updated>2020-01-17T04:00:38.629Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Thu Feb 20 2020 16:22:06 GMT+0800 (China Standard Time) --><h3 id="认识"><a href="#认识" class="headerlink" title="认识"></a>认识</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Traefik2.0 中的配置可以使用两种不同的方式</p><ul><li>动态配置：完全动态的路由配置</li><li>静态配置：启动配置<a id="more"></a></li></ul><h4 id="静态配置"><a href="#静态配置" class="headerlink" title="静态配置"></a>静态配置</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;连接到 providers 并定义 Treafik 将要监听的 entrypoints。在 Traefik 中有三种方式定义静态配置：在配置文件中、在命令行参数中、通过环境变量传递。</p><h4 id="动态配置"><a href="#动态配置" class="headerlink" title="动态配置"></a>动态配置</h4><h4 id="静态配置-1"><a href="#静态配置-1" class="headerlink" title="静态配置"></a>静态配置</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;包含定义系统如何处理请求的所有配置内容，这些配置是可以改变的，而且是无缝热更新的，没有任何请求中断或连接损耗。</p><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;配置KubernetesCRD和部署/公开服务</p><h4 id="安装文件准备"><a href="#安装文件准备" class="headerlink" title="安装文件准备"></a>安装文件准备</h4><ul><li><p>crd.yaml</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat &gt; crd.yaml &lt;&lt;EOF</span></span><br><span class="line">apiVersion: apiextensions.k8s.io/v1beta1</span><br><span class="line">kind: CustomResourceDefinition</span><br><span class="line">metadata:</span><br><span class="line">  name: ingressroutes.traefik.containo.us</span><br><span class="line"></span><br><span class="line">spec:</span><br><span class="line">  group: traefik.containo.us</span><br><span class="line">  version: v1alpha1</span><br><span class="line">  names:</span><br><span class="line">    kind: IngressRoute</span><br><span class="line">    plural: ingressroutes</span><br><span class="line">    singular: ingressroute</span><br><span class="line">  scope: Namespaced</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: apiextensions.k8s.io/v1beta1</span><br><span class="line">kind: CustomResourceDefinition</span><br><span class="line">metadata:</span><br><span class="line">  name: middlewares.traefik.containo.us</span><br><span class="line"></span><br><span class="line">spec:</span><br><span class="line">  group: traefik.containo.us</span><br><span class="line">  version: v1alpha1</span><br><span class="line">  names:</span><br><span class="line">    kind: Middleware</span><br><span class="line">    plural: middlewares</span><br><span class="line">    singular: middleware</span><br><span class="line">  scope: Namespaced</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: apiextensions.k8s.io/v1beta1</span><br><span class="line">kind: CustomResourceDefinition</span><br><span class="line">metadata:</span><br><span class="line">  name: ingressroutetcps.traefik.containo.us</span><br><span class="line"></span><br><span class="line">spec:</span><br><span class="line">  group: traefik.containo.us</span><br><span class="line">  version: v1alpha1</span><br><span class="line">  names:</span><br><span class="line">    kind: IngressRouteTCP</span><br><span class="line">    plural: ingressroutetcps</span><br><span class="line">    singular: ingressroutetcp</span><br><span class="line">  scope: Namespaced</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: apiextensions.k8s.io/v1beta1</span><br><span class="line">kind: CustomResourceDefinition</span><br><span class="line">metadata:</span><br><span class="line">  name: tlsoptions.traefik.containo.us</span><br><span class="line"></span><br><span class="line">spec:</span><br><span class="line">  group: traefik.containo.us</span><br><span class="line">  version: v1alpha1</span><br><span class="line">  names:</span><br><span class="line">    kind: TLSOption</span><br><span class="line">    plural: tlsoptions</span><br><span class="line">    singular: tlsoption</span><br><span class="line">  scope: Namespaced</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: apiextensions.k8s.io/v1beta1</span><br><span class="line">kind: CustomResourceDefinition</span><br><span class="line">metadata:</span><br><span class="line">  name: traefikservices.traefik.containo.us</span><br><span class="line"></span><br><span class="line">spec:</span><br><span class="line">  group: traefik.containo.us</span><br><span class="line">  version: v1alpha1</span><br><span class="line">  names:</span><br><span class="line">    kind: TraefikService</span><br><span class="line">    plural: traefikservices</span><br><span class="line">    singular: traefikservice</span><br><span class="line">  scope: Namespaced</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></li><li><p>rbac.yaml</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat &gt; rbac.yaml &lt;&lt;EOF</span></span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: traefik-ingress-controller</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">kind: ClusterRole</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  name: traefik-ingress-controller</span><br><span class="line"></span><br><span class="line">rules:</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - <span class="string">""</span></span><br><span class="line">    resources:</span><br><span class="line">      - services</span><br><span class="line">      - endpoints</span><br><span class="line">      - secrets</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - extensions</span><br><span class="line">    resources:</span><br><span class="line">      - ingresses</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - extensions</span><br><span class="line">    resources:</span><br><span class="line">      - ingresses/status</span><br><span class="line">    verbs:</span><br><span class="line">      - update</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - traefik.containo.us</span><br><span class="line">    resources:</span><br><span class="line">      - middlewares</span><br><span class="line">      - ingressroutes</span><br><span class="line">      - traefikservices</span><br><span class="line">      - ingressroutetcps</span><br><span class="line">      - tlsoptions</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  name: traefik-ingress-controller</span><br><span class="line"></span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: traefik-ingress-controller</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: traefik-ingress-controller</span><br><span class="line">    namespace: kube-system</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></li><li><p>traefik.yaml</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat &gt;traefik.yaml &lt;&lt;EOF</span></span><br><span class="line">---</span><br><span class="line">kind: Deployment</span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  name: traefik</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: traefik-ingress-lb</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: traefik-ingress-lb</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: traefik-ingress-lb</span><br><span class="line">        name: traefik-ingress-lb</span><br><span class="line">    spec:</span><br><span class="line">      serviceAccountName: traefik-ingress-controller</span><br><span class="line">      dnsPolicy: ClusterFirstWithHostNet</span><br><span class="line">      hostNetwork: <span class="literal">true</span></span><br><span class="line">      containers:</span><br><span class="line">      - image: traefik:v2.1.1</span><br><span class="line">        name: traefik-ingress-lb</span><br><span class="line">        ports:</span><br><span class="line">        - name: web</span><br><span class="line">          containerPort: 80</span><br><span class="line">          hostPort: 80</span><br><span class="line">        - name: websecure</span><br><span class="line">          containerPort: 443</span><br><span class="line">          hostPort: 443</span><br><span class="line">        - name: admin</span><br><span class="line">          containerPort: 8080</span><br><span class="line">        - name: mongo</span><br><span class="line">          hostPort: 27017</span><br><span class="line">          containerPort: 27017</span><br><span class="line">        - name: redis</span><br><span class="line">          containerPort: 6379</span><br><span class="line">          hostPort: 6379</span><br><span class="line">        args:</span><br><span class="line">        - --entrypoints.web.Address=:80</span><br><span class="line">        - --entrypoints.websecure.Address=:443</span><br><span class="line">        - --entryPoints.mongo.address=:27017</span><br><span class="line">        - --entrypoints.redis.Address=:6379</span><br><span class="line">        - --api.insecure=<span class="literal">true</span></span><br><span class="line">        - --providers.kubernetescrd</span><br><span class="line">        - --api</span><br><span class="line">        - --api.dashboard=<span class="literal">true</span></span><br><span class="line">        - --providers.kubernetesingress</span><br><span class="line">        - --accesslog</span><br><span class="line">        - --metrics</span><br><span class="line">        - --metrics.datadog=<span class="literal">true</span></span><br><span class="line">        - --metrics.prometheus=<span class="literal">true</span></span><br><span class="line">        - --tracing</span><br><span class="line">        - --tracing.zipkin=<span class="literal">true</span></span><br><span class="line">        </span><br><span class="line">      nodeSelector:</span><br><span class="line">        IngressProxy: <span class="string">"true"</span></span><br><span class="line">      tolerations:</span><br><span class="line">      - effect: NoSchedule</span><br><span class="line">        key: node-role.kubernetes.io/ingress</span><br><span class="line">        operator: Equal</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">kind: Service</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: traefik</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  <span class="built_in">type</span>: ClusterIP</span><br><span class="line">  selector:</span><br><span class="line">    app: traefik-ingress-lb</span><br><span class="line">  ports:</span><br><span class="line">    - protocol: TCP</span><br><span class="line">      port: 80</span><br><span class="line">      name: web</span><br><span class="line">      targetPort: 80</span><br><span class="line">    - protocol: TCP</span><br><span class="line">      port: 8080</span><br><span class="line">      name: admin</span><br><span class="line">      targetPort: 8080</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></li></ul><p><strong>注</strong>:</p><ul><li>args: 都是静态参数<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>--providers.kubernetesingress</code>这个参数可以开启，如果之前安装过traefik，也建立了一些traefik的ingress。就会自动的导入添加进来，这比较方便和实用。</li></ul><ul><li>Ingressroute.yaml<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat &gt;Ingressroute.yaml&lt;&lt;EOF</span></span><br><span class="line">apiVersion: traefik.containo.us/v1alpha1</span><br><span class="line">kind: IngressRoute</span><br><span class="line">metadata:</span><br><span class="line">  name: traefik-webui</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  entryPoints:</span><br><span class="line">    - web</span><br><span class="line">  routes:</span><br><span class="line">  - match: Host(`traefik.xxlaila.cn`)</span><br><span class="line">    kind: Rule</span><br><span class="line">    services:</span><br><span class="line">    - name: traefik</span><br><span class="line">      port: 8080</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></li></ul><p>上述文件可以参考<a href="https://docs.traefik.io/routing/providers/kubernetes-crd/" target="_blank" rel="noopener">traefik官方</a>，可以直接拿来使用，根据自己的需求来进行修改。插件部分<a href="https://docs.traefik.io/observability/metrics/overview/" target="_blank" rel="noopener">参考</a>官方，也可以<a href="https://docs.traefik.io/user-guides/crd-acme/" target="_blank" rel="noopener">参考实列</a></p><h4 id="执行创建"><a href="#执行创建" class="headerlink" title="执行创建"></a>执行创建</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl apply -f ./</span></span><br></pre></td></tr></table></figure><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在浏览器访问traefik.xxlaila.cn即可<br><img src="https://img.xxlaila.cn/1578558695609.jpg" alt="img"></p><h3 id="traefik-动态配置"><a href="#traefik-动态配置" class="headerlink" title="traefik 动态配置"></a>traefik 动态配置</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在很多时候，某一个应用程序突然发生改变，这就会产生配置文件的改动，按照之前的部署方式来进行使用traefik，每一次的都需要进行重新部署，这对于生成环境或者在正式使用的过程中是不允许的，还好traefik提供了动态配置，动态配置可以支持一个目录，也可以支持一个文件。似乎动态加载目录下面的配置文件更加的舒适，部分配置文件分开，有利于维护和影响小范围。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;动态配置文件生成过多，在某些时候变动过大，traefik重载配置可能会压力比较大。还好traefik有一个参数配置<code>providers.providersThrottleDuration</code>，该参数配置是Traefik在重新加载配置之后等待的持续时间，然后才考虑任何新的配置刷新事件。如果在此持续时间内有任何事件到达，则仅考虑最近的事件，所有先前的事件都将被丢弃。traefik默认时间是2s。</p><h4 id="部署traefik动态配置"><a href="#部署traefik动态配置" class="headerlink" title="部署traefik动态配置"></a>部署traefik动态配置</h4><h5 id="traefik-yaml"><a href="#traefik-yaml" class="headerlink" title="traefik.yaml"></a>traefik.yaml</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat &gt; traefik.yaml&lt;&lt;EOF</span></span><br><span class="line">---</span><br><span class="line">kind: Deployment</span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  name: traefik</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: traefik-ingress-lb</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: traefik-ingress-lb</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: traefik-ingress-lb</span><br><span class="line">        name: traefik-ingress-lb</span><br><span class="line">    spec:</span><br><span class="line">      serviceAccountName: traefik-ingress-controller</span><br><span class="line">      dnsPolicy: ClusterFirstWithHostNet</span><br><span class="line">      hostNetwork: <span class="literal">true</span></span><br><span class="line">      volumes:</span><br><span class="line">      - name: config</span><br><span class="line">        hostPath:</span><br><span class="line">          path: /opt/traefix</span><br><span class="line">          <span class="built_in">type</span>: Directory</span><br><span class="line">      containers:</span><br><span class="line">      - image: traefik:v2.1.1</span><br><span class="line">        name: traefik-ingress-lb</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: config</span><br><span class="line">          mountPath: /config</span><br><span class="line">        ports:</span><br><span class="line">        - name: web</span><br><span class="line">          containerPort: 80</span><br><span class="line">          hostPort: 80</span><br><span class="line">        - name: websecure</span><br><span class="line">          containerPort: 443</span><br><span class="line">          hostPort: 443</span><br><span class="line">        - name: admin</span><br><span class="line">          containerPort: 8080</span><br><span class="line">        args:</span><br><span class="line">        - --configfile=/config/dy_traefik.yaml</span><br><span class="line">        </span><br><span class="line">      nodeSelector:</span><br><span class="line">        IngressProxy: <span class="string">"true"</span></span><br><span class="line">      tolerations:</span><br><span class="line">      - effect: NoSchedule</span><br><span class="line">        key: node-role.kubernetes.io/ingress</span><br><span class="line">        operator: Equal</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">kind: Service</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: traefik</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  <span class="built_in">type</span>: ClusterIP</span><br><span class="line">  selector:</span><br><span class="line">    app: traefik-ingress-lb</span><br><span class="line">  ports:</span><br><span class="line">    - protocol: TCP</span><br><span class="line">      port: 80</span><br><span class="line">      name: web</span><br><span class="line">      targetPort: 80</span><br><span class="line">    - protocol: TCP</span><br><span class="line">      port: 8080</span><br><span class="line">      name: admin</span><br><span class="line">      targetPort: 8080</span><br><span class="line"></span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="comment"># kubectl apply -f traefik.yaml</span></span><br></pre></td></tr></table></figure><h4 id="dashboard部署"><a href="#dashboard部署" class="headerlink" title="dashboard部署"></a>dashboard部署</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat &gt;dashboard.yaml&lt;&lt;EOF</span></span><br><span class="line">apiVersion: traefik.containo.us/v1alpha1</span><br><span class="line">kind: IngressRoute</span><br><span class="line">metadata:</span><br><span class="line">  name: traefik-dashboard</span><br><span class="line">spec:</span><br><span class="line">  routes:</span><br><span class="line">  - match: Host(`traefik.xxlaila.cn`)</span><br><span class="line">    kind: Rule</span><br><span class="line">    services:</span><br><span class="line">    - name: api@internal</span><br><span class="line">      kind: TraefikService</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="comment"># kubectl apply -f dashboard.yaml</span></span><br></pre></td></tr></table></figure><h4 id="创建基础配置文件"><a href="#创建基础配置文件" class="headerlink" title="创建基础配置文件"></a>创建基础配置文件</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat &gt;dy_traefik.yaml&lt;&lt;EOF</span></span><br><span class="line">---</span><br><span class="line">serversTransport:</span><br><span class="line">  insecureSkipVerify: <span class="literal">true</span></span><br><span class="line">api:</span><br><span class="line">  dashboard: <span class="literal">true</span></span><br><span class="line">  insecure: <span class="literal">true</span></span><br><span class="line"><span class="built_in">log</span>:</span><br><span class="line">  filePath: <span class="string">"/config/logs/traefik.log"</span></span><br><span class="line">  format: <span class="string">"json"</span></span><br><span class="line">  level: <span class="string">"INFO"</span></span><br><span class="line">accessLog:</span><br><span class="line">  filePath: <span class="string">"/config/logs/access.log"</span></span><br><span class="line">  bufferingSize: 100</span><br><span class="line">  format: json</span><br><span class="line">providers:</span><br><span class="line">  kubernetesCRD: <span class="string">""</span></span><br><span class="line">  kubernetesIngress: <span class="string">""</span></span><br><span class="line">  providersThrottleDuration: 10s</span><br><span class="line">  file:</span><br><span class="line">    directory: /config/conf</span><br><span class="line">    watch: <span class="literal">true</span></span><br><span class="line">entryPoints:</span><br><span class="line">  web:</span><br><span class="line">    address: <span class="string">":80"</span></span><br><span class="line">  websecure:</span><br><span class="line">    address: <span class="string">":443"</span></span><br><span class="line">  redis:</span><br><span class="line">    address: <span class="string">":6379"</span></span><br><span class="line">  mysql:</span><br><span class="line">    address: <span class="string">":3306"</span></span><br><span class="line">  mongo:</span><br><span class="line">    address: <span class="string">":27017"</span></span><br><span class="line">  es:</span><br><span class="line">    address: <span class="string">":9200"</span></span><br><span class="line">metrics:</span><br><span class="line">  datadog:</span><br><span class="line">    address: 127.0.0.1:8125</span><br><span class="line">    addEntryPointsLabels: <span class="literal">true</span></span><br><span class="line">  prometheus:</span><br><span class="line">    buckets:</span><br><span class="line">      - 0.1</span><br><span class="line">      - 0.3</span><br><span class="line">      - 1.2</span><br><span class="line">      - 5.0</span><br><span class="line">tracing:</span><br><span class="line">  zipkin:</span><br><span class="line">    httpEndpoint: http://10.254.153.94:9411/api/v2/spans</span><br><span class="line">    sameSpan: <span class="literal">true</span></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dy_teaefik.yaml 配置文件是放在 traefik对应node节点，目录建立对应的/opt/traefik/{conf,logs,certs}。需要进行动态更新的文件放在conf目录下面。dy_traefik.yaml文件放在node的/opt/traefik目录下面。<br><strong>注</strong>:</p><ul><li>args: 都是静态参数</li><li>–configfile: 是指定traefik启动时候加载的配置文件</li><li>–providers.file.filename参数: 指定配置文件开启 File Provider</li><li>–providers.file.watch=true 参数: 让 Traefik 动态更新配置<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>--providers.kubernetesingress</code>这个参数可以开启，如果之前安装过traefik，也建立了一些traefik的ingress。就会自动的导入添加进来，这比较方便和实用。</li></ul><h4 id="执行创建-1"><a href="#执行创建-1" class="headerlink" title="执行创建"></a>执行创建</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl apply -f traefik.yaml</span></span><br></pre></td></tr></table></figure><h4 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在conf下面建立一个rule.toml文件。配置一个灰度发布的规则，创建一个名为 Router0 的路由。在 web 这个入口点上面监听 Host=nginx.xxlaila.cn，将请求路由给名为 app 的服务。服务将请求路由给了 appv1 这个服务，权重为3，其他请求路由给了 appv2 服务，权重为2，创建nginx服务可以参考<a href="https://www.xxlaila.cn/2020/01/09/traefik%E7%81%B0%E5%BA%A6%E5%8F%91%E5%B8%83/">nginx资源部署</a></p><ul><li>rule.toml<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat &gt;rule.toml&lt;&lt;EOF</span></span><br><span class="line">[http]</span><br><span class="line">  [http.routers]</span><br><span class="line">    [http.routers.Router0]</span><br><span class="line">      namespace = <span class="string">"default"</span></span><br><span class="line">      entryPoints = [<span class="string">"web"</span>]</span><br><span class="line">      service = <span class="string">"app"</span></span><br><span class="line">      rule = <span class="string">"Host(`nginx.xxlaila.cn`)"</span></span><br><span class="line"></span><br><span class="line">  [http.services]</span><br><span class="line">    [http.services.app]</span><br><span class="line"></span><br><span class="line">      [[http.services.app.weighted.services]]</span><br><span class="line">        name = <span class="string">"appv1"</span></span><br><span class="line">        weight = 3</span><br><span class="line"></span><br><span class="line">      [[http.services.app.weighted.services]]</span><br><span class="line">        name = <span class="string">"appv2"</span></span><br><span class="line">        weight = 2</span><br><span class="line"></span><br><span class="line">    [http.services.appv1]</span><br><span class="line">      [http.services.appv1.loadBalancer]</span><br><span class="line">        [[http.services.appv1.loadBalancer.servers]]</span><br><span class="line">          url = <span class="string">"http://appv1.default.svc.cluster.local:80/"</span></span><br><span class="line"></span><br><span class="line">    [http.services.appv2]</span><br><span class="line">      [http.services.appv2.loadBalancer]</span><br><span class="line">        [[http.services.appv2.loadBalancer.servers]]</span><br><span class="line">          url = <span class="string">"http://appv2.default.svc.cluster.local:80/"</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  [http.middlewares]</span><br><span class="line">    [http.middlewares.Middleware00]</span><br><span class="line">      [http.middlewares.Middleware00.addPrefix]</span><br><span class="line">        prefix = <span class="string">"foobar"</span> </span><br><span class="line"></span><br><span class="line">    [http.middlewares.Middleware01]</span><br><span class="line">      [http.middlewares.Middleware01.basicAuth]</span><br><span class="line">        users = [<span class="string">"foobar"</span>, <span class="string">"foobar"</span>]</span><br><span class="line">        usersFile = <span class="string">"foobar"</span></span><br><span class="line">        realm = <span class="string">"foobar"</span></span><br><span class="line">        removeHeader = <span class="literal">true</span></span><br><span class="line">        headerField = <span class="string">"foobar"</span></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;traefik会自动加载配置，http.middlewares 的配置可以删除和增加来测试是否动态配置是否生效。<br><img src="https://img.xxlaila.cn/1578902148997.jpg" alt="img"><br><img src="https://img.xxlaila.cn/1578902281052.jpg" alt="img"></p><p>这里进行5次请求，appv1 接受了3次请求，appv2 接受了两次请求</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl logs -f appv1-6f88c7b898-qx2pc nginx</span></span><br><span class="line">127.0.0.1 - - [13/Jan/2020:07:56:46 +0000] <span class="string">"GET / HTTP/1.1"</span> 200 9 <span class="string">"-"</span> <span class="string">"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.87 Safari/537.36"</span> <span class="string">"172.20.16.22"</span></span><br><span class="line">127.0.0.1 - - [13/Jan/2020:07:56:50 +0000] <span class="string">"GET / HTTP/1.1"</span> 200 9 <span class="string">"-"</span> <span class="string">"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.87 Safari/537.36"</span> <span class="string">"172.20.16.22"</span></span><br><span class="line">127.0.0.1 - - [13/Jan/2020:07:56:52 +0000] <span class="string">"GET / HTTP/1.1"</span> 304 0 <span class="string">"-"</span> <span class="string">"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.87 Safari/537.36"</span> <span class="string">"172.20.16.22"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># kubectl logs -f appv2-558fdbbdb7-6gd8l nginx</span></span><br><span class="line">127.0.0.1 - - [13/Jan/2020:07:56:48 +0000] <span class="string">"GET / HTTP/1.1"</span> 200 9 <span class="string">"-"</span> <span class="string">"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.87 Safari/537.36"</span> <span class="string">"172.20.16.22"</span></span><br><span class="line">127.0.0.1 - - [13/Jan/2020:07:56:54 +0000] <span class="string">"GET / HTTP/1.1"</span> 200 9 <span class="string">"-"</span> <span class="string">"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.87 Safari/537.36"</span> <span class="string">"172.20.16.22"</span></span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Thu Feb 20 2020 16:22:06 GMT+0800 (China Standard Time) --&gt;&lt;h3 id=&quot;认识&quot;&gt;&lt;a href=&quot;#认识&quot; class=&quot;headerlink&quot; title=&quot;认识&quot;&gt;&lt;/a&gt;认识&lt;/h3&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Traefik2.0 中的配置可以使用两种不同的方式&lt;/p&gt;&lt;ul&gt;&lt;li&gt;动态配置：完全动态的路由配置&lt;/li&gt;&lt;li&gt;静态配置：启动配置
    
    </summary>
    
      <category term="Ingress" scheme="https://www.xxlaila.cn/categories/Ingress/"/>
    
    
      <category term="traefik" scheme="https://www.xxlaila.cn/tags/traefik/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch索引管理</title>
    <link href="https://www.xxlaila.cn/2019/12/30/Elasticsearch%E7%B4%A2%E5%BC%95%E7%AE%A1%E7%90%86/"/>
    <id>https://www.xxlaila.cn/2019/12/30/Elasticsearch索引管理/</id>
    <published>2019-12-30T06:41:07.000Z</published>
    <updated>2020-02-20T08:22:27.926Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Thu Feb 20 2020 16:22:37 GMT+0800 (China Standard Time) --><h3 id="痛点"><a href="#痛点" class="headerlink" title="痛点"></a>痛点</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;公司上线了elk日志分析系统，但是在线下开发测试环境数据量比较大，而且线下都是一些测试和开发使用的数据。也没有必要存放起来。<a id="more"></a>但是随着时间的推移，elasticsearch的数据量会撑爆磁盘。伴随着需要人为的清理。所以这就要删除一定时间的数据，来保障磁盘空间的使用量。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由于索引过多，之前都是实用脚本来管理，比如：增量rollover动态更新脚本、定期delete脚本、定期force_merge脚本、定期shrink脚本、定期快照脚本，随着需求的过多，es也有三个集群，脚本维护虽然用了一定的科学管理办法，但是还是挺难维护的。</p><h3 id="elasticsearch-curator介绍"><a href="#elasticsearch-curator介绍" class="headerlink" title="elasticsearch-curator介绍"></a>elasticsearch-curator介绍</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;elasticsearch-curator管理elasticsearch索引和快照，从集群里获取全部索引或者快照作为可操作列表；迭代用户定义的过滤器列表，根据需要逐步从此可操作列表中删除索引或快照；对保留下来的列表执行各种操作。</p><h4 id="功能"><a href="#功能" class="headerlink" title="功能"></a>功能</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;curator允许对索引和快照执行许多不同的操作，包括：</p><ul><li>从别名添加或删除索引（或两者！）</li><li>更改分片路由分配更改分片路由分配</li><li>关闭索引关闭索引</li><li>建索引创建索引</li><li>删除索引删除索引</li><li>删除快照删除快照</li><li>打开被关闭的索引打开被关闭的索引</li><li>对索引执行forcemerge段合并操作对索引执行forcemerge段合并操作</li><li>ndex索引，包括来自远程集群的索引reindex索引，包括来自远程集群的索引</li><li>更改索引的每个分片的副本数 更改索引的每个分片的副本数</li><li>rollover索引rollover索引</li><li>生成索引的快照（备份）生成索引的快照（备份）</li><li>还原快照还原快照</li></ul><h3 id="elasticsearch-curator安装"><a href="#elasticsearch-curator安装" class="headerlink" title="elasticsearch-curator安装"></a>elasticsearch-curator安装</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;elasticsearch-curator安装可以通过两种方式来进行安装，一种是pip、一种是yum。这里使用pip来进行安装。<a href="https://www.elastic.co/guide/en/elasticsearch/client/curator/current/index.html" target="_blank" rel="noopener">安装参考</a></p><h4 id="pip-安装elasticsearch-curator"><a href="#pip-安装elasticsearch-curator" class="headerlink" title="pip 安装elasticsearch-curator"></a>pip 安装elasticsearch-curator</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pip install elasticsearch-curator</span></span><br></pre></td></tr></table></figure><h4 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># curator_cli --host 127.0.0.1 --port 9200  show_indices</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果es安装监听端口是0.0.0.0，则host参数和port参数不需要</span></span><br></pre></td></tr></table></figure><h4 id="配置-config-yml"><a href="#配置-config-yml" class="headerlink" title="配置 config.yml"></a>配置 config.yml</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># mkdir -p /opt/ELKStack/curator</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># cat &gt; config.yaml&lt;&lt;EOF</span></span><br><span class="line">client:</span><br><span class="line">  hosts: [ <span class="string">"172.21.16.18"</span>, <span class="string">"172.21.16.19"</span>, <span class="string">"172.21.16.20"</span> ]</span><br><span class="line">  port: 9200</span><br><span class="line">  url_prefix:</span><br><span class="line">  use_ssl: False</span><br><span class="line">  certificate:</span><br><span class="line">  client_cert:</span><br><span class="line">  client_key:</span><br><span class="line">  ssl_no_validate: False</span><br><span class="line">  http_auth:</span><br><span class="line">  timeout: 30</span><br><span class="line">  master_only: False</span><br><span class="line"></span><br><span class="line">logging:</span><br><span class="line">  loglevel: INFO</span><br><span class="line">  logfile:</span><br><span class="line">  logformat: default</span><br><span class="line">  blacklist: [<span class="string">'elasticsearch'</span>, <span class="string">'urllib3'</span>]</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><ul><li>CONFIG.YML是配置文件，用于配置ES集群信息，<a href="https://www.elastic.co/guide/en/elasticsearch/client/curator/current/configfile.html" target="_blank" rel="noopener">官方参考</a><ul><li>集群IP</li><li>安全认证信息</li><li>日志信息</li></ul></li></ul><h4 id="配置action-yaml"><a href="#配置action-yaml" class="headerlink" title="配置action.yaml"></a>配置action.yaml</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat &gt;action.yml &lt;&lt;EOF</span></span><br><span class="line">actions:</span><br><span class="line">  1:</span><br><span class="line">    action: delete_indices</span><br><span class="line">    description: &gt;-</span><br><span class="line">      Delete indices older than 30 days (based on index name), <span class="keyword">for</span> logstash-prefixed indices. Ignore the error <span class="keyword">if</span> the filter does not result <span class="keyword">in</span> an actionable list of indices (ignore_empty_list) and <span class="built_in">exit</span> cleanly.</span><br><span class="line">    options:</span><br><span class="line">      ignore_empty_list: True</span><br><span class="line">      disable_action: False</span><br><span class="line">    filters:</span><br><span class="line">    - filtertype: pattern</span><br><span class="line">      kind: regex</span><br><span class="line">      <span class="comment"># 保留 kibana|json|monitoring|metadata 不被清理</span></span><br><span class="line">      value: <span class="string">'^((?!(kibana|json|monitoring|metadata)).)*$'</span></span><br><span class="line">    - filtertype: age</span><br><span class="line">      <span class="built_in">source</span>: creation_date</span><br><span class="line">      direction: older</span><br><span class="line">      <span class="comment">#timestring: '%Yi-%m-%d'</span></span><br><span class="line">      unit: days</span><br><span class="line">      unit_count: 30</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果执行多个任务，在actions: 后面的依次类推，<a href="https://www.elastic.co/guide/en/elasticsearch/client/curator/current/actionfile.html" target="_blank" rel="noopener">官方参考</a></p><h4 id="执行测试"><a href="#执行测试" class="headerlink" title="执行测试"></a>执行测试</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># /usr/bin/curator --config /opt/ELKStack/curator/config.yaml /opt/ELKStack/curator/action.yml 1&gt;&gt; /tmp/curator.log 2&gt;&amp;1</span></span><br></pre></td></tr></table></figure><ul><li><p>执行前</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># curator_cli --host 127.0.0.1 --port 9200  show_indices</span></span><br><span class="line">2019-12-30 14:38:22,438 INFO      Instantiating client object</span><br><span class="line">2019-12-30 14:38:22,439 INFO      Testing client connectivity</span><br><span class="line">2019-12-30 14:38:22,506 INFO      Successfully created Elasticsearch client object with provided settings</span><br><span class="line">.kibana6.4</span><br><span class="line">.monitoring-es-6-2019.12.23</span><br><span class="line">.monitoring-es-6-2019.12.24</span><br><span class="line">.monitoring-es-6-2019.12.25</span><br><span class="line">.monitoring-es-6-2019.12.26</span><br><span class="line">.monitoring-es-6-2019.12.27</span><br><span class="line">.monitoring-es-6-2019.12.28</span><br><span class="line">.monitoring-es-6-2019.12.29</span><br><span class="line">.monitoring-es-6-2019.12.30</span><br><span class="line">.monitoring-kibana-6-2019.12.23</span><br><span class="line">.monitoring-kibana-6-2019.12.24</span><br><span class="line">.monitoring-kibana-6-2019.12.25</span><br><span class="line">.monitoring-kibana-6-2019.12.26</span><br><span class="line">.monitoring-kibana-6-2019.12.27</span><br><span class="line">.monitoring-kibana-6-2019.12.28</span><br><span class="line">.monitoring-kibana-6-2019.12.29</span><br><span class="line">.monitoring-kibana-6-2019.12.30</span><br><span class="line">uat-xxx-xxx-system-2019-11</span><br><span class="line">uat-xxx-xxx-system-2019-12</span><br><span class="line">uat-xxx-xxx-system-2019-11</span><br><span class="line">uat-xxx-xxx-system-2019-12</span><br><span class="line">uat-xxx-xxx-xxx-system-2019-11</span><br><span class="line">uat-xxx-xxx-xxx-system-2019-12</span><br><span class="line">dev-xxx-xxx-system-2019-12</span><br><span class="line">dev-xxx-xxx-system-2019-11</span><br><span class="line">dev-xxx-xxx-system-2019-12</span><br><span class="line">dev-xxx-xxx-system-2019-11</span><br><span class="line">dev-xxx-xxx-system-2019-12</span><br><span class="line">dev-xxx-xxx-xxx-system-2019-11</span><br><span class="line">dev-xxx-xxx-xxx-system-2019-12</span><br><span class="line"><span class="built_in">test</span>-xxx-xxx-system-2019-11</span><br><span class="line"><span class="built_in">test</span>-xxx-xxx-system-2019-12</span><br><span class="line"><span class="built_in">test</span>-xxx-xxx-xxx-system-2019-11</span><br><span class="line"><span class="built_in">test</span>-xxx-xxx-xxx-system-2019-12</span><br><span class="line">zxc-2019-11</span><br><span class="line">zxc-2019-12</span><br></pre></td></tr></table></figure></li><li><p>执行后</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat /tmp/curator.log </span></span><br><span class="line">2019-12-30 16:09:44,383 INFO      Preparing Action ID: 1, <span class="string">"delete_indices"</span></span><br><span class="line">2019-12-30 16:09:44,384 INFO      Creating client object and testing connection</span><br><span class="line">2019-12-30 16:09:44,387 INFO      Instantiating client object</span><br><span class="line">2019-12-30 16:09:44,389 INFO      Testing client connectivity</span><br><span class="line">2019-12-30 16:09:44,398 INFO      Successfully created Elasticsearch client object with provided settings</span><br><span class="line">2019-12-30 16:09:44,403 INFO      Trying Action ID: 1, <span class="string">"delete_indices"</span>: Delete indices older than 30 days. Ignore the error <span class="keyword">if</span> the    filter does not result <span class="keyword">in</span> an actionable list of indices    (ignore_empty_list) and <span class="built_in">exit</span> cleanly.</span><br><span class="line">2019-12-30 16:09:46,667 INFO      Deleting 9 selected indices: [u<span class="string">'dev-xxx-xxx-system-2019-11'</span>, u<span class="string">'uat-xxx-xxx-system-2019-11'</span>, u<span class="string">'test-xxx-xxx-xxx-system-2019-11'</span>, u<span class="string">'test-xxx-xxx-system-2019-11'</span>, u<span class="string">'uat-xxx-xxx-xxx-system-2019-11'</span>, u<span class="string">'dev-xxx-xxx-xxx-system-2019-11'</span>, u<span class="string">'uat-xxx-xxx-system-2019-11'</span>, u<span class="string">'dev-xxx-xxx-system-2019-11'</span>, u<span class="string">'zxc-2019-11'</span>]</span><br><span class="line">2019-12-30 16:09:46,667 INFO      ---deleting index dev-xxx-xxx-system-2019-11</span><br><span class="line">2019-12-30 16:09:46,667 INFO      ---deleting index uat-xxx-xxx-system-2019-11</span><br><span class="line">2019-12-30 16:09:46,667 INFO      ---deleting index <span class="built_in">test</span>-xxx-xxx-xxx-system-2019-11</span><br><span class="line">2019-12-30 16:09:46,667 INFO      ---deleting index <span class="built_in">test</span>-xxx-xxx-system-2019-11</span><br><span class="line">2019-12-30 16:09:46,667 INFO      ---deleting index uat-xxx-xxx-xxx-system-2019-11</span><br><span class="line">2019-12-30 16:09:46,667 INFO      ---deleting index dev-xxx-xxx-xxx-system-2019-11</span><br><span class="line">2019-12-30 16:09:46,667 INFO      ---deleting index uat-xxx-xxx-system-2019-11</span><br><span class="line">2019-12-30 16:09:46,667 INFO      ---deleting index dev-xxx-xxx-system-2019-11</span><br><span class="line">2019-12-30 16:09:46,667 INFO      ---deleting index zxc-2019-11</span><br><span class="line">2019-12-30 16:09:56,702 INFO      Action ID: 1, <span class="string">"delete_indices"</span> completed.</span><br><span class="line">2019-12-30 16:09:56,702 INFO      Job completed.</span><br><span class="line"></span><br><span class="line"><span class="comment"># curator_cli --host 127.0.0.1 --port 9200  show_indices</span></span><br><span class="line">2019-12-30 16:13:09,174 INFO      Instantiating client object</span><br><span class="line">2019-12-30 16:13:09,175 INFO      Testing client connectivity</span><br><span class="line">2019-12-30 16:13:09,182 INFO      Successfully created Elasticsearch client object with provided settings</span><br><span class="line">.kibana6.4</span><br><span class="line">.monitoring-es-6-2019.12.23</span><br><span class="line">.monitoring-es-6-2019.12.24</span><br><span class="line">.monitoring-es-6-2019.12.25</span><br><span class="line">.monitoring-es-6-2019.12.26</span><br><span class="line">.monitoring-es-6-2019.12.27</span><br><span class="line">.monitoring-es-6-2019.12.28</span><br><span class="line">.monitoring-es-6-2019.12.29</span><br><span class="line">.monitoring-es-6-2019.12.30</span><br><span class="line">.monitoring-kibana-6-2019.12.23</span><br><span class="line">.monitoring-kibana-6-2019.12.24</span><br><span class="line">.monitoring-kibana-6-2019.12.25</span><br><span class="line">.monitoring-kibana-6-2019.12.26</span><br><span class="line">.monitoring-kibana-6-2019.12.27</span><br><span class="line">.monitoring-kibana-6-2019.12.28</span><br><span class="line">.monitoring-kibana-6-2019.12.29</span><br><span class="line">.monitoring-kibana-6-2019.12.30</span><br><span class="line">uat-xxx-xxx-system-2019-12</span><br><span class="line">uat-xxx-xxx-system-2019-12</span><br><span class="line">uat-xxx-xxx-xxx-system-2019-12</span><br><span class="line">dev-xxx-xxx-system-2019-12</span><br><span class="line">dev-xxx-xxx-system-2019-12</span><br><span class="line">dev-xxx-xxx-system-2019-12</span><br><span class="line">dev-xxx-xxx-xxx-system-2019-12</span><br><span class="line"><span class="built_in">test</span>-xxx-xxx-system-2019-12</span><br><span class="line"><span class="built_in">test</span>-xxx-xxx-xxx-system-2019-12</span><br><span class="line">zxc-2019-12</span><br></pre></td></tr></table></figure></li></ul><h4 id="设置计划任务"><a href="#设置计划任务" class="headerlink" title="设置计划任务"></a>设置计划任务</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># crontab -e</span></span><br><span class="line">42 4 1 * * /usr/bin/curator --config /opt/ELKStack/curator/config.yaml /opt/ELKStack/curator/action.yml 1&gt;&gt; /tmp/curator.log 2&gt;&amp;1</span><br><span class="line"></span><br><span class="line"><span class="comment"># systemctl restart crond</span></span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Thu Feb 20 2020 16:22:37 GMT+0800 (China Standard Time) --&gt;&lt;h3 id=&quot;痛点&quot;&gt;&lt;a href=&quot;#痛点&quot; class=&quot;headerlink&quot; title=&quot;痛点&quot;&gt;&lt;/a&gt;痛点&lt;/h3&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;公司上线了elk日志分析系统，但是在线下开发测试环境数据量比较大，而且线下都是一些测试和开发使用的数据。也没有必要存放起来。
    
    </summary>
    
      <category term="elasticsearch" scheme="https://www.xxlaila.cn/categories/elasticsearch/"/>
    
    
      <category term="elasticsearch" scheme="https://www.xxlaila.cn/tags/elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>centos 安装字体三步曲</title>
    <link href="https://www.xxlaila.cn/2019/12/23/centos-%E5%AE%89%E8%A3%85%E5%AD%97%E4%BD%93%E4%B8%89%E6%AD%A5%E6%9B%B2/"/>
    <id>https://www.xxlaila.cn/2019/12/23/centos-安装字体三步曲/</id>
    <published>2019-12-23T09:38:36.000Z</published>
    <updated>2019-12-23T09:43:27.263Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Thu Feb 20 2020 16:22:06 GMT+0800 (China Standard Time) --><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;上传字体到服务器。</p><h3 id="安装准备"><a href="#安装准备" class="headerlink" title="安装准备"></a>安装准备</h3><a id="more"></a><h4 id="安装字体库"><a href="#安装字体库" class="headerlink" title="安装字体库"></a>安装字体库</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># yum -y install fontconfig</span></span><br></pre></td></tr></table></figure><h4 id="安装字体索引信息"><a href="#安装字体索引信息" class="headerlink" title="安装字体索引信息"></a>安装字体索引信息</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># yum -y install ttmkfdir mkfontscale</span></span><br></pre></td></tr></table></figure><h4 id="创建目录"><a href="#创建目录" class="headerlink" title="创建目录"></a>创建目录</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;linux的字体目录默认是存放在<code>/usr/share/fonts</code>，可以创建chinese用于存放中文字体。吧字体复制到该目录</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># mkdir -p /usr/share/fonts/chinese</span></span><br></pre></td></tr></table></figure><h3 id="安装字体"><a href="#安装字体" class="headerlink" title="安装字体"></a>安装字体</h3><h4 id="生成字库索引信息"><a href="#生成字库索引信息" class="headerlink" title="生成字库索引信息"></a>生成字库索引信息</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># mkfontscale</span></span><br><span class="line"><span class="comment"># mkfontdir</span></span><br></pre></td></tr></table></figure><h4 id="更新字体缓存"><a href="#更新字体缓存" class="headerlink" title="更新字体缓存"></a>更新字体缓存</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># fc-cache</span></span><br></pre></td></tr></table></figure><h3 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># fc-list</span></span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Thu Feb 20 2020 16:22:06 GMT+0800 (China Standard Time) --&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;上传字体到服务器。&lt;/p&gt;&lt;h3 id=&quot;安装准备&quot;&gt;&lt;a href=&quot;#安装准备&quot; class=&quot;headerlink&quot; title=&quot;安装准备&quot;&gt;&lt;/a&gt;安装准备&lt;/h3&gt;
    
    </summary>
    
      <category term="centos" scheme="https://www.xxlaila.cn/categories/centos/"/>
    
    
      <category term="fonts" scheme="https://www.xxlaila.cn/tags/fonts/"/>
    
  </entry>
  
  <entry>
    <title>nfs服务器异常</title>
    <link href="https://www.xxlaila.cn/2019/12/23/nfs%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%BC%82%E5%B8%B8/"/>
    <id>https://www.xxlaila.cn/2019/12/23/nfs服务器异常/</id>
    <published>2019-12-23T01:29:41.000Z</published>
    <updated>2020-01-02T08:05:04.315Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Thu Feb 20 2020 16:22:06 GMT+0800 (China Standard Time) --><h3 id="故障表现"><a href="#故障表现" class="headerlink" title="故障表现"></a>故障表现</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;近期发现只要是挂载nfs的服务器，不定期的出现服务器卡死，发现是在ansible自动化发布的时候出现一直卡死，然后登录服务器端发现发现命令不能用，如: ls、df等命令无法正常使用。<a id="more"></a>在客户端查看系统日志没有任何错误。查看系统资源，资源利用率也足够。</p><h3 id="故障解决"><a href="#故障解决" class="headerlink" title="故障解决"></a>故障解决</h3><h4 id="nfs服务端"><a href="#nfs服务端" class="headerlink" title="nfs服务端"></a>nfs服务端</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;登录nfs服务端查看系统的日志发现:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">Dec 23 09:01:01 dev-nfs systemd: Removed slice User Slice of root.</span><br><span class="line">Dec 23 09:01:01 dev-nfs systemd: Stopping User Slice of root.</span><br><span class="line">Dec 23 09:21:26 dev-nfs systemd: Created slice User Slice of root.</span><br><span class="line">Dec 23 09:21:26 dev-nfs systemd: Starting User Slice of root.</span><br><span class="line">Dec 23 09:21:26 dev-nfs systemd: Started Session 12836 of user root.</span><br><span class="line">Dec 23 09:21:26 dev-nfs systemd-logind: New session 12836 of user root.</span><br><span class="line">Dec 23 09:21:26 dev-nfs systemd: Starting Session 12836 of user root.</span><br><span class="line">Dec 23 09:22:01 dev-nfs systemd: Stopping RPC <span class="built_in">bind</span> service...</span><br><span class="line">Dec 23 09:22:01 dev-nfs systemd: Starting RPC <span class="built_in">bind</span> service...</span><br><span class="line">Dec 23 09:22:01 dev-nfs systemd: Started RPC <span class="built_in">bind</span> service.</span><br><span class="line">Dec 23 09:22:11 dev-nfs systemd: Started Session 12837 of user root.</span><br><span class="line">Dec 23 09:22:11 dev-nfs systemd-logind: New session 12837 of user root.</span><br><span class="line">Dec 23 09:22:11 dev-nfs systemd: Starting Session 12837 of user root.</span><br><span class="line">Dec 23 09:22:12 dev-nfs systemd: Stopping NFS server and services...</span><br><span class="line">Dec 23 09:22:12 dev-nfs kernel: nfsd: last server has exited, flushing <span class="built_in">export</span> cache</span><br><span class="line">Dec 23 09:22:12 dev-nfs systemd: Stopping NFS Mount Daemon...</span><br><span class="line">Dec 23 09:22:12 dev-nfs systemd: Stopping NFSv4 ID-name mapping service...</span><br><span class="line">Dec 23 09:22:12 dev-nfs rpc.mountd[29810]: Caught signal 15, un-registering and exiting.</span><br><span class="line">Dec 23 09:22:12 dev-nfs systemd: Starting Preprocess NFS configuration...</span><br><span class="line">Dec 23 09:22:12 dev-nfs systemd: Started Preprocess NFS configuration.</span><br><span class="line">Dec 23 09:22:12 dev-nfs systemd: Starting NFSv4 ID-name mapping service...</span><br><span class="line">Dec 23 09:22:12 dev-nfs systemd: Starting NFS Mount Daemon...</span><br><span class="line">Dec 23 09:22:12 dev-nfs systemd: Started NFSv4 ID-name mapping service.</span><br><span class="line">Dec 23 09:22:12 dev-nfs systemd: Started NFS Mount Daemon.</span><br><span class="line">Dec 23 09:22:12 dev-nfs systemd: Starting NFS server and services...</span><br><span class="line">Dec 23 09:22:12 dev-nfs rpc.mountd[31339]: Version 1.3.0 starting</span><br><span class="line">Dec 23 09:22:12 dev-nfs kernel: NFSD: starting 90-second grace period (net ffffffff81ad9d40)</span><br></pre></td></tr></table></figure><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;发现nfs的服务端出现 <code>kernel</code>内核的异常，于是乎登录google得知。发现nfs线程数不够了，提示要增加一些数量的threads。</p><h5 id="当前nfs状态"><a href="#当前nfs状态" class="headerlink" title="当前nfs状态"></a>当前nfs状态</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat /proc/net/rpc/nfsd </span></span><br><span class="line">rc 0 0 30463198</span><br><span class="line">fh 0 0 0 0 0</span><br><span class="line">io 1447382326 1456801108</span><br><span class="line">th 8 0 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000</span><br><span class="line">ra 32 0 0 0 0 0 0 0 0 0 0 0</span><br><span class="line">net 30463199 0 30485174 266</span><br><span class="line">rpc 30463198 1 1 0 0</span><br><span class="line">proc3 22 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</span><br><span class="line">proc4 2 70 30463126</span><br><span class="line">proc4ops 72 0 0 0 570540 491739 28774 6320 0 191550 6463291 255991 0 0 0 0 177217 0 0 523775 0 0 133 6853388 0 230 203547 27936 0 8180 209 0 0 209 0 311026 0 0 0 2126786 0 0 0 266 14491135 185 0 0 0 0 0 0 0 26 15971485 0 3 0 46 204 0 0 0 0 0 0 0 0 0 0 0 0 0</span><br></pre></td></tr></table></figure><h5 id="查看线程数"><a href="#查看线程数" class="headerlink" title="查看线程数"></a>查看线程数</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat /proc/fs/nfsd/threads</span></span><br><span class="line">8</span><br></pre></td></tr></table></figure><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;原来nfs默认启动了8个thread，应该是不够了，可以手动修改增加一些。修改nfs的默认线程数方式如下</p><h5 id="修改nfs的默认线程数"><a href="#修改nfs的默认线程数" class="headerlink" title="修改nfs的默认线程数"></a>修改nfs的默认线程数</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># vim /etc/sysconfig/nfs</span></span><br><span class="line"><span class="comment"># The default is 8. </span></span><br><span class="line">RPCNFSDCOUNT=32</span><br></pre></td></tr></table></figure><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;需要重启nfs</p><h4 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat /proc/net/rpc/nfsd</span></span><br><span class="line">rc 0 0 30464433</span><br><span class="line">fh 0 0 0 0 0</span><br><span class="line">io 1447382326 1456801108</span><br><span class="line">th 32 0 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000</span><br><span class="line">ra 64 0 0 0 0 0 0 0 0 0 0 0</span><br><span class="line">net 30464434 0 30486409 268</span><br><span class="line">rpc 30464433 1 1 0 0</span><br><span class="line">proc3 22 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</span><br><span class="line">proc4 2 70 30464361</span><br><span class="line">proc4ops 72 0 0 0 570540 491739 28774 6320 0 191550 6463293 255991 0 0 0 0 177217 0 0 523775 0 0 133 6853388 0 232 203547 27936 0 8180 209 0 0 209 0 311026 0 0 0 2126786 0 0 0 268 14492227 185 0 0 0 0 0 0 0 26 15971626 0 3 0 46 206 0 0 0 0 0 0 0 0 0 0 0 0 0</span><br><span class="line"></span><br><span class="line"><span class="comment"># cat /proc/fs/nfsd/threads</span></span><br><span class="line">32</span><br><span class="line"></span><br><span class="line"><span class="comment"># cat /proc/fs/nfsd/pool_threads</span></span><br><span class="line">32</span><br><span class="line"></span><br><span class="line"><span class="comment"># cat /proc/fs/nfsd/pool_stats </span></span><br><span class="line"><span class="comment"># pool packets-arrived sockets-enqueued threads-woken threads-timedout</span></span><br><span class="line">0 485 4 481 0</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Thu Feb 20 2020 16:22:06 GMT+0800 (China Standard Time) --&gt;&lt;h3 id=&quot;故障表现&quot;&gt;&lt;a href=&quot;#故障表现&quot; class=&quot;headerlink&quot; title=&quot;故障表现&quot;&gt;&lt;/a&gt;故障表现&lt;/h3&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;近期发现只要是挂载nfs的服务器，不定期的出现服务器卡死，发现是在ansible自动化发布的时候出现一直卡死，然后登录服务器端发现发现命令不能用，如: ls、df等命令无法正常使用。
    
    </summary>
    
      <category term="centos" scheme="https://www.xxlaila.cn/categories/centos/"/>
    
    
      <category term="nfs" scheme="https://www.xxlaila.cn/tags/nfs/"/>
    
  </entry>
  
  <entry>
    <title>traefik https使用</title>
    <link href="https://www.xxlaila.cn/2019/12/19/traefik-https%E4%BD%BF%E7%94%A8/"/>
    <id>https://www.xxlaila.cn/2019/12/19/traefik-https使用/</id>
    <published>2019-12-19T06:06:08.000Z</published>
    <updated>2020-01-09T08:53:19.411Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Thu Feb 20 2020 16:22:07 GMT+0800 (China Standard Time) --><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;之前已经使用traefik服务作为入口，测试并访问了tomcat应用，之前是通过http来访问的，而我们在yaml文件里面也添加8443端口用于https访问，在实际环境中我们也是需要<br>https来进行访问应用，通过traefik实现https，<a href="https://xxlaila.github.io/2019/09/05/traefik-ingress%E4%BD%BF%E7%94%A8/" target="_blank" rel="noopener">traefik http应用</a></p><a id="more"></a><h3 id="操作实践"><a href="#操作实践" class="headerlink" title="操作实践"></a>操作实践</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这里我用了公司的证书，就是为了贴近真实，也满足测试需求，创建一个secret，保存https证书，如果没有证书，可以使用以下方式进行生成证书</p><h4 id="签证书"><a href="#签证书" class="headerlink" title="签证书"></a>签证书</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;没有证书可以使用命令生产证书</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># mkdir certs</span></span><br><span class="line"><span class="comment"># openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout xxlaila.cn.key -out xxlaila.cn.crt -subj "/CN=*.xxlaila.cn"</span></span><br></pre></td></tr></table></figure><h3 id="部署准备"><a href="#部署准备" class="headerlink" title="部署准备"></a>部署准备</h3><h4 id="traefik-toml"><a href="#traefik-toml" class="headerlink" title="traefik.toml"></a>traefik.toml</h4><ul><li><p>http 和https共同存在</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">defaultEntryPoints = [<span class="string">"http"</span>,<span class="string">"https"</span>]</span><br><span class="line">[entryPoints]</span><br><span class="line">  [entryPoints.http]</span><br><span class="line">  address = <span class="string">":80"</span></span><br><span class="line">    entryPoint = <span class="string">"https"</span></span><br><span class="line">  [entryPoints.https]</span><br><span class="line">  address = <span class="string">":443"</span></span><br><span class="line">    [entryPoints.https.tls]</span><br><span class="line">      [[entryPoints.https.tls.certificates]]</span><br><span class="line">      certFile = <span class="string">"/certs/xxlaila.cn.crt"</span></span><br><span class="line">      keyFile = <span class="string">"/certs/xxlaila.cn.key"</span></span><br></pre></td></tr></table></figure></li><li><p>所有http请求全部rewrite为https的规则</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">defaultEntryPoints = [<span class="string">"http"</span>,<span class="string">"https"</span>]</span><br><span class="line">[entryPoints]</span><br><span class="line">  [entryPoints.http]</span><br><span class="line"> <span class="built_in"> address </span>= <span class="string">":80"</span></span><br><span class="line">    [entryPoints.http.redirect]</span><br><span class="line">    entryPoint = <span class="string">"https"</span></span><br><span class="line">  [entryPoints.https]</span><br><span class="line"> <span class="built_in"> address </span>= <span class="string">":443"</span></span><br><span class="line">    [entryPoints.https.tls]</span><br><span class="line">      [[entryPoints.https.tls.certificates]]</span><br><span class="line">      certFile = <span class="string">"/certs/xxlaila.cn.crt"</span></span><br><span class="line">      keyFile = <span class="string">"/certs/xxlaila.cn.key"</span></span><br></pre></td></tr></table></figure></li><li><p>部分域名强制跳转https</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">defaultEntryPoints = [<span class="string">"http"</span>,<span class="string">"https"</span>]</span><br><span class="line">[entryPoints]</span><br><span class="line">  [entryPoints.http]</span><br><span class="line">  address = <span class="string">":80"</span></span><br><span class="line">    [entryPoints.http.redirect]</span><br><span class="line">      regex = <span class="string">"^http://traefix.xxlaila.cn/(.*)"</span></span><br><span class="line">      replacement = <span class="string">"https://traefix.xxlaila.cn/<span class="variable">$1</span>"</span></span><br><span class="line">  [entryPoints.https]</span><br><span class="line">  address = <span class="string">":443"</span></span><br><span class="line">    [entryPoints.https.tls]</span><br><span class="line">      [[entryPoints.https.tls.certificates]]</span><br><span class="line">      certFile = <span class="string">"/certs/xxlaila.cn.crt"</span></span><br><span class="line">      keyFile = <span class="string">"/certs/xxlaila.cn.key"</span></span><br></pre></td></tr></table></figure></li></ul><h4 id="创建证书secret"><a href="#创建证书secret" class="headerlink" title="创建证书secret"></a>创建证书secret</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#  kubectl create secret generic traefik-cert --from-file=certs/xxlaila.cn.crt --from-file=certs/xxlaila.cn.key --from-file=certs/dev.xxlaila.cn.crt --from-file=certs/dev.xxlaila.cn.key --from-file=certs/test.xxlaila.cn.crt --from-file=certs/test.xxlaila.cn.key  -n kube-system</span></span><br><span class="line">secret/traefik-cert created</span><br><span class="line"></span><br><span class="line"><span class="comment"># kubectl get secret traefik-cert -n kube-system </span></span><br><span class="line">NAME           TYPE     DATA   AGE</span><br><span class="line">traefik-cert   Opaque   2      26s</span><br></pre></td></tr></table></figure><ul><li>traefik-cert.yaml<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">证书base64加密</span><br><span class="line"><span class="comment"># cat dev.xxlaila.cn.crt |base64 |tr -d '\n'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># cat &gt; traefik-cert.yaml&lt;&lt;EOF</span></span><br><span class="line">---</span><br><span class="line">kind: Secert</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: traefik-cert</span><br><span class="line">  namespace: kube-system</span><br><span class="line">data:</span><br><span class="line">  <span class="string">"dev.xxlaila.cn.crt"</span>: </span><br><span class="line">  <span class="string">"dev.xxlaila.cn.key"</span>:</span><br><span class="line">  <span class="string">"test.xxlaila.cn.crt"</span></span><br><span class="line">  <span class="string">"test.xxlaila.cn.key"</span>:</span><br><span class="line">  <span class="string">"xxlaila.cn.crt"</span>:</span><br><span class="line">  <span class="string">"xxlaila.cn.key"</span>:</span><br><span class="line"><span class="built_in">type</span>:</span><br><span class="line">  - Opaque</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></li></ul><h4 id="创建configmap保存traefix的配置"><a href="#创建configmap保存traefix的配置" class="headerlink" title="创建configmap保存traefix的配置"></a>创建configmap保存traefix的配置</h4><ul><li>traefik.toml<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat &gt; traefik.toml&lt;&lt;EOF</span></span><br><span class="line">defaultEntryPoints = [<span class="string">"http"</span>,<span class="string">"https"</span>]</span><br><span class="line">[entryPoints]</span><br><span class="line">  [entryPoints.http]</span><br><span class="line">    address = <span class="string">":80"</span></span><br><span class="line">    compress = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">    [entryPoints.http.whitelist]</span><br><span class="line">      sourceRange = [<span class="string">"172.21.0.0/16"</span>, <span class="string">"172.16.0.0/16"</span>]</span><br><span class="line">      useXForwardedFor = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">    [entryPoints.http.redirect]</span><br><span class="line">      entryPoint = <span class="string">"https"</span></span><br><span class="line">  [entryPoints.https]</span><br><span class="line">    address = <span class="string">":443"</span></span><br><span class="line">    [entryPoints.https.tls]</span><br><span class="line">      [[entryPoints.https.tls.certificates]]</span><br><span class="line">      certFile = <span class="string">"/opt/traefix/certs/xxlaila.cn.crt"</span></span><br><span class="line">      keyFile = <span class="string">"/opt/traefix/certs/xxlaila.cn.key"</span></span><br><span class="line">      [[entryPoints.https.tls.certificates]]</span><br><span class="line">      certFile = <span class="string">"/opt/traefix/certs/dev.xxlaila.cn.crt"</span></span><br><span class="line">      keyFile = <span class="string">"/opt/traefix/certs/dev.xxlaila.cn.key"</span></span><br><span class="line">      [[entryPoints.https.tls.certificates]]</span><br><span class="line">      certFile = <span class="string">"/opt/traefix/certs/test.xxlaila.cn.crt"</span></span><br><span class="line">      keyFile = <span class="string">"/opt/traefix/certs/test.xxlaila.cn.key"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># rules</span></span><br><span class="line">filename = <span class="string">"/opt/traefix/conf/rules.toml"</span></span><br><span class="line">watch = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="comment"># kubectl create configmap traefik-conf --from-file=conf/traefik.toml -n kube-system</span></span><br><span class="line">configmap/traefik-conf created</span><br><span class="line"></span><br><span class="line"><span class="comment"># kubectl get configmap traefik-conf -n kube-system</span></span><br><span class="line">NAME           DATA   AGE</span><br><span class="line">traefik-conf   1      25s</span><br></pre></td></tr></table></figure></li></ul><h3 id="重新部署Traefix"><a href="#重新部署Traefix" class="headerlink" title="重新部署Traefix"></a>重新部署Traefix</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;重新部署Traefix主要是要关联创建的secret和configMap，并挂载相对应的主机目录。</p><h4 id="deployment-方式部署"><a href="#deployment-方式部署" class="headerlink" title="deployment 方式部署"></a>deployment 方式部署</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;修改片段</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># vim traefik-deployment.yaml </span></span><br><span class="line">---</span><br><span class="line">kind: Deployment</span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  name: traefik-ingress-controller</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: traefik-ingress-lb</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: traefik-ingress-lb</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: traefik-ingress-lb</span><br><span class="line">        name: traefik-ingress-lb</span><br><span class="line">    spec:</span><br><span class="line">      serviceAccountName: traefik-ingress-controller</span><br><span class="line">      terminationGracePeriodSeconds: 60</span><br><span class="line">      hostNetwork: <span class="literal">true</span> </span><br><span class="line">      dnsPolicy: ClusterFirstWithHostNet</span><br><span class="line">      volumes:</span><br><span class="line">      - name: ssl</span><br><span class="line">        secret:</span><br><span class="line">          secretName: traefik-cert</span><br><span class="line">      - name: config</span><br><span class="line">        configMap:</span><br><span class="line">          name: traefik-conf</span><br><span class="line">          defaultMode: 0644</span><br><span class="line">          items:</span><br><span class="line">            - key: traefik.toml</span><br><span class="line">              path: traefik.toml</span><br><span class="line">      containers:</span><br><span class="line">      - image: traefik:v1.7</span><br><span class="line">        name: traefik-ingress-lb</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - mountPath: <span class="string">"/certs"</span></span><br><span class="line">          name: <span class="string">"ssl"</span></span><br><span class="line">        - mountPath: <span class="string">"/etc/traefik.toml"</span></span><br><span class="line">          subPath: <span class="string">"traefik.toml"</span></span><br><span class="line">          name: <span class="string">"config"</span></span><br><span class="line">        ports:</span><br><span class="line">        - name: http</span><br><span class="line">          containerPort: 80</span><br><span class="line">        - name: admin</span><br><span class="line">          containerPort: 8080</span><br><span class="line">        securityContext:</span><br><span class="line">          capabilities:</span><br><span class="line">            drop:</span><br><span class="line">            - ALL</span><br><span class="line">            add:</span><br><span class="line">              - NET_BIND_SERVICE</span><br><span class="line">        args:</span><br><span class="line">        - --api</span><br><span class="line">        - --web</span><br><span class="line">        - --api.dashboard</span><br><span class="line">        - --web.metrics</span><br><span class="line">        - --metrics.prometheus</span><br><span class="line">        - --web.metrics.prometheus</span><br><span class="line">        - --kubernetes</span><br><span class="line">        - --logLevel=INFO</span><br><span class="line">        - --traefiklog</span><br><span class="line">        - --traefiklog.format=json</span><br><span class="line">        - --accesslog</span><br><span class="line">        - --accesslog.format=json</span><br><span class="line">        - --accessLog.fields.headers.defaultMode=redact</span><br><span class="line">        - --insecureskipverify=<span class="literal">true</span></span><br><span class="line">        - --configFile=/etc/traefik.toml</span><br><span class="line">        - --defaultentrypoints=http,https</span><br><span class="line">        - --entrypoints=Name:https Address::443 TLS</span><br><span class="line">        - --entrypoints=Name:http Address::80 </span><br><span class="line">      nodeSelector:</span><br><span class="line">        IngressProxy: <span class="string">"true"</span></span><br><span class="line">      tolerations:</span><br><span class="line">      - effect: NoSchedule</span><br><span class="line">        key: node-role.kubernetes.io/ingress</span><br><span class="line">        operator: Equal</span><br></pre></td></tr></table></figure><ul><li>执行创建<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl apply -f traefik-deployment.yaml</span></span><br></pre></td></tr></table></figure></li></ul><h4 id="测试ui"><a href="#测试ui" class="headerlink" title="测试ui"></a>测试ui</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat &gt;ui.yaml&lt;&lt;EOF </span></span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: traefik-web-ui</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: traefik-ingress-lb</span><br><span class="line">  ports:</span><br><span class="line">  - name: web</span><br><span class="line">    port: 80</span><br><span class="line">    targetPort: 8080</span><br><span class="line">---</span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: traefik-web-ui</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  annotations:</span><br><span class="line">    kubernetes.io/ingress.class: traefik</span><br><span class="line">    <span class="comment">#traefik.ingress.kubernetes.io/frontend-entry-points: http,https</span></span><br><span class="line">    <span class="comment">#traefik.ingress.kubernetes.io/redirect-entry-point: https</span></span><br><span class="line">spec:</span><br><span class="line">  <span class="comment">#tls:</span></span><br><span class="line">  <span class="comment">#  - secretName: traefik-cert</span></span><br><span class="line">  rules:</span><br><span class="line">  - host: traefik.xxlaila.cn</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - path: /</span><br><span class="line">        backend:</span><br><span class="line">          serviceName: traefik-web-ui</span><br><span class="line">          servicePort: web</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat &gt;ui-test.yaml &lt;&lt;EOF</span></span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: traefik-web-ui-test</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: traefik-ingress-lb</span><br><span class="line">  ports:</span><br><span class="line">  - name: web</span><br><span class="line">    port: 80</span><br><span class="line">    targetPort: 8080</span><br><span class="line">---</span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: traefik-web-ui-test</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  annotations:</span><br><span class="line">    kubernetes.io/ingress.class: traefik</span><br><span class="line">    traefik.ingress.kubernetes.io/frontend-entry-points: http,https</span><br><span class="line">    traefik.ingress.kubernetes.io/redirect-entry-point: https</span><br><span class="line">spec:</span><br><span class="line">  <span class="comment">#tls:</span></span><br><span class="line">  <span class="comment">#  - secretName: traefik-cert</span></span><br><span class="line">  rules:</span><br><span class="line">  - host: traefik.test.xxlaila.cn</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - path: /</span><br><span class="line">        backend:</span><br><span class="line">          serviceName: traefik-web-ui</span><br><span class="line">          servicePort: web</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p><strong>注</strong>:<br>tls: traefikm默认加载的证书是tls开头的crt、key证书。如果只有一个证书，可以这么设置。多个域名证书需要设定不同的secret名称，在tls引用的时候根据不同的域名指定不同secret名称<br>redirect-entry-point: 该域名强制跳转https</p><h3 id="traefik-代理外部服务"><a href="#traefik-代理外部服务" class="headerlink" title="traefik 代理外部服务"></a>traefik 代理外部服务</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;traefix对外部应用提供服务，这里以公司的一个应用app和harbor为列，</p><h4 id="java-app"><a href="#java-app" class="headerlink" title="java app"></a>java app</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat &gt; java-app.yaml</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: app-biz</span><br><span class="line">  name: app-biz</span><br><span class="line">  namespace: default</span><br><span class="line">  annotations:</span><br><span class="line">    kubernetes.io/ingress.class: traefik</span><br><span class="line">    traefik.ingress.kubernetes.io/affinity: <span class="string">"true"</span></span><br><span class="line">    traefik.ingress.kubernetes.io/load-balancer-method: drr</span><br><span class="line">spec:</span><br><span class="line">  clusterIP: None</span><br><span class="line">  ports:</span><br><span class="line">  - name: http</span><br><span class="line">    port: 8030</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 8030</span><br><span class="line">  sessionAffinity: None</span><br><span class="line">  <span class="built_in">type</span>: ClusterIP</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Endpoints</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: app-biz</span><br><span class="line">  name: app-biz</span><br><span class="line">  namespace: default</span><br><span class="line">subsets:</span><br><span class="line">- addresses:</span><br><span class="line">  - ip: 172.22.1.1</span><br><span class="line">  - ip: 172.22.1.2</span><br><span class="line">  ports:</span><br><span class="line">  - name: http</span><br><span class="line">    port: 8030</span><br><span class="line">    protocol: TCP</span><br><span class="line">---</span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: app-biz</span><br><span class="line">  namespace: default</span><br><span class="line">  annotations:</span><br><span class="line">    kubernetes.io/ingress.class: traefik</span><br><span class="line">    traefik.frontend.rule.type: PathPrefixStrip</span><br><span class="line">    traefik.ingress.kubernetes.io/frontend-entry-points: http,https</span><br><span class="line">    traefik.ingress.kubernetes.io/redirect-entry-point: https</span><br><span class="line">spec:</span><br><span class="line">  rules:</span><br><span class="line">  - host: app-biz.test.xxlaila.cn</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">        - path: /</span><br><span class="line">          backend:</span><br><span class="line">            serviceName: app-biz</span><br><span class="line">            servicePort: 8030</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h4 id="harbor"><a href="#harbor" class="headerlink" title="harbor"></a>harbor</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat &gt;harbor.yaml&lt;&lt;EOF</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: harbor</span><br><span class="line">  name: harbor</span><br><span class="line">  namespace: default</span><br><span class="line">  annotations:</span><br><span class="line">    kubernetes.io/ingress.class: traefik</span><br><span class="line">    traefik.ingress.kubernetes.io/affinity: <span class="string">"true"</span></span><br><span class="line">    <span class="comment">#traefik.ingress.kubernetes.io/load-balancer-method: drr</span></span><br><span class="line">spec:</span><br><span class="line">  clusterIP: None</span><br><span class="line">  ports:</span><br><span class="line">  - name: http</span><br><span class="line">    port: 80</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 80</span><br><span class="line">  sessionAffinity: None</span><br><span class="line">  <span class="built_in">type</span>: ClusterIP</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Endpoints</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: harbor</span><br><span class="line">  name: harbor</span><br><span class="line">  namespace: default</span><br><span class="line">subsets:</span><br><span class="line">- addresses:</span><br><span class="line">  - ip: 172.21.16.90</span><br><span class="line">  ports:</span><br><span class="line">  - name: http</span><br><span class="line">    port: 80</span><br><span class="line">    protocol: TCP</span><br><span class="line">---</span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: harbor</span><br><span class="line">  namespace: default</span><br><span class="line">  annotations:</span><br><span class="line">    kubernetes.io/ingress.class: traefik</span><br><span class="line">    traefik.frontend.rule.type: PathPrefixStrip</span><br><span class="line">    traefik.ingress.kubernetes.io/frontend-entry-points: http,https</span><br><span class="line">    traefik.ingress.kubernetes.io/redirect-entry-point: https</span><br><span class="line">spec:</span><br><span class="line">  rules:</span><br><span class="line">  - host: harbor.xxlaila.cn</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">        - path: /</span><br><span class="line">          backend:</span><br><span class="line">            serviceName: harbor</span><br><span class="line">            servicePort: 80</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Thu Feb 20 2020 16:22:07 GMT+0800 (China Standard Time) --&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;之前已经使用traefik服务作为入口，测试并访问了tomcat应用，之前是通过http来访问的，而我们在yaml文件里面也添加8443端口用于https访问，在实际环境中我们也是需要&lt;br&gt;https来进行访问应用，通过traefik实现https，&lt;a href=&quot;https://xxlaila.github.io/2019/09/05/traefik-ingress%E4%BD%BF%E7%94%A8/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;traefik http应用&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Ingress" scheme="https://www.xxlaila.cn/categories/Ingress/"/>
    
    
      <category term="traefik" scheme="https://www.xxlaila.cn/tags/traefik/"/>
    
  </entry>
  
  <entry>
    <title>kube-eventer事件发射器</title>
    <link href="https://www.xxlaila.cn/2019/12/16/kube-eventer%E4%BA%8B%E4%BB%B6%E5%8F%91%E5%B0%84%E5%99%A8/"/>
    <id>https://www.xxlaila.cn/2019/12/16/kube-eventer事件发射器/</id>
    <published>2019-12-16T03:05:43.000Z</published>
    <updated>2019-12-23T07:21:22.010Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Thu Feb 20 2020 16:22:06 GMT+0800 (China Standard Time) --><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;kube-eventer 是一个事件发射器，它将 Kubernetes 事件发送到接收器(例如，DingTalk、SLS、Kafka 等)。<a id="more"></a><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;监控是保障系统稳定性的重要组成部分，在 Kubernetes 开源生态中，资源类的监控工具与组件百花齐放，但是，只有资源类的监控是远远不够的，因为资源监控存在如下两个主要的缺欠：</p><ul><li>监控的实时性与准确性不足</li><li>监控的场景覆盖范围不足</li></ul><p><a href="https://github.com/AliyunContainerService/kube-eventer" target="_blank" rel="noopener">详细参考</a><br><a href="http://baijiahao.baidu.com/s?id=1639090263884959561&wfr=spider&for=pc" target="_blank" rel="noopener">推荐阅读</a></p><h3 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h3><h4 id="kubernetes-事件查看"><a href="#kubernetes-事件查看" class="headerlink" title="kubernetes 事件查看"></a>kubernetes 事件查看</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl get events</span></span><br><span class="line">LAST SEEN   TYPE      REASON                    OBJECT                                 MESSAGE</span><br><span class="line">5d20h       Normal    NodeHasSufficientMemory   node/172.21.16.110                     Node 172.21.16.110 status is now: NodeHasSufficientMemory</span><br><span class="line">5d20h       Normal    NodeHasNoDiskPressure     node/172.21.16.110                     Node 172.21.16.110 status is now: NodeHasNoDiskPressure</span><br><span class="line">5d20h       Normal    RegisteredNode            node/172.21.16.110                     Node 172.21.16.110 event: Registered Node 172.21.16.110 <span class="keyword">in</span> Controller</span><br><span class="line">5d20h       Normal    RegisteredNode            node/172.21.16.110                     Node 172.21.16.110 event: Registered Node 172.21.16.110 <span class="keyword">in</span> Controller</span><br><span class="line">5d20h       Normal    Starting                  node/172.21.16.110                     Starting kubelet.</span><br><span class="line">5d20h       Warning   Rebooted                  node/172.21.17.30                      Node 172.21.17.30 has been rebooted, boot id: f4b25a34-ace9-417a-884a-6eb52bedd4d9</span><br></pre></td></tr></table></figure><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&amp;nbspkubernetes事件分为两类:</p><ul><li>Normal: 达到期望的状态，目前的状态一致</li><li>Warning: 状态在没有预期的情况下产生的</li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;下载官方的yaml文件，定一个kube-eventer.yaml文件。修改<code>command</code>参数<code>--sink=</code>。这里公司使用的是企业微信。这里使用企业微信来进行告警通知。<a href="https://github.com/AliyunContainerService/kube-eventer/blob/master/docs/en/wechat-sink.md" target="_blank" rel="noopener">企业微信参数</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">- --sink=wechat:?corp_id=skjfbikssa985e28974ihjkh&amp;corp_secret=dfjkiSdsdfgL-q8hhhzqKWomFqeC_letAMYCVPsda3sdsa&amp;agent_id=1000020&amp;to_user=&amp;label=kxl&amp;level=Normal</span><br></pre></td></tr></table></figure><h4 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h4><p><img src="https://img.xxlaila.cn/1576465910400.jpg" alt="img"></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Thu Feb 20 2020 16:22:06 GMT+0800 (China Standard Time) --&gt;&lt;h3 id=&quot;介绍&quot;&gt;&lt;a href=&quot;#介绍&quot; class=&quot;headerlink&quot; title=&quot;介绍&quot;&gt;&lt;/a&gt;介绍&lt;/h3&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;kube-eventer 是一个事件发射器，它将 Kubernetes 事件发送到接收器(例如，DingTalk、SLS、Kafka 等)。
    
    </summary>
    
      <category term="kubernetes" scheme="https://www.xxlaila.cn/categories/kubernetes/"/>
    
    
      <category term="kube-eventer" scheme="https://www.xxlaila.cn/tags/kube-eventer/"/>
    
  </entry>
  
  <entry>
    <title>master加入node节点</title>
    <link href="https://www.xxlaila.cn/2019/12/13/master%E5%8A%A0%E5%85%A5node%E8%8A%82%E7%82%B9/"/>
    <id>https://www.xxlaila.cn/2019/12/13/master加入node节点/</id>
    <published>2019-12-13T08:26:22.000Z</published>
    <updated>2019-12-13T08:46:13.312Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Thu Feb 20 2020 16:22:06 GMT+0800 (China Standard Time) --><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;之前一直没有做k8s集群的时候一直没有master加入为node节点。在使用的时候遇到了很多坑，<a id="more"></a>但是都还好，都能及时的解决。这里记录一下吧master加入node行列的好处。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这个问题是之前在<a href="https://www.xxlaila.cn/2019/10/29/istio%E9%83%A8%E7%BD%B2/">部署istio</a>的时候遇到的。整了大半个月最终搞定啦。master加入node节点以后解决了哪些问题。istio、metrics-server、heapster的问题都解决了。在部署metrics-server、heapster的时候不需要增加<code>hostNetwork: true</code>参数。</p><h3 id="master加入node"><a href="#master加入node" class="headerlink" title="master加入node"></a>master加入node</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果master加入node节点需要安装kubele、flanneld、docker、kube-proxy，与正常的node安装没有区别。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;但是master成为node节点以后，我们又不想master部署pod来增加master节点的压力。所以需要吧master节点设置为<code>SchedulingDisabled</code>。设置master节点为<code>SchedulingDisabled</code>的命令是</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl patch node master-01 -p '&#123;"spec":&#123;"unschedulable":true&#125;&#125;'</span></span><br></pre></td></tr></table></figure><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这样设置是将Node 脱离调度范围，但是运行在改node节点上pod不会自动的停止。需要手动停止改node上运行的pod。如果需要回复调度是将<code>unschedulable</code>设置为false。执&gt;行kubectl replace或者kubectl patch 命令就能恢复系统对改 Node 的调度。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl patch node master-01 -p '&#123;"spec":&#123;"unschedulable":false&#125;&#125;'</span></span><br></pre></td></tr></table></figure><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;也可以使用kubectl的子命令cordon和uncordon也用于实现将Node进行隔离和恢复调度的操作。</p><ul><li><p>使用kubectl cordon对某个Node进行隔离调度操作</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl cordon master-01</span></span><br></pre></td></tr></table></figure></li><li><p>恢复</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl uncordon master-01</span></span><br></pre></td></tr></table></figure></li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;需要注意的是即使设置node为<code>SchedulingDisabled</code>，系统还是会调度<code>DaemonSet</code>类型的pod。如果flanneld是pod安装，这个一定要调度过来。否则网络不通。设置<code>DaemonSet</code>类型的pod不调度在<code>SchedulingDisabled</code>的node上，可以吧<code>DaemonSet</code>设置一个<code>nodeSelector</code>的标签。让这类型的pod运行在指定的节点上。</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Thu Feb 20 2020 16:22:06 GMT+0800 (China Standard Time) --&gt;&lt;h3 id=&quot;介绍&quot;&gt;&lt;a href=&quot;#介绍&quot; class=&quot;headerlink&quot; title=&quot;介绍&quot;&gt;&lt;/a&gt;介绍&lt;/h3&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;之前一直没有做k8s集群的时候一直没有master加入为node节点。在使用的时候遇到了很多坑，
    
    </summary>
    
      <category term="kubernetes" scheme="https://www.xxlaila.cn/categories/kubernetes/"/>
    
    
      <category term="node" scheme="https://www.xxlaila.cn/tags/node/"/>
    
  </entry>
  
  <entry>
    <title>istio部署错误解决</title>
    <link href="https://www.xxlaila.cn/2019/12/13/istio%E9%83%A8%E7%BD%B2%E9%94%99%E8%AF%AF%E8%A7%A3%E5%86%B3/"/>
    <id>https://www.xxlaila.cn/2019/12/13/istio部署错误解决/</id>
    <published>2019-12-13T01:31:46.000Z</published>
    <updated>2020-02-25T03:28:19.489Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Feb 25 2020 15:08:41 GMT+0800 (China Standard Time) --><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在前面的一篇文章中我做了简单的部署，但是在疏忽bookinfo的时候出现了错误。<a id="more"></a>这个错误不解决，没办法进行下一步。后学的路由规则完全没办法学习和测试。</p><h3 id="istio错误解决"><a href="#istio错误解决" class="headerlink" title="istio错误解决"></a>istio错误解决</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; istio的错误查看<a href="https://www.xxlaila.cn/2019/10/29/istio%E9%83%A8%E7%BD%B2/">istio的部署</a>，本次根据这个错误来进行解决。</p><h3 id="查看日志"><a href="#查看日志" class="headerlink" title="查看日志"></a>查看日志</h3><h4 id="apiserver日志"><a href="#apiserver日志" class="headerlink" title="apiserver日志"></a>apiserver日志</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 这个错误访问k8s的apiserver 问题，应该是超时。我们可以查看apiserver的日志，利用 journalctl 命令来筛选apiserver的日志</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># journalctl  -u  kube-apiserver  -f</span></span><br><span class="line"></span><br><span class="line">Nov 08 09:59:33 k8s-master-01-3.kxl kube-apiserver[31393]: I1108 09:59:33.659161   31393 trace.go:81] Trace[40457478]: <span class="string">"Create /apis/networking.istio.io/v1alpha3/namespaces/istio-system/gateways"</span> (started: 2019-11-08 09:59:03.657132211 +0800 CST m=+328870.679516549) (total time: 30.001964129s):</span><br><span class="line">Nov 08 09:59:33 k8s-master-01-3.kxl kube-apiserver[31393]: Trace[40457478]: [30.001964129s] [30.001043358s] END</span><br><span class="line">Nov 08 09:59:33 k8s-master-01-3.kxl kube-apiserver[31393]: W1108 09:59:33.659790   31393 dispatcher.go:73] Failed calling webhook, failing closed pilot.validation.istio.io: failed calling webhook <span class="string">"pilot.validation.istio.io"</span>: Post https://istio-galley.istio-system.svc:443/admitpilot?timeout=30s: net/http: request canceled <span class="keyword">while</span> waiting <span class="keyword">for</span> connection (Client.Timeout exceeded <span class="keyword">while</span> awaiting headers)</span><br><span class="line">Nov 08 09:59:39 k8s-master-01-3.kxl kube-apiserver[31393]: I1108 09:59:39.979543   31393 controller.go:107] OpenAPI AggregationController: Processing item v1beta1.metrics.k8s.io</span><br><span class="line">Nov 08 10:00:03 k8s-master-01-3.kxl kube-apiserver[31393]: W1108 10:00:03.764977   31393 dispatcher.go:73] Failed calling webhook, failing closed pilot.validation.istio.io: failed calling webhook <span class="string">"pilot.validation.istio.io"</span>: Post https://istio-galley.istio-system.svc:443/admitpilot?timeout=30s: context deadline exceeded (Client.Timeout exceeded <span class="keyword">while</span> awaiting headers)</span><br><span class="line">Nov 08 10:00:03 k8s-master-01-3.kxl kube-apiserver[31393]: I1108 10:00:03.765401   31393 trace.go:81] Trace[1649710078]: <span class="string">"Create /apis/networking.istio.io/v1alpha3/namespaces/default/destinationrules"</span> (started: 2019-11-08 09:59:33.763211641 +0800 CST m=+328900.785596022) (total time: 30.00209862s):</span><br><span class="line">Nov 08 10:00:03 k8s-master-01-3.kxl kube-apiserver[31393]: Trace[1649710078]: [30.00209862s] [30.001534667s] END</span><br><span class="line">Nov 08 10:00:33 k8s-master-01-3.kxl kube-apiserver[31393]: I1108 10:00:33.840606   31393 trace.go:81] Trace[970347589]: <span class="string">"Create /apis/networking.istio.io/v1alpha3/namespaces/weather/virtualservices"</span> (started: 2019-11-08 10:00:03.83792882 +0800 CST m=+328930.860313362) (total time: 30.002612137s):</span><br><span class="line">Nov 08 10:00:33 k8s-master-01-3.kxl kube-apiserver[31393]: Trace[970347589]: [30.002612137s] [30.001075132s] END</span><br><span class="line">Nov 08 10:00:33 k8s-master-01-3.kxl kube-apiserver[31393]: W1108 10:00:33.841663   31393 dispatcher.go:73] Failed calling webhook, failing closed pilot.validation.istio.io: failed calling webhook <span class="string">"pilot.validation.istio.io"</span>: Post https://istio-galley.istio-system.svc:443/admitpilot?timeout=30s: context deadline exceeded (Client.Timeout exceeded <span class="keyword">while</span> awaiting headers)</span><br><span class="line">Nov 08 10:00:38 k8s-master-01-3.kxl kube-apiserver[31393]: I1108 10:00:38.260710   31393 trace.go:81] Trace[460935607]: <span class="string">"GuaranteedUpdate etcd3: *v1.Endpoints"</span> (started: 2019-11-08 10:00:37.644096515 +0800 CST m=+328964.666480867) (total time: 616.515599ms):</span><br><span class="line">Nov 08 10:00:38 k8s-master-01-3.kxl kube-apiserver[31393]: Trace[460935607]: [533.664848ms] [449.34458ms] Transaction prepared</span><br><span class="line">Nov 08 10:00:39 k8s-master-01-3.kxl kube-apiserver[31393]: I1108 10:00:39.986622   31393 controller.go:107] OpenAPI AggregationController: Processing item v1beta1.metrics.k8s.io</span><br><span class="line">Nov 08 10:01:38 k8s-master-01-3.kxl kube-apiserver[31393]: I1108 10:01:38.780611   31393 trace.go:81] Trace[269873276]: <span class="string">"Get /api/v1/namespaces/default"</span> (started: 2019-11-08 10:01:37.631910347 +0800 CST m=+329024.654294682) (total time: 1.148554735s):</span><br><span class="line">Nov 08 10:01:38 k8s-master-01-3.kxl kube-apiserver[31393]: Trace[269873276]: [1.148211464s] [1.148180236s] About to write a response</span><br></pre></td></tr></table></figure><h4 id="istio-pilot日志"><a href="#istio-pilot日志" class="headerlink" title="istio-pilot日志"></a>istio-pilot日志</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl logs istio-pilot-569499d666-rfjsh  -n istio-system discovery</span></span><br><span class="line">2019-11-08T07:26:14.097765ZinfoHandling event update <span class="keyword">for</span> pod istio-security-post-install-1.2.8-c52np <span class="keyword">in</span> namespace istio-system -&gt; 172.30.112.9</span><br><span class="line">2019-11-08T07:26:27.395268ZinfoHandling event update <span class="keyword">for</span> pod istio-security-post-install-1.2.8-c52np <span class="keyword">in</span> namespace istio-system -&gt; 172.30.112.9</span><br><span class="line">2019-11-08T07:26:38.227484ZinfoClient received GoAway with http2.ErrCodeEnhanceYourCalm.</span><br><span class="line">2019-11-08T07:26:38.227760ZinfopickfirstBalancer: HandleSubConnStateChange: 0xc0001fbaa0, CONNECTING</span><br><span class="line">2019-11-08T07:26:38.228913Zinfotransport: loopyWriter.run returning. connection error: desc = <span class="string">"transport is closing"</span></span><br><span class="line">2019-11-08T07:26:38.230352ZerrormcpError receiving MCP resource: rpc error: code = Unavailable desc = transport is closing</span><br><span class="line">2019-11-08T07:26:38.230387ZerrormcpError receiving MCP response: rpc error: code = Unavailable desc = transport is closing</span><br><span class="line">2019-11-08T07:26:38.235755ZinfopickfirstBalancer: HandleSubConnStateChange: 0xc0001fbaa0, READY</span><br><span class="line">2019-11-08T07:26:39.230701Zinfomcp(re)trying to establish new MCP sink stream</span><br></pre></td></tr></table></figure><h4 id="istio-galley日志"><a href="#istio-galley日志" class="headerlink" title="istio-galley日志"></a>istio-galley日志</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl logs istio-galley-64f7d8cc97-8nbpc  -n istio-system</span></span><br><span class="line">2019-11-08T07:23:38.860184ZinfomcpMCP: connection &#123;addr=172.30.104.7:57190 id=3&#125; ACK collection=istio/rbac/v1alpha1/serviceroles with version=<span class="string">"0"</span> nonce=<span class="string">"16"</span> inc=<span class="literal">false</span></span><br><span class="line">2019-11-08T07:23:38.860197ZinfomcpWatch(): created watch 28 <span class="keyword">for</span> istio/rbac/v1alpha1/serviceroles from group <span class="string">"default"</span>, version <span class="string">"0"</span></span><br><span class="line">2019-11-08T07:23:38.860217ZinfomcpMCP: connection &#123;addr=172.30.104.7:57190 id=3&#125; ACK collection=istio/networking/v1alpha3/gateways with version=<span class="string">"0"</span> nonce=<span class="string">"17"</span> inc=<span class="literal">false</span></span><br><span class="line">2019-11-08T07:23:38.860268ZinfomcpWatch(): created watch 29 <span class="keyword">for</span> istio/networking/v1alpha3/gateways from group <span class="string">"default"</span>, version <span class="string">"0"</span></span><br><span class="line">2019-11-08T07:26:38.227268Zinfotransport: Got too many pings from the client, closing the connection.</span><br><span class="line">2019-11-08T07:26:38.227414Zinfotransport: loopyWriter.run returning. Err: transport: Connection closing</span><br><span class="line">2019-11-08T07:26:38.228857Zinfotransport: http2Server.HandleStreams failed to <span class="built_in">read</span> frame: <span class="built_in">read</span> tcp 172.30.104.4:9901-&gt;172.30.104.7:57190: use of closed network connection</span><br><span class="line">2019-11-08T07:26:38.229130ZerrormcpMCP: connection &#123;addr=172.30.104.7:57190 id=3&#125;: TERMINATED with errors: rpc error: code = Canceled desc = context canceled</span><br><span class="line">2019-11-08T07:26:38.229162ZinfomcpMCP: connection &#123;addr=172.30.104.7:57190 id=3&#125;: CLOSED</span><br></pre></td></tr></table></figure><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;前面其实有一个错误，忘记记录了，是一个tls的证书问题。根据上面的错误在google上找了好久，各种文档都查看了好久。就是安装的时候去验证tls证书，还有什么webhook问题。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>解决办法:</strong> 需要在apiserver里面需要配置 enable-admission-plugins，由于在安装的时候指定了某一个插件，导致这个未启用，如果没有配置该插件，默认其实是启用的。两个插件分别是：ValidatingAdmissionWebhook、MutatingAdmissionWebhook。安装文档里面已经修改，<a href="https://www.xxlaila.cn/2019/09/11/kubernetes-v1-14%E5%AE%89%E8%A3%85/">参考配置</a>。修改以后需要重启kube-apiserver。</p><h4 id="master加入node"><a href="#master加入node" class="headerlink" title="master加入node"></a>master加入node</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果master节点未安装kubele、flanneld、docker、kube-proxy。会导致master节点访问不了集群内部的istio-sidecar-injector服务。就会导致自动注入失败。而且当在部署自动注入的时候就会提示: <code>Error creating: Internal error occurred: failed calling webhook &quot;sidecar-injector.istio.io&quot;: Post https://istio-sidecar-injector.istio-system.svc:443/inject?timeout=30s: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers</code>。<br><img src="https://img.xxlaila.cn/1576201446462.jpg" alt="img"><br>在这个错误提示前，在容器里面看看能否访问该地址。是否同</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -vL  -k  https://istio-sidecar-injector.istio-system.svc:443/inject?timeout=30s</span><br></pre></td></tr></table></figure><p>![img]<a href="https://img.xxlaila.cn/1D39819D6935D7496D07AC714D17A231.jpg()" target="_blank" rel="noopener">https://img.xxlaila.cn/1D39819D6935D7496D07AC714D17A231.jpg()</a></p><p>这里有大神总结的<a href="https://mp.weixin.qq.com/s/6TjJQrv_z6AZPKw6eigAcQ" target="_blank" rel="noopener">详细错误</a>，master节点加入node<a href="https://www.xxlaila.cn/2019/12/13/master加入node节点">详细参考</a>说明。</p><h4 id="验证api-resources"><a href="#验证api-resources" class="headerlink" title="验证api-resources"></a>验证api-resources</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl api-resources | grep admissionregistration</span><br><span class="line">mutatingwebhookconfigurations                  admissionregistration.k8s.io   <span class="literal">false</span>        MutatingWebhookConfiguration</span><br><span class="line">validatingwebhookconfigurations                admissionregistration.k8s.io   <span class="literal">false</span>        ValidatingWebhookConfiguration</span><br></pre></td></tr></table></figure><ul><li>启用 admissionregistration.k8s.io/v1alpha1 API<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl api-versions | grep admissionregistration.k8s.io</span></span><br><span class="line">admissionregistration.k8s.io/v1beta1</span><br></pre></td></tr></table></figure></li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;使用上面命令可以检查当前是否以启用，admissionregistration.k8s.io/v1alpha1 API，若不存在则需要在 apiserver 的配置中添加–runtime-config=admissionregistration.k8s.io/v1alpha1。</p><h3 id="重新部署"><a href="#重新部署" class="headerlink" title="重新部署"></a>重新部署</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;新建一个Values.yaml 配置参数文件。下面是参考一个大神的。然后根据自己测试修改的</p><ul><li>Values.yaml<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br></pre></td><td class="code"><pre><span class="line">global:</span><br><span class="line">  defaultResources:</span><br><span class="line">    requests:</span><br><span class="line">      cpu: 30m</span><br><span class="line">      memory: 50Mi</span><br><span class="line">    limits:</span><br><span class="line">      cpu: 400m</span><br><span class="line">      memory: 600Mi</span><br><span class="line">  proxy:</span><br><span class="line">    includeIPRanges: 10.244.0.0/16,10.254.0.0/16</span><br><span class="line">    <span class="comment"># 是否开启自动注入功能，取值enabled则该pods只要没有被注解为sidecar.istio.io/inject: "false",就会自动注入。如果取值为disabled，则需要为pod设置注解sidecar.istio.io/inject: "true"才会进行注入</span></span><br><span class="line">    <span class="comment"># 如果要使用官方bookinfo来进行测试学习，这个设置为enabled。如果设置为disable的，在部署官方bookinfo的时候则不会部署 `Sidecar (istio-proxy)`。需要自己手动去整。官方默认是开启状态</span></span><br><span class="line">    autoInject: enabled</span><br><span class="line">    resources:</span><br><span class="line">      requests:</span><br><span class="line">        cpu: 30m</span><br><span class="line">        memory: 50Mi</span><br><span class="line">      limits:</span><br><span class="line">        cpu: 400m</span><br><span class="line">        memory: 500Mi</span><br><span class="line">  mtls:</span><br><span class="line">    enabled: <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">sidecarInjectorWebhook:</span><br><span class="line">  enabled: <span class="literal">true</span></span><br><span class="line">  <span class="comment"># 变量为true，就会为所有命名空间开启自动注入功能。如果赋值为false，则只有标签为istio-injection的命名空间才会开启自动注入功能</span></span><br><span class="line">  enableNamespacesByDefault: <span class="literal">false</span></span><br><span class="line">  rewriteAppHTTPProbe: <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">mixer:</span><br><span class="line">  policy:</span><br><span class="line">    enabled: enabled</span><br><span class="line">  telemetry:</span><br><span class="line">    enabled: <span class="literal">true</span></span><br><span class="line">    resources:</span><br><span class="line">      requests:</span><br><span class="line">        cpu: 100m</span><br><span class="line">        memory: 300Mi</span><br><span class="line">      limits:</span><br><span class="line">        cpu: 1000m</span><br><span class="line">        memory: 1024Mi</span><br><span class="line"></span><br><span class="line">pilot:</span><br><span class="line">  enabled: <span class="literal">true</span></span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      cpu: 100m</span><br><span class="line">      memory: 300Mi</span><br><span class="line">    limits:</span><br><span class="line">      cpu: 1000m</span><br><span class="line">      memory: 1024Mi</span><br><span class="line"></span><br><span class="line">gateways:</span><br><span class="line">  enabled: <span class="literal">true</span></span><br><span class="line">  istio-ingressgateway:</span><br><span class="line">    enabled: <span class="literal">true</span></span><br><span class="line">    <span class="built_in">type</span>: NodePort</span><br><span class="line">    resources:</span><br><span class="line">      requests:</span><br><span class="line">        cpu: 100m</span><br><span class="line">        memory: 128Mi</span><br><span class="line">      limits:</span><br><span class="line">        cpu: 1000m</span><br><span class="line">        memory: 1024Mi</span><br><span class="line">  istio-egressgateway:</span><br><span class="line">    enabled: enabled</span><br><span class="line">    <span class="built_in">type</span>: NodePort</span><br><span class="line">    resources:</span><br><span class="line">      requests:</span><br><span class="line">        cpu: 100m</span><br><span class="line">        memory: 128Mi</span><br><span class="line">      limits:</span><br><span class="line">        cpu: 1000m</span><br><span class="line">        memory: 256Mi</span><br><span class="line"></span><br><span class="line">tracing:</span><br><span class="line">  enabled: <span class="literal">true</span></span><br><span class="line">  jaeger:</span><br><span class="line">    resources:</span><br><span class="line">      limits:</span><br><span class="line">        cpu: 300m</span><br><span class="line">        memory: 900Mi</span><br><span class="line">      requests:</span><br><span class="line">        cpu: 30m</span><br><span class="line">        memory: 100Mi</span><br><span class="line">  zipkin:</span><br><span class="line">    resources:</span><br><span class="line">      limits:</span><br><span class="line">        cpu: 300m</span><br><span class="line">        memory: 900Mi</span><br><span class="line">      requests:</span><br><span class="line">        cpu: 30m</span><br><span class="line">        memory: 100Mi</span><br><span class="line">  contextPath: /</span><br><span class="line">  ingress:</span><br><span class="line">    enabled: <span class="literal">true</span></span><br><span class="line">    annotations:</span><br><span class="line">      kubernetes.io/ingress.class: traefik</span><br><span class="line">    hosts:</span><br><span class="line">      - istio-tracing.xxlaila.cn</span><br><span class="line"></span><br><span class="line">kiali:</span><br><span class="line">  enabled: <span class="literal">true</span></span><br><span class="line">  resources:</span><br><span class="line">    limits:</span><br><span class="line">      cpu: 300m</span><br><span class="line">      memory: 900Mi</span><br><span class="line">    requests:</span><br><span class="line">      cpu: 30m</span><br><span class="line">      memory: 50Mi</span><br><span class="line">  hub: kiali</span><br><span class="line">  contextPath: /</span><br><span class="line">  ingress:</span><br><span class="line">    enabled: <span class="literal">true</span></span><br><span class="line">    annotations: </span><br><span class="line">      kubernetes.io/ingress.class: traefik</span><br><span class="line">    hosts:</span><br><span class="line">      - istio-kiali.xxlaila.cn</span><br><span class="line">  dashboard:</span><br><span class="line">    grafanaURL: http://grafana:3000</span><br><span class="line">    jaegerURL: http://jaeger-query:16686</span><br><span class="line"></span><br><span class="line">grafana:</span><br><span class="line">  enabled: <span class="literal">true</span></span><br><span class="line">  persist: <span class="literal">true</span></span><br><span class="line">  storageClassName: xxlaila-nfs-storage</span><br><span class="line">  accessMode: ReadWriteMany</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      cpu: 30m</span><br><span class="line">      memory: 50Mi</span><br><span class="line">    limits:</span><br><span class="line">      cpu: 300m</span><br><span class="line">      memory: 500Mi</span><br><span class="line">  contextPath: /</span><br><span class="line">  ingress:</span><br><span class="line">    enabled: <span class="literal">true</span></span><br><span class="line">    annotations:</span><br><span class="line">      kubernetes.io/ingress.class: traefik</span><br><span class="line">    hosts:</span><br><span class="line">      - istio-grafana.xxlaila.cn</span><br><span class="line"></span><br><span class="line">prometheus:</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      cpu: 30m</span><br><span class="line">      memory: 50Mi</span><br><span class="line">    limits:</span><br><span class="line">      cpu: 500m</span><br><span class="line">      memory: 1024Mi</span><br><span class="line">  retention: 3d</span><br><span class="line">  contextPath: /</span><br><span class="line">  ingress:</span><br><span class="line">    enabled: <span class="literal">true</span></span><br><span class="line">    annotations:</span><br><span class="line">      kubernetes.io/ingress.class: traefik</span><br><span class="line">    hosts:</span><br><span class="line">      - istio-prometheus.xxlaila.cn</span><br><span class="line"></span><br><span class="line">istio_cni:</span><br><span class="line">  enabled: <span class="literal">false</span></span><br></pre></td></tr></table></figure></li></ul><p><strong>注</strong>:</p><ul><li>istio 访问外部服务，istio网格默认不能访问外部服务，如需要访问外部服务有三种方式<ul><li>global.proxy.includeIPRanges: istio 访问外部服务。指定访问外部的服务ip地址段，直接通过proxy进行访问。默认是<code>*</code> 所有的</li><li>创建应用时指定pod annotaion: traffic.sidecar.istio.io/includeOutboundIPRanges: “127.0.0.1/24,10.244.0.1/24”</li><li>创建ServiceEntry, 需要通过egressgateway控制访问外部服务，应用场景一般是集群的node不能访问外部网络。如集群可以访问外部网络则不需要</li></ul></li></ul><p><a href="https://mp.weixin.qq.com/s/PPTnoyVD2bzeZ6vHRUphzQ" target="_blank" rel="noopener">参考文献</a><br><a href="https://istio.io/docs/reference/config/installation-options/" target="_blank" rel="noopener">官方参数</a></p><h4 id="安装-Istio"><a href="#安装-Istio" class="headerlink" title="安装 Istio"></a>安装 Istio</h4><ul><li><p>部署crds</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># helm install install/kubernetes/helm/istio-init --name istio-init --namespace istio-system</span></span><br></pre></td></tr></table></figure></li><li><p>部署istio</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># helm install ./install/kubernetes/helm/istio --name istio --namespace istio-system -f Values.yaml  --host=10.254.156.238:44134</span></span><br></pre></td></tr></table></figure></li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这里说一下这个 <code>--host</code>参数。在执行helm安装的时候遇到了 <code>portforward.go:178] lost connection to pod， Error: transport is closing</code>。ip是tiller-deploy的ip</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl get svc -n kube-system tiller-deploy</span></span><br><span class="line">NAME            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)     AGE</span><br><span class="line">tiller-deploy   ClusterIP   10.254.156.238   &lt;none&gt;        44134/TCP   10d</span><br></pre></td></tr></table></figure><ul><li>部署kiali登录认证<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat &gt;kiali-secret.yaml &lt;&lt;EOF</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  name: kiali</span><br><span class="line">  namespace: istio-system</span><br><span class="line">  labels:</span><br><span class="line">    app: kiali</span><br><span class="line"><span class="built_in">type</span>: Opaque</span><br><span class="line">data:</span><br><span class="line">  username: <span class="string">"YWRtaW4="</span></span><br><span class="line">  passphrase: <span class="string">"YWRtaW4="</span></span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="comment"># kubectl apply -f kiali-secret.yaml</span></span><br></pre></td></tr></table></figure></li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;账号密码是admin/admin，可以参考<a href="https://www.xxlaila.cn/2019/10/29/istio%E9%83%A8%E7%BD%B2/">istio部署</a>最前面</p><h4 id="查看验证"><a href="#查看验证" class="headerlink" title="查看验证"></a>查看验证</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># helm list --all</span></span><br><span class="line">NAME      REVISIONUPDATED                 STATUS  CHART           APP VERSIONNAMESPACE   </span><br><span class="line">istio     1       Fri Dec 13 09:23:59 2019DEPLOYEDistio-1.4.0     1.4.0      istio-system</span><br><span class="line">istio-init1       Fri Dec 13 09:22:56 2019DEPLOYEDistio-init-1.4.01.4.0      istio-system</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl get pods -n istio-system</span></span><br><span class="line">NAME                                     READY   STATUS      RESTARTS   AGE</span><br><span class="line">grafana-6df449db94-496vn                 1/1     Running     0          59m</span><br><span class="line">istio-citadel-56bc45cd9-9tv99            1/1     Running     0          59m</span><br><span class="line">istio-egressgateway-6646ddf7bd-vskqb     1/1     Running     0          59m</span><br><span class="line">istio-galley-8466db4f-9pjfj              1/1     Running     0          59m</span><br><span class="line">istio-ingressgateway-6ff999fc48-pdwj8    1/1     Running     0          59m</span><br><span class="line">istio-init-crd-10-1.4.0-lzssz            0/1     Completed   0          61m</span><br><span class="line">istio-init-crd-11-1.4.0-gp9cg            0/1     Completed   0          61m</span><br><span class="line">istio-init-crd-14-1.4.0-2md46            0/1     Completed   0          61m</span><br><span class="line">istio-pilot-7dbb475df9-fchzq             2/2     Running     3          59m</span><br><span class="line">istio-policy-f8bb48d59-wsmvb             2/2     Running     3          59m</span><br><span class="line">istio-sidecar-injector-9f4dbd594-r9tm6   1/1     Running     0          59m</span><br><span class="line">istio-telemetry-5c57d8976c-8rmvc         2/2     Running     4          59m</span><br><span class="line">istio-telemetry-5c57d8976c-gt8zt         2/2     Running     0          3m45s</span><br><span class="line">istio-tracing-567bc5c88f-gtpfl           1/1     Running     0          59m</span><br><span class="line">kiali-77b68664b7-pdvck                   1/1     Running     0          59m</span><br><span class="line">prometheus-575dbff696-s62dw              1/1     Running     0          59m</span><br></pre></td></tr></table></figure><h3 id="部署官方的bookinfo"><a href="#部署官方的bookinfo" class="headerlink" title="部署官方的bookinfo"></a>部署官方的bookinfo</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;使用自动注入。</p><h4 id="部署pods-和服务"><a href="#部署pods-和服务" class="headerlink" title="部署pods 和服务"></a>部署pods 和服务</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl label namespace default istio-injection=enabled</span></span><br><span class="line">namespace/default labeled</span><br><span class="line"></span><br><span class="line"><span class="comment"># kubectl apply -f samples/bookinfo/platform/kube/bookinfo.yaml</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># kubectl get services</span></span><br><span class="line">NAME          TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE</span><br><span class="line">details       ClusterIP   10.254.148.138   &lt;none&gt;        9080/TCP   15s</span><br><span class="line">kubernetes    ClusterIP   10.254.0.1       &lt;none&gt;        443/TCP    15d</span><br><span class="line">productpage   ClusterIP   10.254.183.24    &lt;none&gt;        9080/TCP   11s</span><br><span class="line">ratings       ClusterIP   10.254.185.74    &lt;none&gt;        9080/TCP   15s</span><br><span class="line">reviews       ClusterIP   10.254.180.76    &lt;none&gt;        9080/TCP   13s</span><br><span class="line"></span><br><span class="line"><span class="comment"># kubectl get pods</span></span><br><span class="line">NAME                             READY   STATUS              RESTARTS   AGE</span><br><span class="line">details-v1-c5b5f496d-ztml6       1/1     Running             0          18s</span><br><span class="line">productpage-v1-c7765c886-592sd   0/1     ContainerCreating   0          13s</span><br><span class="line">ratings-v1-f745cf57b-8d7h2       1/1     Running             0          18s</span><br><span class="line">reviews-v1-75b979578c-nrj48      1/1     Running             0          15s</span><br><span class="line">reviews-v2-597bf96c8f-tvc5v      1/1     Running             0          16s</span><br><span class="line">reviews-v3-54c6c64795-75qgp      1/1     Running             0          16s</span><br></pre></td></tr></table></figure><h4 id="部署gateway"><a href="#部署gateway" class="headerlink" title="部署gateway"></a>部署gateway</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl apply -f samples/bookinfo/networking/bookinfo-gateway.yaml</span></span><br><span class="line">gateway.networking.istio.io/bookinfo-gateway created</span><br><span class="line">virtualservice.networking.istio.io/bookinfo created</span><br><span class="line"></span><br><span class="line"><span class="comment"># kubectl get gateway</span></span><br><span class="line">NAME               AGE</span><br><span class="line">bookinfo-gateway   4s</span><br><span class="line"></span><br><span class="line"><span class="comment"># kubectl apply -f samples/bookinfo/networking/destination-rule-all.yaml</span></span><br><span class="line">destinationrule.networking.istio.io/productpage created</span><br><span class="line">destinationrule.networking.istio.io/reviews created</span><br><span class="line">destinationrule.networking.istio.io/ratings created</span><br><span class="line">destinationrule.networking.istio.io/details created</span><br></pre></td></tr></table></figure><h4 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl get pods</span></span><br><span class="line">NAME                             READY   STATUS    RESTARTS   AGE</span><br><span class="line">details-v1-c5b5f496d-75vcp       2/2     Running   0          11m</span><br><span class="line">productpage-v1-c7765c886-lh7hc   2/2     Running   0          11m</span><br><span class="line">ratings-v1-f745cf57b-6hdd9       2/2     Running   0          11m</span><br><span class="line">reviews-v1-75b979578c-n7dvn      2/2     Running   0          11m</span><br><span class="line">reviews-v2-597bf96c8f-fptt2      2/2     Running   0          11m</span><br><span class="line">reviews-v3-54c6c64795-fn74z      2/2     Running   0          11m</span><br></pre></td></tr></table></figure><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在浏览器打开任意node的ip，<a href="http://ip:31380/productpage，" target="_blank" rel="noopener">http://ip:31380/productpage，</a> istio部署错误解决完成。</p><h4 id="规则验证"><a href="#规则验证" class="headerlink" title="规则验证"></a>规则验证</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在刚开始建立的时候已经设置了默认的目标规则。下面来测试一下官方给的默认规则。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;吧所有的流量迁移到v3版本。需要执行virtual-service-reviews-v3.yaml文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl apply -f virtual-service-reviews-v3.yaml</span></span><br></pre></td></tr></table></figure><p><img src="https://img.xxlaila.cn/1576483227032.jpg" alt="img"></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;设定一个登录某一个用户显示v2版本。默认显示v3版本。需要执行virtual-service-reviews-jason-v2-v3.yaml</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl apply -f virtual-service-reviews-jason-v2-v3.yaml</span></span><br></pre></td></tr></table></figure><p><img src="https://img.xxlaila.cn/1576483408814.jpg" alt="img"><br><img src="https://img.xxlaila.cn/1576483452482.jpg" alt="img"><br><img src="https://img.xxlaila.cn/1576483506265.jpg" alt="img"></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue Feb 25 2020 15:08:41 GMT+0800 (China Standard Time) --&gt;&lt;h3 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h3&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;在前面的一篇文章中我做了简单的部署，但是在疏忽bookinfo的时候出现了错误。
    
    </summary>
    
      <category term="kubernetes" scheme="https://www.xxlaila.cn/categories/kubernetes/"/>
    
    
      <category term="istio" scheme="https://www.xxlaila.cn/tags/istio/"/>
    
  </entry>
  
  <entry>
    <title>alertmanager告警配置</title>
    <link href="https://www.xxlaila.cn/2019/12/06/alertmanager%E5%91%8A%E8%AD%A6%E9%85%8D%E7%BD%AE/"/>
    <id>https://www.xxlaila.cn/2019/12/06/alertmanager告警配置/</id>
    <published>2019-12-06T08:46:31.000Z</published>
    <updated>2019-12-06T09:57:27.541Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Thu Feb 20 2020 16:22:06 GMT+0800 (China Standard Time) --><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 前篇文章做了kubernetes 的 监控，基于<a href="https://www.xxlaila.cn/2019/12/04/k8s-v1-14-prometheus%E4%B8%8Egrafana%E9%83%A8%E7%BD%B2/">prometheus与grafana部署</a>，监控是做好了，但是还缺乏告警机制，没有告警机制监控就白做了，prometheus的告警就是alertmanager来做。<a id="more"></a> 而在部署kube-prometheus的时候，alertmanager也是部署完成，这里只需要稍加修改alertmanager即可实现告警</p><h3 id="配置-alertmanager"><a href="#配置-alertmanager" class="headerlink" title="配置 alertmanager"></a>配置 alertmanager</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;打开之前部署<a href="https://www.xxlaila.cn/2019/12/04/k8s-v1-14-prometheus%E4%B8%8Egrafana%E9%83%A8%E7%BD%B2/">prometheus与grafana部署</a>，里面有alertmanager的地址<code>http://alertmanager.xxlaila.cn/</code>，打开界面点击 <code>Status</code> 按钮我们可以查看到alertmanager的默认配置。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">global:</span><br><span class="line">  resolve_timeout: 5m</span><br><span class="line">  http_config: &#123;&#125;</span><br><span class="line">  smtp_hello: localhost</span><br><span class="line">  smtp_require_tls: <span class="literal">true</span></span><br><span class="line">  pagerduty_url: https://events.pagerduty.com/v2/enqueue</span><br><span class="line">  hipchat_api_url: https://api.hipchat.com/</span><br><span class="line">  opsgenie_api_url: https://api.opsgenie.com/</span><br><span class="line">  wechat_api_url: https://qyapi.weixin.qq.com/cgi-bin/</span><br><span class="line">  victorops_api_url: https://alert.victorops.com/integrations/generic/20131114/alert/</span><br><span class="line">route:</span><br><span class="line">  receiver: <span class="string">"null"</span></span><br><span class="line">  group_by:</span><br><span class="line">  - job</span><br><span class="line">  routes:</span><br><span class="line">  - receiver: <span class="string">"null"</span></span><br><span class="line">    match:</span><br><span class="line">      alertname: Watchdog</span><br><span class="line">  group_wait: 30s</span><br><span class="line">  group_interval: 5m</span><br><span class="line">  repeat_interval: 12h</span><br><span class="line">receivers:</span><br><span class="line">- name: <span class="string">"null"</span></span><br><span class="line">templates: []</span><br></pre></td></tr></table></figure><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这个默认配置是alertmanager目录下<code>alertmanager-secret.yaml</code>文件生成的，这个配置文件是通过base64加密过的，可以使用base64解密查看</p><ul><li><p>原alertmanager-secret.yaml</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">data:</span><br><span class="line">  alertmanager.yaml: Imdsb2JhbCI6CiAgInJlc29sdmVfdGltZW91dCI6ICI1bSIKInJlY2VpdmVycyI6Ci0gIm5hbWUiOiAibnVsbCIKInJvdXRlIjoKICAiZ3JvdXBfYnkiOgogIC0gImpvYiIKICAiZ3JvdXBfaW50ZXJ2YWwiOiAiNW0iCiAgImdyb3VwX3dhaXQiOiAiMzBzIgogICJyZWNlaXZlciI6ICJudWxsIgogICJyZXBlYXRfaW50ZXJ2YWwiOiAiMTJoIgogICJyb3V0ZXMiOgogIC0gIm1hdGNoIjoKICAgICAgImFsZXJ0bmFtZSI6ICJXYXRjaGRvZyIKICAgICJyZWNlaXZlciI6ICJudWxsIg==</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  name: alertmanager-main</span><br><span class="line">  namespace: monitoring</span><br><span class="line"><span class="built_in">type</span>: Opaque</span><br></pre></td></tr></table></figure></li><li><p>解密alertmanager-secret.yaml</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># echo "Imdsb2JhbCI6CiAgInJlc29sdmVfdGltZW91dCI6ICI1bSIKInJlY2VpdmVycyI6Ci0gIm5hbWUiOiAibnVsbCIKInJvdXRlIjoKICAiZ3JvdXBfYnkiOgogIC0gImpvYiIKICAiZ3JvdXBfaW50ZXJ2YWwiOiAiNW0iCiAgImdyb3VwX3dhaXQiOiAiMzBzIgogICJyZWNlaXZlciI6ICJudWxsIgogICJyZXBlYXRfaW50ZXJ2YWwiOiAiMTJoIgogICJyb3V0ZXMiOgogIC0gIm1hdGNoIjoKICAgICAgImFsZXJ0bmFtZSI6ICJXYXRjaGRvZyIKICAgICJyZWNlaXZlciI6ICJudWxsIg==" |base64 -d</span></span><br><span class="line"><span class="string">"global"</span>:</span><br><span class="line">  <span class="string">"resolve_timeout"</span>: <span class="string">"5m"</span></span><br><span class="line"><span class="string">"receivers"</span>:</span><br><span class="line">- <span class="string">"name"</span>: <span class="string">"null"</span></span><br><span class="line"><span class="string">"route"</span>:</span><br><span class="line">  <span class="string">"group_by"</span>:</span><br><span class="line">  - <span class="string">"job"</span></span><br><span class="line">  <span class="string">"group_interval"</span>: <span class="string">"5m"</span></span><br><span class="line">  <span class="string">"group_wait"</span>: <span class="string">"30s"</span></span><br><span class="line">  <span class="string">"receiver"</span>: <span class="string">"null"</span></span><br><span class="line">  <span class="string">"repeat_interval"</span>: <span class="string">"12h"</span></span><br><span class="line">  <span class="string">"routes"</span>:</span><br><span class="line">  - <span class="string">"match"</span>:</span><br><span class="line">      <span class="string">"alertname"</span>: <span class="string">"Watchdog"</span></span><br><span class="line">    <span class="string">"receiver"</span>: <span class="string">"null"</span></span><br></pre></td></tr></table></figure></li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;配置的结构差不多是一致的，内容嘛都是默认的。这里我们要实现自己的通知，就需要改改啦，这里我使用了企业微信来进行告警，<a href="https://www.xxlaila.cn/2019/08/20/zabbix%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E5%91%8A%E8%AD%A6/">企业微信</a>申请参考。这里我们要新建一个alertmanager.yaml 文件，这个文件名不能随便命名，可以看到alertmanager-secret.yaml是这么定义的。也可以在kubernetes的dashbord界面看到alertmanager 的安装参数也是这个。可以进入容器看到这个文件，默认路径在/etc/alertmanager/config/alertmanager.yaml。</p><h4 id="新建alertmanager-yaml"><a href="#新建alertmanager-yaml" class="headerlink" title="新建alertmanager.yaml"></a>新建alertmanager.yaml</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">global:</span><br><span class="line">  resolve_timeout: 5m</span><br><span class="line">  smtp_smarthost: <span class="string">'smtp.exmail.qq.com:465'</span></span><br><span class="line">  smtp_from: <span class="string">'admin@admin.com'</span></span><br><span class="line">  smtp_auth_username: <span class="string">'admin@admin.com'</span></span><br><span class="line">  smtp_auth_password: <span class="string">'123456'</span></span><br><span class="line">  smtp_require_tls: <span class="literal">true</span></span><br><span class="line">  hipchat_api_url: <span class="string">'https://hipchat.foobar.org/'</span></span><br><span class="line">  wechat_api_url: <span class="string">'https://qyapi.weixin.qq.com/cgi-bin/'</span> <span class="comment"># 企业微信地址</span></span><br><span class="line">  wechat_api_secret: <span class="string">'KJfj93rijk903240i--234jsnjkhf23sjkfjsfsd'</span> <span class="comment"># 企业微信Secret</span></span><br><span class="line">  wechat_api_corp_id: <span class="string">'wwa98457kdsnfk8'</span> <span class="comment"># 企业微信CorpId</span></span><br><span class="line">templates:</span><br><span class="line">- <span class="string">'*.tmpl'</span></span><br><span class="line">route:</span><br><span class="line">  group_by: [<span class="string">'alertname'</span>]</span><br><span class="line">  group_wait: 30s</span><br><span class="line">  group_interval: 5m</span><br><span class="line">  repeat_interval: 1h</span><br><span class="line">  receiver: default</span><br><span class="line">  routes:</span><br><span class="line">  - receiver: <span class="string">'wechat'</span></span><br><span class="line">    <span class="built_in">continue</span>: <span class="literal">true</span></span><br><span class="line">inhibit_rules:</span><br><span class="line">- source_match:</span><br><span class="line">receivers:</span><br><span class="line">- name: <span class="string">'default'</span></span><br><span class="line">  email_configs:</span><br><span class="line">  - to: <span class="string">'hahah@admin.com'</span></span><br><span class="line">    send_resolved: <span class="literal">true</span></span><br><span class="line">- name: <span class="string">'wechat'</span></span><br><span class="line">  wechat_configs:</span><br><span class="line">  - send_resolved: <span class="literal">true</span></span><br><span class="line">    corp_id: <span class="string">'wwa98457kdsnfk8'</span> <span class="comment"># 企业微信CorpId</span></span><br><span class="line">    to_user: <span class="string">'@all'</span> <span class="comment"># 接受人，都是all</span></span><br><span class="line">    to_party: <span class="string">''</span> <span class="comment"># 接收组的id</span></span><br><span class="line">    message: <span class="string">'&#123;&#123; template "wechat.default.message" . &#125;&#125;'</span> <span class="comment"># 发送消息的模版</span></span><br><span class="line">    agent_id: <span class="string">'1000021'</span> <span class="comment"># 企业微信自定义应用的id</span></span><br></pre></td></tr></table></figure><p><strong>参数</strong>：</p><ul><li>global: 全局配置。定义一些全局的公共参数，如全局的SMTP配置，企业微信，钉钉，这里配置了企业邮箱和企业微信。</li><li>templates: 模版。定义告警通知时的模板，如邮件模板、企业微信告警模版。</li><li>route: 告警路由。根据标签匹配，确定当前告警应该如何处理。</li><li>receivers: 接收人，可以是一个邮箱也可以是企业微信，也可以是一个webhook，这里我配置的企业微信的运维部门。是一个抽象的东西。</li><li>inhibit_rules: 抑制规则。设置合理的抑制规则可以减少垃圾告警的产生</li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这里要定义一个默认的接受方式<code>- name: &#39;default&#39;</code>，否则会出错误。错误如下:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">level=error ts=2019-12-06T08:36:25.005Z <span class="built_in">caller</span>=coordinator.go:124 component=configuration msg=<span class="string">"Loading configuration file failed"</span> file=/etc/alertmanager/config/alertmanager.yaml err=<span class="string">"root route must specify a default receiver"</span></span><br></pre></td></tr></table></figure><h4 id="tmpl模板的配置"><a href="#tmpl模板的配置" class="headerlink" title=".tmpl模板的配置"></a>.tmpl模板的配置</h4><ul><li>wechat.default.message.tmpl<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat &gt; wechat.default.message.tmpl &lt;&lt;EOF</span></span><br><span class="line">&#123;&#123; define <span class="string">"wechat.default.message"</span> &#125;&#125;</span><br><span class="line">&#123;&#123;- <span class="keyword">if</span> gt (len .Alerts.Firing) 0 -&#125;&#125;</span><br><span class="line">&#123;&#123;- range <span class="variable">$index</span>, <span class="variable">$alert</span> := .Alerts -&#125;&#125;</span><br><span class="line">&#123;&#123;- <span class="keyword">if</span> eq <span class="variable">$index</span> 0 -&#125;&#125;</span><br><span class="line">告警类型: &#123;&#123; <span class="variable">$alert</span>.Labels.alertname &#125;&#125;</span><br><span class="line">告警级别: &#123;&#123; <span class="variable">$alert</span>.Labels.severity &#125;&#125;</span><br><span class="line"></span><br><span class="line">=====================</span><br><span class="line">&#123;&#123;- end &#125;&#125;</span><br><span class="line">===告警详情===</span><br><span class="line">告警详情: &#123;&#123; <span class="variable">$alert</span>.Annotations.message &#125;&#125;</span><br><span class="line">故障时间: &#123;&#123; <span class="variable">$alert</span>.StartsAt.Format <span class="string">"2019-11-06 17:01:01"</span> &#125;&#125;</span><br><span class="line">===参考信息===</span><br><span class="line">&#123;&#123; <span class="keyword">if</span> gt (len <span class="variable">$alert</span>.Labels.instance) 0 -&#125;&#125;故障实例ip: &#123;&#123; <span class="variable">$alert</span>.Labels.instance &#125;&#125;;&#123;&#123;- end -&#125;&#125;</span><br><span class="line">&#123;&#123;- <span class="keyword">if</span> gt (len <span class="variable">$alert</span>.Labels.namespace) 0 -&#125;&#125;故障实例所在namespace: &#123;&#123; <span class="variable">$alert</span>.Labels.namespace &#125;&#125;;&#123;&#123;- end -&#125;&#125;</span><br><span class="line">&#123;&#123;- <span class="keyword">if</span> gt (len <span class="variable">$alert</span>.Labels.node) 0 -&#125;&#125;故障物理机ip: &#123;&#123; <span class="variable">$alert</span>.Labels.node &#125;&#125;;&#123;&#123;- end -&#125;&#125;</span><br><span class="line">&#123;&#123;- <span class="keyword">if</span> gt (len <span class="variable">$alert</span>.Labels.pod_name) 0 -&#125;&#125;故障pod名称: &#123;&#123; <span class="variable">$alert</span>.Labels.pod_name &#125;&#125;&#123;&#123;- end &#125;&#125;</span><br><span class="line">=====================</span><br><span class="line">&#123;&#123;- end &#125;&#125;</span><br><span class="line">&#123;&#123;- end &#125;&#125;</span><br><span class="line"></span><br><span class="line">&#123;&#123;- <span class="keyword">if</span> gt (len .Alerts.Resolved) 0 -&#125;&#125;</span><br><span class="line">&#123;&#123;- range <span class="variable">$index</span>, <span class="variable">$alert</span> := .Alerts -&#125;&#125;</span><br><span class="line">&#123;&#123;- <span class="keyword">if</span> eq <span class="variable">$index</span> 0 -&#125;&#125;</span><br><span class="line">告警类型: &#123;&#123; <span class="variable">$alert</span>.Labels.alertname &#125;&#125;</span><br><span class="line">告警级别: &#123;&#123; <span class="variable">$alert</span>.Labels.severity &#125;&#125;</span><br><span class="line"></span><br><span class="line">=====================</span><br><span class="line">&#123;&#123;- end &#125;&#125;</span><br><span class="line">===告警详情===</span><br><span class="line">告警详情: &#123;&#123; <span class="variable">$alert</span>.Annotations.message &#125;&#125;</span><br><span class="line">故障时间: &#123;&#123; <span class="variable">$alert</span>.StartsAt.Format <span class="string">"2019-11-06 17:01:01"</span> &#125;&#125;</span><br><span class="line">恢复时间: &#123;&#123; <span class="variable">$alert</span>.EndsAt.Format <span class="string">"2019-11-06 17:01:01"</span> &#125;&#125;</span><br><span class="line">===参考信息===</span><br><span class="line">&#123;&#123; <span class="keyword">if</span> gt (len <span class="variable">$alert</span>.Labels.instance) 0 -&#125;&#125;故障实例ip: &#123;&#123; <span class="variable">$alert</span>.Labels.instance &#125;&#125;;&#123;&#123;- end -&#125;&#125;</span><br><span class="line">&#123;&#123;- <span class="keyword">if</span> gt (len <span class="variable">$alert</span>.Labels.namespace) 0 -&#125;&#125;故障实例所在namespace: &#123;&#123; <span class="variable">$alert</span>.Labels.namespace &#125;&#125;;&#123;&#123;- end -&#125;&#125;</span><br><span class="line">&#123;&#123;- <span class="keyword">if</span> gt (len <span class="variable">$alert</span>.Labels.node) 0 -&#125;&#125;故障物理机ip: &#123;&#123; <span class="variable">$alert</span>.Labels.node &#125;&#125;;&#123;&#123;- end -&#125;&#125;</span><br><span class="line">&#123;&#123;- <span class="keyword">if</span> gt (len <span class="variable">$alert</span>.Labels.pod_name) 0 -&#125;&#125;故障pod名称: &#123;&#123; <span class="variable">$alert</span>.Labels.pod_name &#125;&#125;;&#123;&#123;- end &#125;&#125;</span><br><span class="line">=====================</span><br><span class="line">&#123;&#123;- end &#125;&#125;</span><br><span class="line">&#123;&#123;- end &#125;&#125;</span><br><span class="line">&#123;&#123;- end &#125;&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></li></ul><h3 id="建立alertmanager-main"><a href="#建立alertmanager-main" class="headerlink" title="建立alertmanager-main"></a>建立alertmanager-main</h3><h4 id="删除原有的配置项"><a href="#删除原有的配置项" class="headerlink" title="删除原有的配置项"></a>删除原有的配置项</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl delete secret alertmanager-main -n monitoring</span></span><br></pre></td></tr></table></figure><h4 id="部署alertmanager-secret"><a href="#部署alertmanager-secret" class="headerlink" title="部署alertmanager secret"></a>部署alertmanager secret</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;重新部署alertmanager secret有两种方式，第一种是把建立好的alertmanager.yaml 通过base64加密以后覆盖之前文件的base64内容，wechat.default.message.tmpl模版文件也是一样。整体格式如下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat alertmanager-secret.yaml </span></span><br><span class="line">apiVersion: v1</span><br><span class="line">data:</span><br><span class="line">  alertmanager.yaml: bash64</span><br><span class="line">  template_1.tmpl: bash64</span><br><span class="line">  template_2.tmpl: bash64</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  name: alertmanager-main</span><br><span class="line">  namespace: monitoring</span><br><span class="line"><span class="built_in">type</span>: Opaque</span><br></pre></td></tr></table></figure><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这种创建比较麻烦，每次修改文件都要去生成一次。不方便。所以可以使用以下方式，简单快捷。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl create secret generic alertmanager-main --from-file=alertmanager.yaml,wechat.default.message.tmpl -n monitoring</span></span><br></pre></td></tr></table></figure><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;部署完成以后，Secret 对象将会挂载到 AlertManager 对象创建的 AlertManager Pod 中去。等一小会就企业微信就可以收到告警信息</p><h3 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h3><h4 id="alertmanager-web界面的config信息会发生变化"><a href="#alertmanager-web界面的config信息会发生变化" class="headerlink" title="alertmanager web界面的config信息会发生变化"></a>alertmanager web界面的config信息会发生变化</h4><p><img src="https://img.xxlaila.cn/1575624600073.jpg" alt="img"><br><img src="https://img.xxlaila.cn/1575624706636.jpg" alt="img"></p><h4 id="企业微信"><a href="#企业微信" class="headerlink" title="企业微信"></a>企业微信</h4><p><img src="https://img.xxlaila.cn/1575624815597.jpg" alt="img"></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Thu Feb 20 2020 16:22:06 GMT+0800 (China Standard Time) --&gt;&lt;h3 id=&quot;介绍&quot;&gt;&lt;a href=&quot;#介绍&quot; class=&quot;headerlink&quot; title=&quot;介绍&quot;&gt;&lt;/a&gt;介绍&lt;/h3&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 前篇文章做了kubernetes 的 监控，基于&lt;a href=&quot;https://www.xxlaila.cn/2019/12/04/k8s-v1-14-prometheus%E4%B8%8Egrafana%E9%83%A8%E7%BD%B2/&quot;&gt;prometheus与grafana部署&lt;/a&gt;，监控是做好了，但是还缺乏告警机制，没有告警机制监控就白做了，prometheus的告警就是alertmanager来做。
    
    </summary>
    
      <category term="监控" scheme="https://www.xxlaila.cn/categories/%E7%9B%91%E6%8E%A7/"/>
    
    
      <category term="alertmanager" scheme="https://www.xxlaila.cn/tags/alertmanager/"/>
    
  </entry>
  
  <entry>
    <title>k8s v1.14 prometheus与grafana部署</title>
    <link href="https://www.xxlaila.cn/2019/12/04/k8s-v1-14-prometheus%E4%B8%8Egrafana%E9%83%A8%E7%BD%B2/"/>
    <id>https://www.xxlaila.cn/2019/12/04/k8s-v1-14-prometheus与grafana部署/</id>
    <published>2019-12-04T09:55:44.000Z</published>
    <updated>2019-12-11T05:50:28.208Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Thu Feb 20 2020 16:22:06 GMT+0800 (China Standard Time) --><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;kube-prometheus是读取Metrcs、etcd、api的其中数据。<a id="more"></a></p><h4 id="查看etcd的metrics输出信息"><a href="#查看etcd的metrics输出信息" class="headerlink" title="查看etcd的metrics输出信息"></a>查看etcd的metrics输出信息</h4><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># curl --cacert <span class="regexp">/etc/</span>kubernetes<span class="regexp">/ssl/</span>ca.pem --cert <span class="regexp">/etc/</span>etcd<span class="regexp">/ssl/</span>etcd.pem --key <span class="regexp">/etc/</span>etcd<span class="regexp">/ssl/</span>etcd-key.pem https:<span class="comment">//172.21.17.30:2379/metrics</span></span><br></pre></td></tr></table></figure><h4 id="查看kube-apiserver的metrics信息"><a href="#查看kube-apiserver的metrics信息" class="headerlink" title="查看kube-apiserver的metrics信息"></a>查看kube-apiserver的metrics信息</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl get --raw /metrics</span></span><br></pre></td></tr></table></figure><h4 id="下载官方的yaml文件"><a href="#下载官方的yaml文件" class="headerlink" title="下载官方的yaml文件"></a>下载官方的yaml文件</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># git clone https://github.com/coreos/kube-prometheus</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># cd kube-prometheus/manifests</span></span><br><span class="line"><span class="comment"># mkdir -p operator node-exporter alertmanager grafana kube-state-metrics prometheus serviceMonitor adapter</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># mv *-serviceMonitor* serviceMonitor/</span></span><br><span class="line"><span class="comment"># mv grafana-* grafana/</span></span><br><span class="line"><span class="comment"># mv kube-state-metrics-* kube-state-metrics/</span></span><br><span class="line"><span class="comment"># mv alertmanager-* alertmanager/</span></span><br><span class="line"><span class="comment"># mv node-exporter-* node-exporter/</span></span><br><span class="line"><span class="comment"># mv prometheus-adapter* adapter/</span></span><br><span class="line"><span class="comment"># mv prometheus-* prometheus/</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># cd setup/</span></span><br><span class="line"><span class="comment"># mv prometheus-operator* ../operator/</span></span><br><span class="line"><span class="comment"># mv 0namespace-namespace.yaml ../</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># cd ..</span></span><br><span class="line"><span class="comment"># ls -ltrh</span></span><br><span class="line">-rw-r--r-- 1 root root   60 Dec  3 17:45 0namespace-namespace.yaml</span><br><span class="line">drwxr-xr-x 2 root root  219 Dec  3 17:46 grafana</span><br><span class="line">drwxr-xr-x 2 root root  305 Dec  3 17:46 kube-state-metrics</span><br><span class="line">drwxr-xr-x 2 root root  200 Dec  3 17:46 node-exporter</span><br><span class="line">drwxr-xr-x 2 root root 4.0K Dec  3 17:47 operator</span><br><span class="line">drwxr-xr-x 2 root root  149 Dec  4 13:40 alertmanager</span><br><span class="line">drwxr-xr-x 2 root root 4.0K Dec  5 09:56 prometheus</span><br><span class="line">drwxr-xr-x 2 root root 4.0K Dec  5 10:01 adapter</span><br><span class="line">drwxr-xr-x 2 root root 4.0K Dec  5 11:55 serviceMonitor</span><br></pre></td></tr></table></figure><h3 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;部署前需要修改文件；</p><h4 id="创建监控etcd-secret"><a href="#创建监控etcd-secret" class="headerlink" title="创建监控etcd secret"></a>创建监控etcd secret</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;etcd 监控要用到证书同时需要修改prometheus-prometheus.yaml。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl -n monitoring create secret generic etcd-certs --from-file=/etc/kubernetes/ssl/ca.pem --from-file=etcd-key.pem --from-file=etcd.pem</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># kubectl get secret -n monitoring</span></span><br><span class="line">etcd-certs                        Opaque                                3      5d15h</span><br></pre></td></tr></table></figure><h4 id="修改prometheus-prometheus-yaml"><a href="#修改prometheus-prometheus-yaml" class="headerlink" title="修改prometheus-prometheus.yaml"></a>修改prometheus-prometheus.yaml</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cd prometheus/</span></span><br><span class="line"><span class="comment"># vim prometheus-prometheus.yaml</span></span><br><span class="line">apiVersion: monitoring.coreos.com/v1</span><br><span class="line">kind: Prometheus</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    prometheus: k8s</span><br><span class="line">  name: k8s</span><br><span class="line">  namespace: monitoring</span><br><span class="line">spec:</span><br><span class="line">  alerting:</span><br><span class="line">    alertmanagers:</span><br><span class="line">    - name: alertmanager-main</span><br><span class="line">      namespace: monitoring</span><br><span class="line">      port: web</span><br><span class="line">  baseImage: quay.io/prometheus/prometheus</span><br><span class="line">  nodeSelector:</span><br><span class="line">    kubernetes.io/os: linux</span><br><span class="line">  podMonitorSelector: &#123;&#125;</span><br><span class="line">  replicas: 2</span><br><span class="line">  <span class="comment"># 添加etcd 证书</span></span><br><span class="line">  secrets:</span><br><span class="line">  - etcd-certs</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      memory: 400Mi</span><br><span class="line">  <span class="comment"># 设置数据保留天数</span></span><br><span class="line">  retention: 7d</span><br><span class="line">  <span class="comment"># 创建外部存储pvc</span></span><br><span class="line">  storage:</span><br><span class="line">    volumeClaimTemplate:</span><br><span class="line">      spec:</span><br><span class="line">        accessModes:</span><br><span class="line">        - ReadWriteOnce</span><br><span class="line">        metadata:</span><br><span class="line">          annotations:</span><br><span class="line">            storageclass.kubernetes.io/is-default-class: <span class="literal">true</span></span><br><span class="line">          labels:</span><br><span class="line">            prometheus: prometheus-data-pvc</span><br><span class="line">        resources:</span><br><span class="line">          requests:</span><br><span class="line">            storage: 25Gi</span><br><span class="line">  ruleSelector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      prometheus: k8s</span><br><span class="line">      role: alert-rules</span><br><span class="line">  securityContext:</span><br><span class="line">    fsGroup: 2000</span><br><span class="line">    runAsNonRoot: <span class="literal">true</span></span><br><span class="line">    runAsUser: 1000</span><br><span class="line">  serviceAccountName: prometheus-k8s</span><br><span class="line">  serviceMonitorNamespaceSelector: &#123;&#125;</span><br><span class="line">  serviceMonitorSelector: &#123;&#125;</span><br><span class="line">  version: v2.11.0</span><br></pre></td></tr></table></figure><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>storageclass.kubernetes.io/is-default-class: true</code> 是设置的默认动态存储，可以参考<a href="https://www.xxlaila.cn/2019/08/12/kube-nfs-%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8/">kube-nfs-动态存储</a></p><h4 id="部署应用"><a href="#部署应用" class="headerlink" title="部署应用"></a>部署应用</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;部署前吧adapter 目录下面的 <code>prometheus-adapter-apiService.yaml</code> 重命名，因为前面安装了metrics。如果这里在覆盖安装，就会导致<code>metrics.k8s.io</code>报错。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># kubectl apply -f 0namespace-namespace.yaml</span></span><br><span class="line"><span class="keyword">namespace</span>/monitoring created</span><br><span class="line"></span><br><span class="line"><span class="meta"># kubectl apply -f operator/</span></span><br><span class="line"><span class="meta"># kubectl -n monitoring get pod|grep operator</span></span><br><span class="line">prometheus-<span class="keyword">operator</span><span class="number">-548</span>c6dc45c-vz6l6   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">40</span>h</span><br><span class="line"></span><br><span class="line"><span class="meta"># kubectl apply -f adapter/</span></span><br><span class="line"><span class="meta"># kubectl apply -f alertmanager/</span></span><br><span class="line"><span class="meta"># kubectl apply -f node-exporter/</span></span><br><span class="line"><span class="meta"># kubectl apply -f kube-state-metrics/</span></span><br><span class="line"><span class="meta"># kubectl apply -f grafana/</span></span><br><span class="line"><span class="meta"># kubectl apply -f prometheus/</span></span><br><span class="line"><span class="meta"># kubectl apply -f serviceMonitor/</span></span><br></pre></td></tr></table></figure><h4 id="查看部署状态"><a href="#查看部署状态" class="headerlink" title="查看部署状态"></a>查看部署状态</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl get all -n monitoring</span></span><br><span class="line">NAME                                       READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod/alertmanager-main-0                    2/2     Running   0          40h</span><br><span class="line">pod/alertmanager-main-1                    2/2     Running   0          40h</span><br><span class="line">pod/alertmanager-main-2                    2/2     Running   0          40h</span><br><span class="line">pod/grafana-5db74b88f4-7mt8c               1/1     Running   0          40h</span><br><span class="line">pod/kube-state-metrics-54f98c4687-mz5lq    3/3     Running   0          18h</span><br><span class="line">pod/node-exporter-hb66c                    2/2     Running   0          40h</span><br><span class="line">pod/node-exporter-l2s8g                    2/2     Running   0          40h</span><br><span class="line">pod/node-exporter-sjbmg                    2/2     Running   0          40h</span><br><span class="line">pod/node-exporter-vw87m                    2/2     Running   0          40h</span><br><span class="line">pod/node-exporter-zr8fk                    2/2     Running   0          40h</span><br><span class="line">pod/node-exporter-zxcwl                    2/2     Running   0          40h</span><br><span class="line">pod/prometheus-adapter-8667948d79-tcz47    1/1     Running   0          18h</span><br><span class="line">pod/prometheus-k8s-0                       3/3     Running   1          20h</span><br><span class="line">pod/prometheus-k8s-1                       3/3     Running   1          20h</span><br><span class="line">pod/prometheus-operator-548c6dc45c-vz6l6   1/1     Running   0          40h</span><br><span class="line"></span><br><span class="line">NAME                            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                      AGE</span><br><span class="line">service/alertmanager-main       ClusterIP   10.254.101.249   &lt;none&gt;        9093/TCP                     40h</span><br><span class="line">service/alertmanager-operated   ClusterIP   None             &lt;none&gt;        9093/TCP,9094/TCP,9094/UDP   40h</span><br><span class="line">service/etcd                    ClusterIP   None             &lt;none&gt;        2379/TCP                     17h</span><br><span class="line">service/grafana                 ClusterIP   10.254.214.6     &lt;none&gt;        3000/TCP                     40h</span><br><span class="line">service/kube-state-metrics      ClusterIP   None             &lt;none&gt;        8443/TCP,9443/TCP            18h</span><br><span class="line">service/node-exporter           ClusterIP   None             &lt;none&gt;        9100/TCP                     40h</span><br><span class="line">service/prometheus-adapter      ClusterIP   10.254.60.49     &lt;none&gt;        443/TCP                      18h</span><br><span class="line">service/prometheus-k8s          ClusterIP   10.254.41.152    &lt;none&gt;        9090/TCP                     40h</span><br><span class="line">service/prometheus-operated     ClusterIP   None             &lt;none&gt;        9090/TCP                     20h</span><br><span class="line">service/prometheus-operator     ClusterIP   None             &lt;none&gt;        8080/TCP                     40h</span><br><span class="line"></span><br><span class="line">NAME                           DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE</span><br><span class="line">daemonset.apps/node-exporter   6         6         6       6            6           kubernetes.io/os=linux   40h</span><br><span class="line"></span><br><span class="line">NAME                                  READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">deployment.apps/grafana               1/1     1            1           40h</span><br><span class="line">deployment.apps/kube-state-metrics    1/1     1            1           18h</span><br><span class="line">deployment.apps/prometheus-adapter    1/1     1            1           18h</span><br><span class="line">deployment.apps/prometheus-operator   1/1     1            1           40h</span><br><span class="line"></span><br><span class="line">NAME                                             DESIRED   CURRENT   READY   AGE</span><br><span class="line">replicaset.apps/grafana-5db74b88f4               1         1         1       40h</span><br><span class="line">replicaset.apps/kube-state-metrics-54f98c4687    1         1         1       18h</span><br><span class="line">replicaset.apps/prometheus-adapter-8667948d79    1         1         1       18h</span><br><span class="line">replicaset.apps/prometheus-operator-548c6dc45c   1         1         1       40h</span><br><span class="line"></span><br><span class="line">NAME                                 READY   AGE</span><br><span class="line">statefulset.apps/alertmanager-main   3/3     40h</span><br><span class="line">statefulset.apps/prometheus-k8s      2/2     20h</span><br></pre></td></tr></table></figure><h4 id="配置ingress"><a href="#配置ingress" class="headerlink" title="配置ingress"></a>配置ingress</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat &gt;ingress-monitor.yaml &lt;&lt;EOF </span></span><br><span class="line">---</span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: prometheus-web-ui</span><br><span class="line">  namespace: monitoring</span><br><span class="line">  annotations:</span><br><span class="line">    kubernetes.io/ingress.class: traefik</span><br><span class="line">spec:</span><br><span class="line">  rules:</span><br><span class="line">  - host: prometheus.xxlaila.cn</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - path: /</span><br><span class="line">        backend:</span><br><span class="line">          serviceName: prometheus-k8s</span><br><span class="line">          servicePort: 9090</span><br><span class="line">---</span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: grafana-web-ui</span><br><span class="line">  namespace: monitoring</span><br><span class="line">  annotations:</span><br><span class="line">    kubernetes.io/ingress.class: traefik</span><br><span class="line">spec:</span><br><span class="line">  rules:</span><br><span class="line">  - host: grafana.xxlaila.cn</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - path: /</span><br><span class="line">        backend:</span><br><span class="line">          serviceName: grafana</span><br><span class="line">          servicePort: 3000</span><br><span class="line">---</span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: alertmanager-web-ui</span><br><span class="line">  namespace: monitoring</span><br><span class="line">  annotations:</span><br><span class="line">    kubernetes.io/ingress.class: traefik</span><br><span class="line">spec:</span><br><span class="line">  rules:</span><br><span class="line">  - host: alertmanager.xxlaila.cn</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - path: /</span><br><span class="line">        backend:</span><br><span class="line">          serviceName: alertmanager-main</span><br><span class="line">          servicePort: 9093</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="comment"># kubectl apply -f ingress-monitor.yaml</span></span><br></pre></td></tr></table></figure><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 在浏览器打开域名即可访问</p><h3 id="常用应用监控"><a href="#常用应用监控" class="headerlink" title="常用应用监控"></a>常用应用监控</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; kubernetes 自身常见的监控有kube-apiserver、kube-scheduler、kube-controller-manager、etcd。node节点常见的有kubelet、kube-proxy。在serviceMonitor目录下面默认的文件只能满足kube-apiserver、kubelet两个，其他的修改单独修改文件才能监控。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 上面阐述的是集群是二进制方式安装，而不是以pod形式进行安装。</p><h4 id="kube-scheduler监控"><a href="#kube-scheduler监控" class="headerlink" title="kube-scheduler监控"></a>kube-scheduler监控</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;kube-scheduler的service、endpoints不在kubernetes集群内，可以通过<code>kubectl get ep -n kube-system</code> 进行查看，修改 <code>prometheus-serviceMonitorKubeScheduler.yaml</code>，在该文件添加如下内容或者新起一个文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat &gt;&gt; prometheus-serviceMonitorKubeScheduler.yaml &lt;&lt;EOF</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kube-scheduler</span><br><span class="line">  name: kube-scheduler</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  clusterIP: None</span><br><span class="line">  ports:</span><br><span class="line">  - name: http-metrics</span><br><span class="line">    port: 10251</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 10251</span><br><span class="line">  sessionAffinity: None</span><br><span class="line">  <span class="built_in">type</span>: ClusterIP</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Endpoints</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kube-scheduler</span><br><span class="line">  name: kube-scheduler</span><br><span class="line">  namespace: kube-system</span><br><span class="line">subsets:</span><br><span class="line">- addresses:</span><br><span class="line">  - ip: 172.21.17.30</span><br><span class="line">  - ip: 172.21.17.31</span><br><span class="line">  - ip: 172.21.16.110</span><br><span class="line">  ports:</span><br><span class="line">  - name: http-metrics</span><br><span class="line">    port: 10251</span><br><span class="line">    protocol: TCP</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="comment"># kubectl apply -f prometheus-serviceMonitorKubeScheduler.yaml</span></span><br></pre></td></tr></table></figure><h4 id="kube-controller-manager-监控"><a href="#kube-controller-manager-监控" class="headerlink" title="kube-controller-manager 监控"></a>kube-controller-manager 监控</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;kube-controller-manager修改，因为kubernetes 集群是采用ssl证书安装，默认的kube-controller-manager是没有使用ssl加密的，所以这里需要使用ssl证书，及https，否则不能监控。就会提示什么403、x509、400错误。</p><ul><li><p>prometheus-serviceMonitorKubeControllerManager.yaml 修改</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat prometheus-serviceMonitorKubeControllerManager.yaml</span></span><br><span class="line">apiVersion: monitoring.coreos.com/v1</span><br><span class="line">kind: ServiceMonitor</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kube-controller-manager</span><br><span class="line">  name: kube-controller-manager</span><br><span class="line">  namespace: monitoring</span><br><span class="line">spec:</span><br><span class="line">  endpoints:</span><br><span class="line">  - bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token</span><br><span class="line">    interval: 30s</span><br><span class="line">    port: https-metrics</span><br><span class="line">    scheme: https</span><br><span class="line">    tlsConfig:</span><br><span class="line">      insecureSkipVerify: <span class="literal">true</span></span><br><span class="line">    metricRelabelings:</span><br><span class="line">    - action: drop</span><br><span class="line">      regex: etcd_(debugging|disk|request|server).*</span><br><span class="line">      sourceLabels:</span><br><span class="line">      - __name__</span><br><span class="line">  jobLabel: k8s-app</span><br><span class="line">  namespaceSelector:</span><br><span class="line">    matchNames:</span><br><span class="line">    - kube-system</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: kube-controller-manager</span><br></pre></td></tr></table></figure></li><li><p>新建kube-controller-manager-service.yaml</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat &gt;kube-controller-manager-service.yaml &lt;&lt;EOF</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kube-controller-manager</span><br><span class="line">  name: kube-controller-manager</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  clusterIP: None</span><br><span class="line">  ports:</span><br><span class="line">  - name: https-metrics</span><br><span class="line">    port: 10252</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 10252</span><br><span class="line">  sessionAffinity: None</span><br><span class="line">  <span class="built_in">type</span>: ClusterIP</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Endpoints</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kube-controller-manager</span><br><span class="line">  name: kube-controller-manager</span><br><span class="line">  namespace: kube-system</span><br><span class="line">subsets:</span><br><span class="line">- addresses:</span><br><span class="line">  - ip: 172.21.17.30</span><br><span class="line">  - ip: 172.21.17.31</span><br><span class="line">  - ip: 172.21.16.110</span><br><span class="line">  ports:</span><br><span class="line">  - name: https-metrics</span><br><span class="line">    port: 10252</span><br><span class="line">    protocol: TCP</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></li><li><p>执行创建</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl apply -f prometheus-serviceMonitorKubeControllerManager.yaml</span></span><br><span class="line"><span class="comment"># kubectl apply -f kube-controller-manager-service.yaml</span></span><br></pre></td></tr></table></figure></li></ul><h4 id="etcd-监控"><a href="#etcd-监控" class="headerlink" title="etcd 监控"></a>etcd 监控</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; etcd 不在k8s集群内部所以要创建Endpoints、Service</p><ul><li>prometheus-serviceMonitoretcd.yaml<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat &gt; prometheus-serviceMonitoretcd.yaml&lt;&lt;EOF</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: etcd</span><br><span class="line">  name: etcd</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  clusterIP: None</span><br><span class="line">  ports:</span><br><span class="line">  - name: https-metrics</span><br><span class="line">    port: 2379</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 2379</span><br><span class="line">  sessionAffinity: None</span><br><span class="line">  <span class="built_in">type</span>: ClusterIP</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Endpoints</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: etcd</span><br><span class="line">  name: etcd</span><br><span class="line">  namespace: kube-system</span><br><span class="line">subsets:</span><br><span class="line">- addresses:</span><br><span class="line">  - ip: 172.21.17.30</span><br><span class="line">  - ip: 172.21.17.31</span><br><span class="line">  - ip: 172.21.16.110</span><br><span class="line">  ports:</span><br><span class="line">  - name: https-metrics</span><br><span class="line">    port: 2379</span><br><span class="line">    protocol: TCP</span><br><span class="line">---</span><br><span class="line">apiVersion: monitoring.coreos.com/v1</span><br><span class="line">kind: ServiceMonitor</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: etcd</span><br><span class="line">  name: etcd</span><br><span class="line">  namespace: monitoring</span><br><span class="line">spec:</span><br><span class="line">  endpoints:</span><br><span class="line">  - interval: 10s</span><br><span class="line">    port: https-metrics</span><br><span class="line">    scheme: https</span><br><span class="line">    tlsConfig:</span><br><span class="line">      caFile: /etc/prometheus/secrets/etcd-certs/ca.pem</span><br><span class="line">      certFile: /etc/prometheus/secrets/etcd-certs/etcd.pem</span><br><span class="line">      keyFile: /etc/prometheus/secrets/etcd-certs/etcd-key.pem</span><br><span class="line">      insecureSkipVerify: <span class="literal">true</span></span><br><span class="line">  namespaceSelector:</span><br><span class="line">    matchNames:</span><br><span class="line">    - kube-system</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: etcd</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="comment"># kubectl apply -f prometheus-serviceMonitoretcd.yaml</span></span><br></pre></td></tr></table></figure></li></ul><h4 id="kube-proxy-监控"><a href="#kube-proxy-监控" class="headerlink" title="kube-proxy 监控"></a>kube-proxy 监控</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; kube-proxy的metrics收集端口为10249，可以查看kub-proxy的安装文档。使用的是http方式，不需要ssl加密</p><ul><li><p>新建 kube-proxy.yaml</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat &gt;  kube-proxy.yaml &lt;&lt;EOF</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kube-proxy</span><br><span class="line">  name: kube-proxy</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  clusterIP: None</span><br><span class="line">  ports:</span><br><span class="line">  - name: http-metrics</span><br><span class="line">    port: 10249</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 10249</span><br><span class="line">  sessionAffinity: None</span><br><span class="line">  <span class="built_in">type</span>: ClusterIP</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Endpoints</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kube-proxy</span><br><span class="line">  name: kube-proxy</span><br><span class="line">  namespace: kube-system</span><br><span class="line">subsets:</span><br><span class="line">- addresses:</span><br><span class="line">  - ip: 172.21.16.204</span><br><span class="line">  - ip: 172.21.16.231</span><br><span class="line">  - ip: ……</span><br><span class="line">  ports:</span><br><span class="line">  - name: http-metrics</span><br><span class="line">    port: 10249</span><br><span class="line">    protocol: TCP</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></li><li><p>新建 prometheus-serviceMonitorProxy.yaml</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat &gt; prometheus-serviceMonitorProxy.yaml &lt;&lt;EOF</span></span><br><span class="line">---</span><br><span class="line">apiVersion: monitoring.coreos.com/v1</span><br><span class="line">kind: ServiceMonitor</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kube-proxy</span><br><span class="line">  name: kube-proxy</span><br><span class="line">  namespace: monitoring</span><br><span class="line">spec:</span><br><span class="line">  endpoints:</span><br><span class="line">  - interval: 30s</span><br><span class="line">    port: http-metrics</span><br><span class="line">  jobLabel: k8s-app</span><br><span class="line">  namespaceSelector:</span><br><span class="line">    matchNames:</span><br><span class="line">    - kube-system</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: kube-proxy</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></li><li><p>执行创建</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl apply -f prometheus-serviceMonitorProxy.yaml</span></span><br><span class="line"><span class="comment"># kubectl apply -f kube-proxy.yaml</span></span><br></pre></td></tr></table></figure></li></ul><h4 id="traefik-监控"><a href="#traefik-监控" class="headerlink" title="traefik 监控"></a>traefik 监控</h4><ul><li>新建prometheus-serviceMonitorTraefix.yaml<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat &gt; prometheus-serviceMonitorTraefix.yaml &lt;&lt;EOF</span></span><br><span class="line">---</span><br><span class="line">apiVersion: monitoring.coreos.com/v1</span><br><span class="line">kind: ServiceMonitor</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: traefik-ingress</span><br><span class="line">  name: traefik-ingress</span><br><span class="line">  namespace: monitoring</span><br><span class="line">spec:</span><br><span class="line">  jobLabel: k8s-app</span><br><span class="line">  endpoints:</span><br><span class="line">  - port: admin  <span class="comment">#---设置为traefik 8080端口名称 admin</span></span><br><span class="line">    interval: 30s</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: traefik-ingress</span><br><span class="line">  namespaceSelector:</span><br><span class="line">    matchNames:</span><br><span class="line">    - kube-system</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="comment"># kubectl apply -f prometheus-serviceMonitorTraefix.yaml</span></span><br></pre></td></tr></table></figure></li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;前提是能打开traefix 的metrics页面，跟着我前面的文档安装，默认是开启的。</p><h3 id="grafana-修改"><a href="#grafana-修改" class="headerlink" title="grafana 修改"></a>grafana 修改</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;grafana默认安装后，需要安装插件，否则饼状图无法显示。而且我们还需要倒入官方的一些dashbord 模版，默认grafana安装如果pod 重建之后什么都没有了，这时候我们需要建立一个pvc，吧数据保存到磁盘里面，即使grafana重建之后数据还在。不受任何影响。</p><h4 id="新建grafana-pvc-yaml"><a href="#新建grafana-pvc-yaml" class="headerlink" title="新建grafana-pvc.yaml"></a>新建grafana-pvc.yaml</h4><ul><li>grafana-pvc.yaml<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat &gt; grafana-pvc.yaml &lt;&lt;EOF</span></span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: grafana-pvc</span><br><span class="line">  namespace: monitoring</span><br><span class="line">spec:</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteMany</span><br><span class="line">  storageClassName: xxlaila-nfs-storage</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 5Gi</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="comment"># kubectl apply -f grafana-pvc.yaml</span></span><br></pre></td></tr></table></figure></li></ul><h4 id="修改granfana-deployment-yaml"><a href="#修改granfana-deployment-yaml" class="headerlink" title="修改granfana-deployment.yaml"></a>修改granfana-deployment.yaml</h4><ul><li>granfana-deployment.yaml<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 修改</span></span><br><span class="line">    volumes:</span><br><span class="line">      <span class="comment">#- emptyDir: &#123;&#125;</span></span><br><span class="line">      - name: grafana-storage</span><br><span class="line">        persistentVolumeClaim:</span><br><span class="line">          claimName: grafana-pvc</span><br><span class="line">      - name: grafana-datasources</span><br><span class="line"><span class="comment"># 新增</span></span><br><span class="line">        - mountPath: /grafana-dashboard-definitions/0/grafana-dashboard-k8s-traefik-ingress</span><br><span class="line">          name: grafana-dashboard-k8s-traefik-ingress</span><br><span class="line">          readOnly: <span class="literal">false</span></span><br><span class="line">        - mountPath: /grafana-dashboard-definitions/0/grafana-dashboard-k8s-etcd-clusters-as-service</span><br><span class="line">          name: grafana-dashboard-k8s-etcd-clusters-as-service</span><br><span class="line">          readOnly: <span class="literal">false</span></span><br><span class="line">        - mountPath: /grafana-dashboard-definitions/0/grafana-dashboard-k8s-etcd-cluster-as-pod</span><br><span class="line">          name: grafana-dashboard-k8s-etcd-cluster-as-pod</span><br><span class="line">          readOnly: <span class="literal">false</span></span><br><span class="line">        - mountPath: /grafana-dashboard-definitions/0/grafana-dashboard-k8s-etcd-server</span><br><span class="line">          name: grafana-dashboard-k8s-etcd-server</span><br><span class="line">          readOnly: <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 新增</span></span><br><span class="line">    - configMap:</span><br><span class="line">          name: grafana-dashboard-k8s-etcd-clusters-as-service</span><br><span class="line">        name: grafana-dashboard-k8s-etcd-clusters-as-service</span><br><span class="line">      - configMap:</span><br><span class="line">          name: grafana-dashboard-k8s-etcd-cluster-as-pod</span><br><span class="line">        name: grafana-dashboard-k8s-etcd-cluster-as-pod</span><br><span class="line">      - configMap:</span><br><span class="line">          name: grafana-dashboard-k8s-etcd-server</span><br><span class="line">        name: grafana-dashboard-k8s-etcd-server</span><br><span class="line">      - configMap:</span><br><span class="line">          name: grafana-dashboard-k8s-traefik-ingress</span><br><span class="line">        name: grafana-dashboard-k8s-traefik-ingress</span><br></pre></td></tr></table></figure></li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;上述新增值需要吧dashbord的模版倒入grafana-dashboardDefinitions.yaml文件里面，格式可以参考里面的格式，记住数据库需要修改，否则无法链接数据库，dashbord无法显示。</p><h4 id="查看service、endpoints"><a href="#查看service、endpoints" class="headerlink" title="查看service、endpoints"></a>查看service、endpoints</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl get svc,endpoints -n kube-system</span></span><br><span class="line">NAME                              TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                  AGE</span><br><span class="line">service/etcd                      ClusterIP   None             &lt;none&gt;        2379/TCP                 3m41s</span><br><span class="line">service/kube-controller-manager   ClusterIP   None             &lt;none&gt;        10252/TCP                16h</span><br><span class="line">service/kube-dns                  ClusterIP   10.254.0.2       &lt;none&gt;        53/UDP,53/TCP,9153/TCP   7d16h</span><br><span class="line">service/kube-proxy                ClusterIP   None             &lt;none&gt;        10249/TCP                37m</span><br><span class="line">service/kube-scheduler            ClusterIP   None             &lt;none&gt;        10251/TCP                18h</span><br><span class="line">service/kubelet                   ClusterIP   None             &lt;none&gt;        10250/TCP                40h</span><br><span class="line">service/kubernetes-dashboard      NodePort    10.254.139.196   &lt;none&gt;        443:31417/TCP            6d18h</span><br><span class="line">service/metrics-server            ClusterIP   10.254.196.151   &lt;none&gt;        443/TCP                  2d23h</span><br><span class="line"></span><br><span class="line">NAME                                ENDPOINTS                                                                 AGE</span><br><span class="line">endpoints/etcd                      172.21.16.110:2379,172.21.17.30:2379,172.21.17.31:2379                    3m41s</span><br><span class="line">endpoints/kube-controller-manager   172.21.16.110:10252,172.21.17.30:10252,172.21.17.31:10252                 16h</span><br><span class="line">endpoints/kube-dns                  10.244.1.46:53,10.244.4.36:53,10.244.1.46:53 + 3 more...                  7d16h</span><br><span class="line">endpoints/kube-proxy                172.21.16.204:10249,172.21.16.231:10249,172.21.17.34:10249 + 3 more...    37m</span><br><span class="line">endpoints/kube-scheduler            172.21.16.110:10251,172.21.17.30:10251,172.21.17.31:10251                 7d16h</span><br><span class="line">endpoints/kubelet                   172.21.16.204:10255,172.21.16.231:10255,172.21.17.34:10255 + 15 more...   40h</span><br><span class="line">endpoints/kubernetes-dashboard      10.244.6.27:8443                                                          6d18h</span><br><span class="line">endpoints/metrics-server            172.21.17.34:4443                                                         2d23h</span><br></pre></td></tr></table></figure><h4 id="查看接口信息"><a href="#查看接口信息" class="headerlink" title="查看接口信息"></a>查看接口信息</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl api-versions| grep monitoring</span></span><br><span class="line">monitoring.coreos.com/v1</span><br><span class="line"></span><br><span class="line"><span class="comment"># kubectl get --raw "/apis/monitoring.coreos.com/v1"|jq .</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># kubectl get --raw "/apis/monitoring.coreos.com/v1/servicemonitors"|jq .</span></span><br></pre></td></tr></table></figure><h3 id="查看验证"><a href="#查看验证" class="headerlink" title="查看验证"></a>查看验证</h3><h4 id="Prometheus-的Targets监控"><a href="#Prometheus-的Targets监控" class="headerlink" title="Prometheus 的Targets监控"></a>Prometheus 的Targets监控</h4><p><img src="https://img.xxlaila.cn/1575513127483.jpg" alt="img"><br><img src="https://img.xxlaila.cn/1575513184822.jpg" alt="img"><br><img src="https://img.xxlaila.cn/1575513219480.jpg" alt="img"><br><img src="https://img.xxlaila.cn/1575517225144.jpg" alt="img"><br><img src="https://img.xxlaila.cn/1575519980419.jpg" alt="img"></p><h4 id="granfa-查看"><a href="#granfa-查看" class="headerlink" title="granfa 查看"></a>granfa 查看</h4><p><img src="https://img.xxlaila.cn/1575513263070.jpg" alt="img"><br><img src="https://img.xxlaila.cn/1575513304800.jpg" alt="img"><br><img src="https://img.xxlaila.cn/1575513339328.jpg" alt="img"></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Thu Feb 20 2020 16:22:06 GMT+0800 (China Standard Time) --&gt;&lt;h3 id=&quot;介绍&quot;&gt;&lt;a href=&quot;#介绍&quot; class=&quot;headerlink&quot; title=&quot;介绍&quot;&gt;&lt;/a&gt;介绍&lt;/h3&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;kube-prometheus是读取Metrcs、etcd、api的其中数据。
    
    </summary>
    
      <category term="监控" scheme="https://www.xxlaila.cn/categories/%E7%9B%91%E6%8E%A7/"/>
    
    
      <category term="prometheus" scheme="https://www.xxlaila.cn/tags/prometheus/"/>
    
  </entry>
  
  <entry>
    <title>centos 7 升级内核</title>
    <link href="https://www.xxlaila.cn/2019/12/03/centos-7-%E5%8D%87%E7%BA%A7%E5%86%85%E6%A0%B8/"/>
    <id>https://www.xxlaila.cn/2019/12/03/centos-7-升级内核/</id>
    <published>2019-12-03T09:01:03.000Z</published>
    <updated>2019-12-12T06:29:22.159Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Thu Feb 20 2020 16:22:06 GMT+0800 (China Standard Time) --><h3 id="centos-7-升级内核版本"><a href="#centos-7-升级内核版本" class="headerlink" title="centos 7 升级内核版本"></a>centos 7 升级内核版本</h3><h4 id="查看当前内核版本"><a href="#查看当前内核版本" class="headerlink" title="查看当前内核版本"></a>查看当前内核版本</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># uname -r</span></span><br><span class="line">3.10.0-693.el7.x86_64</span><br><span class="line"></span><br><span class="line"><span class="comment"># uname -a</span></span><br><span class="line">Linux k8s-master-01-3.kxl 3.10.0-693.el7.x86_64 <span class="comment">#1 SMP Tue Aug 22 21:09:27 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux</span></span><br></pre></td></tr></table></figure><a id="more"></a><h4 id="更新yum源仓库和插件"><a href="#更新yum源仓库和插件" class="headerlink" title="更新yum源仓库和插件"></a>更新yum源仓库和插件</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># yum -y update</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># reboot</span></span><br></pre></td></tr></table></figure><h3 id="升级内核"><a href="#升级内核" class="headerlink" title="升级内核"></a>升级内核</h3><h4 id="导入ELRepo仓库的公共密钥"><a href="#导入ELRepo仓库的公共密钥" class="headerlink" title="导入ELRepo仓库的公共密钥"></a>导入ELRepo仓库的公共密钥</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org</span></span><br></pre></td></tr></table></figure><h4 id="安装ELRepo仓库的yum源"><a href="#安装ELRepo仓库的yum源" class="headerlink" title="安装ELRepo仓库的yum源"></a>安装ELRepo仓库的yum源</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-4.el7.elrepo.noarch.rpm</span></span><br></pre></td></tr></table></figure><h4 id="查看可用的系统内核包"><a href="#查看可用的系统内核包" class="headerlink" title="查看可用的系统内核包"></a>查看可用的系统内核包</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># yum --disablerepo="*" --enablerepo="elrepo-kernel" list available</span></span><br><span class="line">elrepo-kernel                                                                                                                                                                      | 2.9 kB  00:00:00     </span><br><span class="line">elrepo-kernel/primary_db                                                                                                                                                           | 1.8 MB  00:00:00     </span><br><span class="line">Available Packages</span><br><span class="line">kernel-lt.x86_64                                                                                     4.4.205-1.el7.elrepo                                                                    elrepo-kernel</span><br><span class="line">kernel<span class="_">-lt</span>-devel.x86_64                                                                               4.4.205-1.el7.elrepo                                                                    elrepo-kernel</span><br><span class="line">kernel<span class="_">-lt</span>-doc.noarch                                                                                 4.4.205-1.el7.elrepo                                                                    elrepo-kernel</span><br><span class="line">kernel<span class="_">-lt</span>-headers.x86_64                                                                             4.4.205-1.el7.elrepo                                                                    elrepo-kernel</span><br><span class="line">kernel<span class="_">-lt</span>-tools.x86_64                                                                               4.4.205-1.el7.elrepo                                                                    elrepo-kernel</span><br><span class="line">kernel<span class="_">-lt</span>-tools-libs.x86_64                                                                          4.4.205-1.el7.elrepo                                                                    elrepo-kernel</span><br><span class="line">kernel<span class="_">-lt</span>-tools-libs-devel.x86_64                                                                    4.4.205-1.el7.elrepo                                                                    elrepo-kernel</span><br><span class="line">kernel-ml.x86_64                                                                                     5.4.1-1.el7.elrepo                                                                      elrepo-kernel</span><br><span class="line">kernel-ml-devel.x86_64                                                                               5.4.1-1.el7.elrepo                                                                      elrepo-kernel</span><br><span class="line">kernel-ml-doc.noarch                                                                                 5.4.1-1.el7.elrepo                                                                      elrepo-kernel</span><br><span class="line">kernel-ml-headers.x86_64                                                                             5.4.1-1.el7.elrepo                                                                      elrepo-kernel</span><br><span class="line">kernel-ml-tools.x86_64                                                                               5.4.1-1.el7.elrepo                                                                      elrepo-kernel</span><br><span class="line">kernel-ml-tools-libs.x86_64                                                                          5.4.1-1.el7.elrepo                                                                      elrepo-kernel</span><br><span class="line">kernel-ml-tools-libs-devel.x86_64                                                                    5.4.1-1.el7.elrepo                                                                      elrepo-kernel</span><br><span class="line">perf.x86_64                                                                                          5.4.1-1.el7.elrepo                                                                      elrepo-kernel</span><br><span class="line">python-perf.x86_64                                                                                   5.4.1-1.el7.elrepo                                                                      elrepo-kernel</span><br></pre></td></tr></table></figure><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;结果为长期维护版本lt为4.4，最新主线稳定版ml为5.4，这里安装的是4.4</p><h4 id="安装kernel"><a href="#安装kernel" class="headerlink" title="安装kernel"></a>安装kernel</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># yum -y --enablerepo=elrepo-kernel install kernel-lt-4.4.205-1.el7.elrepo kernel-lt-devel-4.4.205-1.el7.elrepo</span></span><br></pre></td></tr></table></figure><h3 id="设置-grub2"><a href="#设置-grub2" class="headerlink" title="设置 grub2"></a>设置 grub2</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;内核安装好后，需要设置为默认启动选项并重启后才会生效</p><h4 id="查看系统上的所有可用内核"><a href="#查看系统上的所有可用内核" class="headerlink" title="查看系统上的所有可用内核"></a>查看系统上的所有可用内核</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># awk -F\' '$1=="menuentry " &#123;print i++ " : " $2&#125;' /etc/grub2.cfg</span></span><br><span class="line">0 : CentOS Linux (4.4.205-1.el7.elrepo.x86_64) 7 (Core)</span><br><span class="line">1 : CentOS Linux (3.10.0-957.12.1.el7.x86_64) 7 (Core)</span><br><span class="line">2 : CentOS Linux (3.10.0-693.el7.x86_64) 7 (Core)</span><br><span class="line">3 : CentOS Linux (0-rescue-d1f142097d497f24c021d7de9b81cab4) 7 (Core)</span><br></pre></td></tr></table></figure><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;服务器上存在4 个内核，我们要使用 4.4 这个版本，可以通过 grub2-set-default 0 命令或编辑 /etc/default/grub 文件来设置</p><h4 id="设置新的内核为grub2的默认版本"><a href="#设置新的内核为grub2的默认版本" class="headerlink" title="设置新的内核为grub2的默认版本"></a>设置新的内核为grub2的默认版本</h4><ul><li><p>方法1<br>通过 grub2-set-default 0 命令设置，其中 0 是上面查询出来的可用内核</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># grub2-set-default 0</span></span><br></pre></td></tr></table></figure></li><li><p>方法2<br>编辑 /etc/default/grub 文件，设置 GRUB_DEFAULT=0，通过上面查询显示的编号为 0 的内核作为默认内核。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># vim /etc/default/grub</span></span><br><span class="line">GRUB_TIMEOUT=1</span><br><span class="line">GRUB_DISTRIBUTOR=<span class="string">"<span class="variable">$(sed 's, release .*$,,g' /etc/system-release)</span>"</span></span><br><span class="line">GRUB_DEFAULT=0</span><br><span class="line">GRUB_DISABLE_SUBMENU=<span class="literal">true</span></span><br><span class="line">GRUB_TERMINAL=<span class="string">"serial console"</span></span><br><span class="line">GRUB_SERIAL_COMMAND=<span class="string">"serial --speed=115200"</span></span><br><span class="line">GRUB_CMDLINE_LINUX=<span class="string">"console=tty0 crashkernel=auto console=ttyS0,115200"</span></span><br><span class="line">GRUB_DISABLE_RECOVERY=<span class="string">"true"</span></span><br></pre></td></tr></table></figure></li></ul><h4 id="生成-grub-配置文件并重启"><a href="#生成-grub-配置文件并重启" class="headerlink" title="生成 grub 配置文件并重启"></a>生成 grub 配置文件并重启</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># grub2-mkconfig -o /boot/grub2/grub.cfg</span></span><br><span class="line">Generating grub configuration file ...</span><br><span class="line">Found linux image: /boot/vmlinuz-4.4.205-1.el7.elrepo.x86_64</span><br><span class="line">Found initrd image: /boot/initramfs-4.4.205-1.el7.elrepo.x86_64.img</span><br><span class="line">Found linux image: /boot/vmlinuz-3.10.0-957.12.1.el7.x86_64</span><br><span class="line">Found initrd image: /boot/initramfs-3.10.0-957.12.1.el7.x86_64.img</span><br><span class="line">Found linux image: /boot/vmlinuz-3.10.0-693.el7.x86_64</span><br><span class="line">Found initrd image: /boot/initramfs-3.10.0-693.el7.x86_64.img</span><br><span class="line">Found linux image: /boot/vmlinuz-0-rescue-d1f142097d497f24c021d7de9b81cab4</span><br><span class="line">Found initrd image: /boot/initramfs-0-rescue-d1f142097d497f24c021d7de9b81cab4.img</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># reboot</span></span><br></pre></td></tr></table></figure><h3 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># uname -r</span></span><br><span class="line">4.4.205-1.el7.elrepo.x86_64</span><br></pre></td></tr></table></figure><h3 id="删除旧内核"><a href="#删除旧内核" class="headerlink" title="删除旧内核"></a>删除旧内核</h3><h4 id="查看系统中全部的内核"><a href="#查看系统中全部的内核" class="headerlink" title="查看系统中全部的内核"></a>查看系统中全部的内核</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rpm -qa | grep kernel</span></span><br><span class="line">kernel<span class="_">-lt</span>-devel-4.4.205-1.el7.elrepo.x86_64</span><br><span class="line">kernel-3.10.0-693.el7.x86_64</span><br><span class="line">kernel-3.10.0-957.12.1.el7.x86_64</span><br><span class="line">kernel<span class="_">-lt</span>-4.4.205-1.el7.elrepo.x86_64</span><br><span class="line">kernel-tools-libs-3.10.0-1062.4.3.el7.x86_64</span><br><span class="line">kernel-3.10.0-1062.4.3.el7.x86_64</span><br><span class="line">kernel-tools-3.10.0-1062.4.3.el7.x86_64</span><br></pre></td></tr></table></figure><h4 id="yum-remove-删除旧内核的-RPM-包"><a href="#yum-remove-删除旧内核的-RPM-包" class="headerlink" title="yum remove 删除旧内核的 RPM 包"></a>yum remove 删除旧内核的 RPM 包</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># yum remove kernel-3.10.0-693.el7.x86_64 kernel-3.10.0-957.12.1.el7.x86_64 kernel-tools-libs-3.10.0-1062.4.3.el7.x86_64 kernel-3.10.0-1062.4.3.el7.x86_64 kernel-tools-3.10.0-1062.4.3.el7.x86_64</span></span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Thu Feb 20 2020 16:22:06 GMT+0800 (China Standard Time) --&gt;&lt;h3 id=&quot;centos-7-升级内核版本&quot;&gt;&lt;a href=&quot;#centos-7-升级内核版本&quot; class=&quot;headerlink&quot; title=&quot;centos 7 升级内核版本&quot;&gt;&lt;/a&gt;centos 7 升级内核版本&lt;/h3&gt;&lt;h4 id=&quot;查看当前内核版本&quot;&gt;&lt;a href=&quot;#查看当前内核版本&quot; class=&quot;headerlink&quot; title=&quot;查看当前内核版本&quot;&gt;&lt;/a&gt;查看当前内核版本&lt;/h4&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# uname -r&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3.10.0-693.el7.x86_64&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# uname -a&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Linux k8s-master-01-3.kxl 3.10.0-693.el7.x86_64 &lt;span class=&quot;comment&quot;&gt;#1 SMP Tue Aug 22 21:09:27 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="centos" scheme="https://www.xxlaila.cn/categories/centos/"/>
    
    
      <category term="kernel" scheme="https://www.xxlaila.cn/tags/kernel/"/>
    
  </entry>
  
  <entry>
    <title>flannel cni容器部署</title>
    <link href="https://www.xxlaila.cn/2019/11/29/flannel-cni%E5%AE%B9%E5%99%A8%E9%83%A8%E7%BD%B2/"/>
    <id>https://www.xxlaila.cn/2019/11/29/flannel-cni容器部署/</id>
    <published>2019-11-29T03:50:55.000Z</published>
    <updated>2020-02-22T12:00:52.934Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sun Feb 23 2020 16:11:22 GMT+0800 (China Standard Time) --><h3 id="flannel-cni-配置"><a href="#flannel-cni-配置" class="headerlink" title="flannel cni 配置"></a>flannel cni 配置</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;flannel 以 DaemonSet 的形式运行在 Kubernetes 集群中。 由于我们的 etcd 集群启用了 TLS 认证，为了从 flannel 容器中能访问 etcd，我们先把 etcd 的 TLS 证书信息保存到 Kubernetes 的Secret 中。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;之前是吧flannel以服务的形式部署在node节点上，这种模式每次新增节点的时候都要去部署一次flannel，显得比较麻烦，以pod形式部署，每次新增节点后，kubernetes会自动的部署flannel。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;删除原有的网络组件，采用容器方式进行部署。</p><h3 id="kube-controller-manager修改"><a href="#kube-controller-manager修改" class="headerlink" title="kube-controller-manager修改"></a>kube-controller-manager修改</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;启动参数增加如下两项<a id="more"></a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">--allocate-node-cidrs=<span class="literal">true</span></span><br><span class="line">--cluster-cidr=10.244.0.0/16</span><br></pre></td></tr></table></figure><p><strong>参数</strong>:</p><ul><li>1.是否应在云提供商上分配和设置Pod的CIDR</li><li>2.集群中Pod的CIDR范围。要求–allocate-node-cidrs为true</li></ul><p>kube-controller-manager参数<a href="https://kubernetes.io/docs/reference/command-line-tools-reference/kube-controller-manager/" target="_blank" rel="noopener">详细说明</a></p><h3 id="kubelet-修改"><a href="#kubelet-修改" class="headerlink" title="kubelet 修改"></a>kubelet 修改</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;kubelet修改两个配置文件，kubelet-config.yaml 文件已更新</p><h4 id="kubelet-service启动文件"><a href="#kubelet-service启动文件" class="headerlink" title="kubelet.service启动文件"></a>kubelet.service启动文件</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">--network-plugin=cni</span><br><span class="line">--cni-conf-dir=/etc/cni/net.d</span><br><span class="line">--cni-bin-dir=/opt/cni/bin</span><br></pre></td></tr></table></figure><p>kubele参数<a href="https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet/" target="_blank" rel="noopener">详细说明</a></p><h4 id="kube-proxy-修改子网"><a href="#kube-proxy-修改子网" class="headerlink" title="kube-proxy 修改子网"></a>kube-proxy 修改子网</h4><ul><li>kube-proxy-config.yaml<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">clusterCIDR: 10.244.0.0/16</span><br></pre></td></tr></table></figure></li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;k8s<a href="https://www.xxlaila.cn/2019/09/11/kubernetes-v1-14%E5%AE%89%E8%A3%85/">集群安装文档</a>已经更新，node<a href="https://www.xxlaila.cn/2019/09/16/kubernetes-v1-14-node%E5%AE%89%E8%A3%85/">节点安装文档</a>已经更新。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;首先停止node 的flananel、 kubelet、kube-proxy。在删除/etc/cni/net.d/、/run/flannel/subnet.env、/var/lib/cni/flannel 的历史文件，重启网卡，除了flannel不启动，其他均启动。全新安装不需要这么操作，flannel证书也不需要复制。<a href="https://github.com/containernetworking/cni" target="_blank" rel="noopener">二进制安装参考</a></p><h3 id="下载cni插件"><a href="#下载cni插件" class="headerlink" title="下载cni插件"></a>下载cni插件</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;cni <a href="https://github.com/containernetworking/plugins/releases" target="_blank" rel="noopener">插件下载</a>，解压后，放在各个节点的 /opt/cni/bin 下。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">ls -l /opt/cni/bin/</span><br><span class="line">total 70144</span><br><span class="line">-rwxr-xr-x 1 root root  4159253 Nov 26 16:32 bandwidth</span><br><span class="line">-rwxr-xr-x 1 root root  4628074 Nov 26 16:32 bridge</span><br><span class="line">-rwxr-xr-x 1 root root 12124236 Nov 26 16:32 dhcp</span><br><span class="line">-rwxr-xr-x 1 root root  5894275 Nov 26 16:32 firewall</span><br><span class="line">-rwxr-xr-x 1 root root  3069556 Nov 26 16:32 flannel</span><br><span class="line">-rwxr-xr-x 1 root root  4113837 Nov 26 16:32 host-device</span><br><span class="line">-rwxr-xr-x 1 root root  3614305 Nov 26 16:32 host-local</span><br><span class="line">-rwxr-xr-x 1 root root  4275320 Nov 26 16:32 ipvlan</span><br><span class="line">-rwxr-xr-x 1 root root  3209373 Nov 26 16:32 loopback</span><br><span class="line">-rwxr-xr-x 1 root root  4346248 Nov 26 16:32 macvlan</span><br><span class="line">-rwxr-xr-x 1 root root  3895553 Nov 26 16:32 portmap</span><br><span class="line">-rwxr-xr-x 1 root root  4546828 Nov 26 16:32 ptp</span><br><span class="line">-rwxr-xr-x 1 root root  3392736 Nov 26 16:32 sbr</span><br><span class="line">-rwxr-xr-x 1 root root  2885430 Nov 26 16:32 static</span><br><span class="line">-rwxr-xr-x 1 root root  3356497 Nov 26 16:32 tuning</span><br><span class="line">-rwxr-xr-x 1 root root  4275168 Nov 26 16:32 vlan</span><br></pre></td></tr></table></figure><h3 id="flannel-部署"><a href="#flannel-部署" class="headerlink" title="flannel 部署"></a>flannel 部署</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wget https://raw.githubusercontent.com/coreos/flannel/v0.11.0/Documentation/kube-flannel.yml</span><br><span class="line"></span><br><span class="line">kubectl apply -f ./kube-flannel.yml</span><br></pre></td></tr></table></figure><h3 id="查看flannel安装情况"><a href="#查看flannel安装情况" class="headerlink" title="查看flannel安装情况"></a>查看flannel安装情况</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl get po,svc -o wide</span></span><br><span class="line">NAME                 READY   STATUS    RESTARTS   AGE   IP           NODE            NOMINATED NODE   READINESS GATES</span><br><span class="line">pod/nginx-ds-b9wgm   1/1     Running   0          43h   10.244.6.2   172.21.17.41    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">pod/nginx-ds-dd9mb   1/1     Running   0          43h   10.244.1.3   172.21.17.34    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">pod/nginx-ds-lcrn5   1/1     Running   0          43h   10.244.4.2   172.21.16.231   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">pod/nginx-ds-n52vr   1/1     Running   0          43h   10.244.2.2   172.21.17.40    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">pod/nginx-ds-twdxm   1/1     Running   0          43h   10.244.5.2   172.21.16.204   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">pod/nginx-ds-z72mx   1/1     Running   0          43h   10.244.3.2   172.21.17.38    &lt;none&gt;           &lt;none&gt;</span><br><span class="line"></span><br><span class="line">NAME                 TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE   SELECTOR</span><br><span class="line">service/kubernetes   ClusterIP   10.254.0.1      &lt;none&gt;        443/TCP        44h   &lt;none&gt;</span><br><span class="line">service/nginx-ds     NodePort    10.254.230.34   &lt;none&gt;        80:31286/TCP   43h   app=nginx-ds</span><br><span class="line"></span><br><span class="line"><span class="comment"># kubectl get po,svc -o wide -n kube-system</span></span><br><span class="line">NAME                                              READY   STATUS    RESTARTS   AGE     IP              NODE            NOMINATED NODE   READINESS GATES</span><br><span class="line">pod/coredns-5579b8778b-dlk4c                      1/1     Running   4          43h     10.244.1.2      172.21.17.34    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">pod/kube-flannel-ds-amd64-2t8rn                   1/1     Running   0          44h     172.21.17.41    172.21.17.41    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">pod/kube-flannel-ds-amd64-9sb8v                   1/1     Running   0          44h     172.21.16.231   172.21.16.231   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">pod/kube-flannel-ds-amd64-npl5k                   1/1     Running   0          44h     172.21.17.34    172.21.17.34    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">pod/kube-flannel-ds-amd64-r5n8r                   1/1     Running   0          44h     172.21.16.204   172.21.16.204   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">pod/kube-flannel-ds-amd64-wpfxw                   1/1     Running   0          44h     172.21.17.40    172.21.17.40    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">pod/kube-flannel-ds-amd64-x2v8z                   1/1     Running   0          44h     172.21.17.38    172.21.17.38    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">pod/kubernetes-dashboard-65dfbf6f4f-sc92h         1/1     Running   0          21h     10.244.6.10     172.21.17.41    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">pod/metrics-server-v0.3.4-5cd6d6b55f-psq2z        2/2     Running   0          3h20m   172.21.17.34    172.21.17.34    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">pod/traefik-ingress-controller-56b6d5b864-srnmm   1/1     Running   0          155m    172.21.17.41    172.21.17.41    &lt;none&gt;           &lt;none&gt;</span><br><span class="line"></span><br><span class="line">NAME                              TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                  AGE     SELECTOR</span><br><span class="line">service/kube-dns                  ClusterIP   10.254.0.2       &lt;none&gt;        53/UDP,53/TCP,9153/TCP   43h     k8s-app=kube-dns</span><br><span class="line">service/kubernetes-dashboard      NodePort    10.254.139.196   &lt;none&gt;        443:31417/TCP            21h     k8s-app=kubernetes-dashboard</span><br><span class="line">service/metrics-server            ClusterIP   10.254.201.191   &lt;none&gt;        443/TCP                  3h56m   k8s-app=metrics-server</span><br><span class="line">service/traefik-ingress-service   ClusterIP   None             &lt;none&gt;        80/TCP,8080/TCP          154m    k8s-app=traefik-ingress-lb</span><br><span class="line">service/traefik-web-ui            ClusterIP   10.254.78.17     &lt;none&gt;        80/TCP                   23h     k8s-app=traefik-ingress-lb</span><br></pre></td></tr></table></figure><h3 id="查看节点的网络"><a href="#查看节点的网络" class="headerlink" title="查看节点的网络"></a>查看节点的网络</h3><ul><li><p>node-01</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ifconfig</span></span><br><span class="line">cni0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1450</span><br><span class="line">        inet 10.244.6.1  netmask 255.255.255.0  broadcast 10.244.6.255</span><br><span class="line">        ether 42:56:73:73:c5:69  txqueuelen 1000  (Ethernet)</span><br><span class="line">        RX packets 121976  bytes 48185929 (45.9 MiB)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 143012  bytes 112170228 (106.9 MiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br><span class="line">eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span><br><span class="line">        inet 172.21.17.41  netmask 255.255.240.0  broadcast 172.21.31.255</span><br><span class="line">        ether fa:16:3e:a0:b1:af  txqueuelen 1000  (Ethernet)</span><br><span class="line">        RX packets 1878425  bytes 997129342 (950.9 MiB)</span><br><span class="line">        RX errors 0  dropped 29  overruns 0  frame 0</span><br><span class="line">        TX packets 1014950  bytes 378435170 (360.9 MiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br><span class="line">flannel.1: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1450</span><br><span class="line">        inet 10.244.6.0  netmask 255.255.255.255  broadcast 0.0.0.0</span><br><span class="line">        ether 32:83:f7:e6:de:77  txqueuelen 0  (Ethernet)</span><br><span class="line">        RX packets 207502  bytes 36217464 (34.5 MiB)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 242424  bytes 246992876 (235.5 MiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br><span class="line">lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt;  mtu 65536</span><br><span class="line">        inet 127.0.0.1  netmask 255.0.0.0</span><br><span class="line">        loop  txqueuelen 1  (Local Loopback)</span><br><span class="line">        RX packets 15889  bytes 7196484 (6.8 MiB)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 15889  bytes 7196484 (6.8 MiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br><span class="line">vethb26f5960: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1450</span><br><span class="line">        ether a6:a8:18:c3:f0:16  txqueuelen 0  (Ethernet)</span><br><span class="line">        RX packets 23  bytes 2075 (2.0 KiB)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 49  bytes 4330 (4.2 KiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br></pre></td></tr></table></figure></li><li><p>node-02</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ifconfig</span></span><br><span class="line">cni0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1450</span><br><span class="line">        inet 10.244.4.1  netmask 255.255.255.0  broadcast 10.244.4.255</span><br><span class="line">        ether 82:14:33:5c:b0:b7  txqueuelen 1000  (Ethernet)</span><br><span class="line">        RX packets 150228  bytes 747318135 (712.6 MiB)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 214837  bytes 209342880 (199.6 MiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br><span class="line">eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span><br><span class="line">        inet 172.21.16.231  netmask 255.255.240.0  broadcast 172.21.31.255</span><br><span class="line">        ether fa:16:3e:d8:23:fe  txqueuelen 1000  (Ethernet)</span><br><span class="line">        RX packets 10290258  bytes 3436274673 (3.2 GiB)</span><br><span class="line">        RX errors 0  dropped 19  overruns 0  frame 0</span><br><span class="line">        TX packets 9490095  bytes 3777352983 (3.5 GiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br><span class="line">flannel.1: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1450</span><br><span class="line">        inet 10.244.4.0  netmask 255.255.255.255  broadcast 0.0.0.0</span><br><span class="line">        ether ee:a3:ff:37:3a:61  txqueuelen 0  (Ethernet)</span><br><span class="line">        RX packets 280851  bytes 31096456 (29.6 MiB)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 262931  bytes 968429571 (923.5 MiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br><span class="line">lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt;  mtu 65536</span><br><span class="line">        inet 127.0.0.1  netmask 255.0.0.0</span><br><span class="line">        loop  txqueuelen 1  (Local Loopback)</span><br><span class="line">        RX packets 653134  bytes 200562497 (191.2 MiB)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 653134  bytes 200562497 (191.2 MiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br><span class="line">veth8aa15f82: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1450</span><br><span class="line">        ether fa:23:1e:b0:65:20  txqueuelen 0  (Ethernet)</span><br><span class="line">        RX packets 49191  bytes 4622232 (4.4 MiB)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 53647  bytes 19011709 (18.1 MiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br></pre></td></tr></table></figure></li></ul><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Sun Feb 23 2020 16:11:22 GMT+0800 (China Standard Time) --&gt;&lt;h3 id=&quot;flannel-cni-配置&quot;&gt;&lt;a href=&quot;#flannel-cni-配置&quot; class=&quot;headerlink&quot; title=&quot;flannel cni 配置&quot;&gt;&lt;/a&gt;flannel cni 配置&lt;/h3&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;flannel 以 DaemonSet 的形式运行在 Kubernetes 集群中。 由于我们的 etcd 集群启用了 TLS 认证，为了从 flannel 容器中能访问 etcd，我们先把 etcd 的 TLS 证书信息保存到 Kubernetes 的Secret 中。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;之前是吧flannel以服务的形式部署在node节点上，这种模式每次新增节点的时候都要去部署一次flannel，显得比较麻烦，以pod形式部署，每次新增节点后，kubernetes会自动的部署flannel。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;删除原有的网络组件，采用容器方式进行部署。&lt;/p&gt;&lt;h3 id=&quot;kube-controller-manager修改&quot;&gt;&lt;a href=&quot;#kube-controller-manager修改&quot; class=&quot;headerlink&quot; title=&quot;kube-controller-manager修改&quot;&gt;&lt;/a&gt;kube-controller-manager修改&lt;/h3&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;启动参数增加如下两项
    
    </summary>
    
      <category term="kubernetes" scheme="https://www.xxlaila.cn/categories/kubernetes/"/>
    
    
      <category term="flannel" scheme="https://www.xxlaila.cn/tags/flannel/"/>
    
  </entry>
  
  <entry>
    <title>k8s-dashboard v2.0.0部署</title>
    <link href="https://www.xxlaila.cn/2019/11/28/k8s-dashboard-v2-0-0%E9%83%A8%E7%BD%B2/"/>
    <id>https://www.xxlaila.cn/2019/11/28/k8s-dashboard-v2-0-0部署/</id>
    <published>2019-11-28T07:47:19.000Z</published>
    <updated>2019-12-02T07:01:32.306Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Thu Feb 20 2020 16:22:06 GMT+0800 (China Standard Time) --><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Kubernetes Dashboard 从v2.0.0-beta1版本开始，集成了一个metrics-scraper的组件，可以通过 Kubernetes 的 Metrics API 收集一些基础资源的监控信息，并在web页面展示</p><a id="more"></a><h3 id="下载文件"><a href="#下载文件" class="headerlink" title="下载文件"></a>下载文件</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0-beta6/aio/deploy/recommended.yaml</span><br></pre></td></tr></table></figure><h3 id="使用-openssl-签发证书"><a href="#使用-openssl-签发证书" class="headerlink" title="使用 openssl 签发证书"></a>使用 openssl 签发证书</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir certs</span><br><span class="line">openssl req -nodes -newkey rsa:2048 -keyout certs/dashboard.key -out certs/dashboard.csr -subj <span class="string">"/C=/ST=/L=/O=/OU=/CN=kubernetes-dashboard"</span></span><br><span class="line">openssl x509 -req -sha256 -days 10000 -<span class="keyword">in</span> certs/dashboard.csr -signkey certs/dashboard.key -out certs/dashboard.crt</span><br></pre></td></tr></table></figure><h3 id="安装-Dashboard"><a href="#安装-Dashboard" class="headerlink" title="安装 Dashboard"></a>安装 Dashboard</h3><h4 id="创建namespace"><a href="#创建namespace" class="headerlink" title="创建namespace"></a>创建namespace</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create namespace kubernetes-dashboard</span><br></pre></td></tr></table></figure><h4 id="导入证书"><a href="#导入证书" class="headerlink" title="导入证书"></a>导入证书</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create secret generic kubernetes-dashboard-certs --from-file=certs -n kubernetes-dashboard</span><br></pre></td></tr></table></figure><h4 id="修改recommended-yaml"><a href="#修改recommended-yaml" class="headerlink" title="修改recommended.yaml"></a>修改recommended.yaml</h4><ul><li><p>注释namespace</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Namespace</span><br><span class="line">metadata:</span><br><span class="line">  name: kubernetes-dashboard</span><br></pre></td></tr></table></figure></li><li><p>使用自签发的证书<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;使用自签发的证书,注释掉 kubernetes-dashboard-certs 的 Secret 定义</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">  name: kubernetes-dashboard-certs</span><br><span class="line">  namespace: kubernetes-dashboard</span><br><span class="line"><span class="built_in">type</span>: Opaque</span><br></pre></td></tr></table></figure></li><li><p>部署</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f recommended.yaml</span><br></pre></td></tr></table></figure></li></ul><h4 id="使用-NodePort-暴露服务"><a href="#使用-NodePort-暴露服务" class="headerlink" title="使用 NodePort 暴露服务"></a>使用 NodePort 暴露服务</h4><ul><li><p>新建 external-https-svc.yaml</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">cat &gt;external-https-svc.yaml&lt;&lt;EOF</span><br><span class="line">kind: Service</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">  name: kubernetes-dashboard-external</span><br><span class="line">  namespace: kubernetes-dashboard</span><br><span class="line">spec:</span><br><span class="line">  <span class="built_in">type</span>: NodePort</span><br><span class="line">  ports:</span><br><span class="line">    - port: 443</span><br><span class="line">      targetPort: 8443</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br></pre></td></tr></table></figure></li><li><p>部署</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f external-https-svc.yaml</span><br></pre></td></tr></table></figure></li><li><p>查看验证</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># kubectl <span class="keyword">get</span> svc,pods -n kubernetes-dashboard</span><br><span class="line"></span><br><span class="line">NAME                                    TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)         AGE</span><br><span class="line">service/dashboard-metrics-scraper       ClusterIP   <span class="number">10.254</span><span class="number">.199</span><span class="number">.169</span>   &lt;none&gt;        <span class="number">8000</span>/TCP        <span class="number">9</span>m50s</span><br><span class="line">service/kubernetes-dashboard            ClusterIP   <span class="number">10.254</span><span class="number">.73</span><span class="number">.119</span>    &lt;none&gt;        <span class="number">443</span>/TCP         <span class="number">9</span>m51s</span><br><span class="line">service/kubernetes-dashboard-<span class="keyword">external</span>   NodePort    <span class="number">10.254</span><span class="number">.169</span><span class="number">.250</span>   &lt;none&gt;        <span class="number">443</span>:<span class="number">32318</span>/TCP   <span class="number">11</span>m</span><br><span class="line"></span><br><span class="line">NAME                                             READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod/dashboard-metrics-scraper<span class="number">-69f</span>cc6d9df<span class="number">-4</span>lctd   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">9</span>m49s</span><br><span class="line">pod/kubernetes-dashboard<span class="number">-77</span>d4694b5f-vkgfz        <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">9</span>m49s</span><br></pre></td></tr></table></figure></li></ul><p>使用之前的密钥认证登录，未出图，查了一下，说的是兼容问题，v1.15.0以上就没问题<br><img src="https://img.xxlaila.cn/1574927727171.jpg" alt="img"></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Thu Feb 20 2020 16:22:06 GMT+0800 (China Standard Time) --&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Kubernetes Dashboard 从v2.0.0-beta1版本开始，集成了一个metrics-scraper的组件，可以通过 Kubernetes 的 Metrics API 收集一些基础资源的监控信息，并在web页面展示&lt;/p&gt;
    
    </summary>
    
      <category term="kubernetes" scheme="https://www.xxlaila.cn/categories/kubernetes/"/>
    
    
      <category term="dashboard v2.0.0" scheme="https://www.xxlaila.cn/tags/dashboard-v2-0-0/"/>
    
  </entry>
  
  <entry>
    <title>logstash详解</title>
    <link href="https://www.xxlaila.cn/2019/11/21/logstash%E8%AF%A6%E8%A7%A3/"/>
    <id>https://www.xxlaila.cn/2019/11/21/logstash详解/</id>
    <published>2019-11-21T03:51:23.000Z</published>
    <updated>2019-11-27T01:15:35.606Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Thu Feb 20 2020 16:22:06 GMT+0800 (China Standard Time) --><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;前篇文件<a href="http://www.xxlaila.cn/2019/11/15/elk%E9%83%A8%E7%BD%B2/">elk部署</a>粗略的完成了部署，但是真正是批量使用的时候发现还是有很多不足，优化的点还是非常的多。<a id="more"></a></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;使用ElasticSearch时一般需要自己创建ElasticSearch的索引的Mapping，当索引非常多的时候，可能需要配置一个索引模板Template来对类似的索引做统一配置，让索引模板Template中配置匹配索引的规则，来确定该Template会被应用到哪些索引上。</p><h3 id="Template配置方式"><a href="#Template配置方式" class="headerlink" title="Template配置方式"></a>Template配置方式</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Logstash在整合ElasticSearch的时候，有三种方式可以来进行Template的配置。</p><h4 id="使用ElasticSearch默认自带的索引模板"><a href="#使用ElasticSearch默认自带的索引模板" class="headerlink" title="使用ElasticSearch默认自带的索引模板"></a>使用ElasticSearch默认自带的索引模板</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ElasticSearch默认自带了一个名字为”logstash”的模板，默认应用于Logstash写入数据到ElasticSearch使用，我们可以在通过es的api接口、或者在kibana dev tools窗口通过GET /_template/来进行查看</p><ul><li><p>api 查看</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ curl -XGET http://127.0.0.1:9200/_template  -s | python -m json.tool</span><br><span class="line"></span><br><span class="line">$ curl -XGET http://127.0.0.1:9200/_template?pretty</span><br></pre></td></tr></table></figure></li><li><p>kibana 查看<br><img src="https://img.xxlaila.cn/1574314182454.jpg" alt="img"></p></li><li><p>优点: 最简单，无须任何配置</p></li><li><p>缺点: 无法自定义一些配置，例如：分词方式</p></li></ul><h4 id="在Logstash-Indexer端自定义配置索引模板"><a href="#在Logstash-Indexer端自定义配置索引模板" class="headerlink" title="在Logstash Indexer端自定义配置索引模板"></a>在Logstash Indexer端自定义配置索引模板</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Logstash的output插件中使用template指定本机器上的一个模板json文件路径，可以在json文件中设置对应的Template模板信息。前面的章节就使用的这种方式。</p><ul><li>优点：配置简单</li><li>缺点：因为分散在Logstash Indexer机器上，维护起来比较麻烦</li></ul><h4 id="在ElasticSearch服务端自定义配置索引模板"><a href="#在ElasticSearch服务端自定义配置索引模板" class="headerlink" title="在ElasticSearch服务端自定义配置索引模板"></a>在ElasticSearch服务端自定义配置索引模板</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由ElasticSearch负责加载模板。这种方式需要在ElasticSearch的集群中的config/templates路径下配置模板json。而且ElasticSearch提供了Restful API接口维护索引模板信息。</p><ul><li>优点：维护比较容易，可动态更改，全局生效。</li><li>缺点：需要注意模板的命名规则，比较容易通过看Template名字就能够确定模板应用到哪些索引</li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;三种索引方式都有优缺点；但是使用第三种方式是最好的，就像之前<a href="http://www.xxlaila.cn/2019/11/15/elk%E9%83%A8%E7%BD%B2/">elk部署</a>就使用的是第二种方式，然后是在用的时候发现，logstash是多台服务器，维护起来非常非常的麻烦。如果logstash 和ElasticSearch只有一台服务器，可以使用第二种方式，在Logstash Indexer端维护Template文件即可。</p><h3 id="模版类型"><a href="#模版类型" class="headerlink" title="模版类型"></a>模版类型</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ElasticSearch的模板类型主要由两种：静态模板和动态模板</p><h4 id="静态模板"><a href="#静态模板" class="headerlink" title="静态模板"></a>静态模板</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;适合索引字段数据固定的场景，一旦配置完成，不能向里面加入多余的字段，否则会报错</p><ul><li>优点：scheam已知，业务场景明确，不容易出现因字段随便映射从而造成元数据撑爆es内存，从而导致es集群全部宕机</li><li>缺点：字段数多的情况下配置稍繁琐，针对于每个索引可能需要的模板都不同，很有可能需要配置很多个模板</li></ul><h4 id="动态模板"><a href="#动态模板" class="headerlink" title="动态模板"></a>动态模板</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;适合字段数不明确，大量字段的配置类型相同的场景，可以按照类型规则动态添加新字段，新加字段不会报错。主要需要配置 <code>dynamic_templates</code>。</p><ul><li>优点：可动态添加任意字段，无须改动schema</li><li>缺点：无标准schema导致数据不规则，如果添加的字段非常多，有可能造成ES集群宕机</li></ul><p><strong>注</strong>: 模板在设置生效后，仅对ES集群中新建立的索引生效，而对已存在的索引及时索引名满足模板的匹配规则，也不会生效，因此如果需要改变现有索引的Mapping信息，仍需要在正确的Mapping基础上建立新的索引，并将数据从原索引拷贝至新索引，变更新索引别名为原索引这种方式来实现。</p><h3 id="模板结构"><a href="#模板结构" class="headerlink" title="模板结构"></a>模板结构</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;模版的结构如<a href="http://www.xxlaila.cn/2019/11/15/elk%E9%83%A8%E7%BD%B2/">elk部署</a>里面所提到的。分四部分</p><ul><li>通用设置: 主要是模板匹配索引的过滤规则，影响该模板对哪些索引生效；</li><li>settings: 配置索引的公共参数，比如索引的replicas，以及分片数shards等参数；</li><li>mappings: 最重要的一部分，在这部分中配置每个type下的每个field的相关属性，比如field类型（string,long,date等等），是否分词，是否在内存中缓存等等属性都在这部分配置；</li><li>aliases: 索引别名，索引别名可用在索引数据迁移等用途上。</li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当我们在定制索引模版的时候，这时候我们需要参考研发给的日志标准和需要的日志标准格式，以及日志样本等，给出一些运维的见解。否则做出来的东西不一定满足需求，又要重新来做。着重参考如下:</p><ul><li>是否存储</li><li>是否分词</li><li>以什么来建立索引</li><li>字段类型是什么</li><li>如何排序</li><li>字段数是否固定</li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;结合这些，我们还可以参考词库的维护，ElasticSearch后期结构的变化调整，如果这些不考虑，在后期量起来以后，改动任何一项都需要去重新建立索引。是非常蛋疼的。</p><h3 id="创建模版"><a href="#创建模版" class="headerlink" title="创建模版"></a>创建模版</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这里采用第三种三种方式建立模版，登录kibana，在dev tools栏下面，删除默认的logstash-<em>模版，然后创建一个logstash-</em>的模版，这样当新的索引来了以后，就会加载这个模版。</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Thu Feb 20 2020 16:22:06 GMT+0800 (China Standard Time) --&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;前篇文件&lt;a href=&quot;http://www.xxlaila.cn/2019/11/15/elk%E9%83%A8%E7%BD%B2/&quot;&gt;elk部署&lt;/a&gt;粗略的完成了部署，但是真正是批量使用的时候发现还是有很多不足，优化的点还是非常的多。
    
    </summary>
    
      <category term="elk" scheme="https://www.xxlaila.cn/categories/elk/"/>
    
    
      <category term="logstash" scheme="https://www.xxlaila.cn/tags/logstash/"/>
    
  </entry>
  
</feed>
